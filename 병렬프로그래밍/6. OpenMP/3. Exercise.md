## Example 1

```c++
dotp = 0;
for (i=0; i<n; i++)
	dotp += a[i] + b[i];
```

첫 번째 코드는 단순히 `a`와 `b`의 같은 인덱스 원소를 더해서, 그 값을 `dotp`에 계속 누적하는 코드다. 여기서 `dotp`는 반복문 바깥에서 정의되어 있기 때문에 **공유 변수**이고, 이 상태로 반복문을 병렬화하면 여러 스레드가 동시에 `dotp`를 갱신하게 되어 race condition이 발생할 수 있다. 이런 상황에서는 `atomic`이나 `critical`을 사용해서 보호할 수도 있지만, 이 경우에는 OpenMP의 `reduction`을 쓰는 게 더 자연스럽다.

```c++
dotp = 0;
#pragma omp parallel for reduction(+:dotp)
for (i=0; i<n; i++)
	dotp += a[i] + b[i];
```

`reduction(+:dotp)`을 붙이면, OpenMP가 각 스레드마다 **자기만의 로컬 `dotp`** 를 하나씩 만들어서 그 안에 부분 합을 계산하게 한다. 그리고 병렬 영역이 끝날 때, 모든 스레드의 로컬 `dotp`를 `+` 연산으로 한 번에 합쳐서 최종 `dotp`에 넣어준다.  

결과적으로, race condition 없이 각 스레드가 나눠서 계산한 부분 합을 안전하게 모아 도트 프로덕트를 구할 수 있게 되는 것이다.

---
## Example 2

```c++
for (i=0; i<(int)sqrt(x); i++) {
	a[i] = 2.3 * i;
	if (i<10) b[i] = a[i];
}
```

두 번째 예시는 병렬화하기에 비교적 단순한 구조다. 우선 반복문의 조건을 보면, 반복 범위가 `sqrt(x)`로 주어져 있다. `x`는 반복문 바깥에서 이미 정의되어 있고, 루프가 시작될 때 `sqrt(x)`가 계산되어 반복 범위가 **고정된 값**으로 확정된다. OpenMP가 `parallel for`를 적용하려면, 반복문의 크기가 컴파일 시점 또는 루프 시작 시점에 **확실하게 결정**되어 있어야 하므로 이 부분은 문제가 없다.

반복문 내부에서는 `a[i]`가 인덱스에 따라 갱신되고, `i < 10`일 때만 `b[i]`가 업데이트된다. 각 반복에서 접근하는 인덱스 `i`는 서로 다르므로, 스레드 간에 **동일한 메모리 위치에 접근하는 충돌(race condition)** 이 발생하지 않는다. 즉, 공유 변수를 동시에 갱신하거나, 서로의 계산 결과를 사용해야 하는 의존성도 없다.

따라서 이 루프는 OpenMP로 안전하게 병렬화할 수 있다.

```c++
#pragma omp parallel for
for (i=0; i<(int)sqrt(x); i++) {
	a[i] = 2.3 * i;
	if (i<10) b[i] = a[i];
}
```

---
## Example3

```c++
for (i=k; i<n; i++)
	a[i] = b * a[i-k];
```

자 딱봐도 a[i-k] 가 a[i] 에 영향을 주고 있다. 즉 각 변수들끼리 의존성이 있는 상태이다. 이런 경우에 이상태로 병렬화를 할 수 없다.

그러나 잘 생각해보면 지금 의존성이 있는건 i 와 i-k 번째 값들이다. 즉 이 두 개는 같은 thread 안에 있으면 된다.  우선 하나의 쓰레드 안에서 두 개가 동시에 있기 위해서는 for문이 k 씩 건너 뛰어야 한다. 그리고 병렬 대상을 시작 점으로 하게 되면 시작점으로 부터 k 번째 떨어져 있는 값은 하나의 쓰레드에 위치하게 된다. 

```c++
#pragma omp parallel for
for ( int s = 0; s<n; s++)
```