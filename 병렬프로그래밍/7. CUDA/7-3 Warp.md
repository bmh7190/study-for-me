## Mapping Thread Blocks Onto SMs
CUDA에서 하나의 블록(block)에 속한 모든 스레드(thread)는 **같은 커널 코드**를 실행한다. 이런 실행 모델을 흔히 _Single Program, Multiple Data_ 방식이라고 부른다. 즉, 스레드들은 모두 동일한 프로그램(커널)을 실행하지만, 서로 다른 데이터 조각을 나눠서 처리한다.

프로그래머는 블록과 그리드의 차원을 직접 정의할 수 있다. 예를 들어 1차원, 2차원, 3차원 형태로 블록을 구성할 수 있어서, 이미지나 행렬처럼 2D·3D 데이터 구조에 맞춰 직관적으로 스레드를 배치할 수 있다.

각 스레드는 자신이 속한 블록 안에서 고유한 `threadIdx`(스레드 ID)를 가진다. 같은 블록에 속한 스레드들은 **공유 메모리(shared memory)** 를 통해 데이터를 주고받을 수 있고, `__syncthreads()` 같은 동기화 primitive를 사용해 **공유된 작업을 수행하는 동안 서로 발맞춰(sync)** 실행할 수 있다. 반대로, 서로 다른 블록에 속한 스레드들끼리는 이런 방식으로 효율적으로 협업하거나 동기화하기 어렵다. 그래서 CUDA에서는 **블록 내부는 긴밀한 협업·동기화**, **블록 간에는 독립적인 작업 단위**로 설계하는 것이 일반적인 패턴이다.

---
## Partitioning of CUDA Thread Blocks into Warps
CUDA에서는 하나의 스레드 블록이 내부적으로 **32개의 스레드로 이루어진 워프(warp)** 단위로 다시 나뉘어 실행된다. 이 워프는 GPU가 실제로 명령을 동시에 실행시키는 가장 작은 실행 단위다. 워프 안의 스레드들은 연속된 `threadIdx` 값을 가지며, 번호가 증가하는 순서대로 묶인다. 이 분할 방식은 언제나 동일하기 때문에, 프로그래머는 워프 내부의 규칙적인 구조를 알고 이를 제어 흐름(예: `if (threadIdx.x % 32 == 0)`)에서 활용할 수 있다.

하지만 주의할 점은 **워프 간의 순서나 실행 타이밍은 절대 보장되지 않는다**는 것이다. GPU 스케줄러가 상황에 따라 어떤 워프를 먼저 실행할지 마음대로 선택할 수 있기 때문에, 워프 간의 실행 순서에 의존하는 코드를 작성하면 안 된다.

또한 스레드들 사이에 어떤 형태로든 **데이터 의존성**이 존재한다면, 반드시 `__syncthreads()`를 사용해 **블록 내부의 스레드들을 동기화**해야 올바른 결과를 얻을 수 있다. `__syncthreads()`는 같은 블록 안의 스레드들이 모두 특정 지점까지 도달할 때까지 기다리게 하므로, 공유 메모리를 사용하는 연산에서 필수적인 안전장치 역할을 한다.

---
## Warp Scheduling
CUDA의 SM(Streaming Multiprocessor)은 **오버헤드가 거의 없는 워프 스케줄링**을 수행한다. 즉, SM은 매 순간 여러 워프 중에서 **딱 하나의 워프만 선택하여 실행**하는데, 이 선택 과정에서 별도의 비용이 거의 들지 않는다.

![](../../images/Pasted%20image%2020251203215505.png)

스케줄링의 기본 규칙은 다음과 같다.  

워프가 다음에 실행해야 할 명령의 **피연산자(데이터)가 준비되어 있다면**, 그 워프는 “실행 가능 상태(eligible)”가 된다. 여러 개의 실행 가능한 워프가 있을 경우 SM은 우선순위 기반 정책에 따라 그중 하나를 골라 실행한다.

CUDA의 실행 방식은 **SIMD(단일 명령, 다중 데이터)** 모델을 따른다. 즉, **선택된 워프 안의 모든 스레드는 동일한 명령을 동시에 실행**한다. 단, 각 스레드는 서로 다른 데이터를 처리하므로 병렬 계산이 이루어진다.

만약 실행 중인 워프가 메모리 접근 등으로 인해 **스톨(stall)** 상태에 빠지면 어떻게 될까? GPU는 CPU와 다르게 워프 전환에 비용이 거의 없기 때문에, SM은 즉시 다른 준비된 워프를 선택해 실행한다. 이렇게 함으로써 **메모리 지연(latency)** 을 효과적으로 숨기고 전체 GPU 연산 효율을 극대화한다.

---
## Barrier Synchronization

![](../../images/Pasted%20image%2020251203220106.png)

`__syncthreads()` 는 **같은 블록에 속한 모든 스레드가 이 지점에 도달할 때까지 기다리게 하는 동기화 함수**이다. 블록 내 스레드들이 모두 `__syncthreads()`를 호출해야만 그 다음 코드로 진행할 수 있다. 따라서 어느 하나라도 먼저 지나가거나, 일부만 호출하는 상황은 허용되지 않는다.

이 함수는 주로 **타일 기반(tile-based) 알고리즘**에서 사용된다. 예를 들어 공유 메모리(shared memory)에 데이터를 블록 단위로 로드할 때, 모든 스레드가 해당 타일을 다 채웠는지 확인해야 안전하게 연산을 이어갈 수 있다. 즉,

> _“타일 전체가 제대로 로드되었는지, 모두가 준비되었는지 확인하는 ‘합류 지점(barrier)’ 역할”_  
> 을 수행하는 셈이다.

`__syncthreads()`는 조건문(if-then-else) 안에서도 사용할 수는 있다. 하지만 **해당 조건이 블록 전체의 스레드에게 동일하게 평가되는 경우에만** 의미가 있다. 만약 어떤 스레드는 `if` 블록 안에서 `__syncthreads()`를 실행하고, 다른 스레드는 조건이 false라서 실행하지 않는다면 블록이 서로 기다리다가 영원히 멈추는 상황(hang)이 발생할 수 있다. 혹은 예상치 못한 부작용이 나타날 수도 있다.

