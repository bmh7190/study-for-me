기존 방식에서는 캐시(cache)가 있긴 했지만, 우리가 직접 “이 데이터를 캐시에 넣어두자”라고 관리할 수 있는 구조는 아니었다. 캐시는 하드웨어가 알아서 관리하는 영역이라, **재사용 가능한 데이터가 있어도, 그걸 얼마나 잘 활용할지는 GPU와 캐시 정책에 달려 있고, 프로그래머가 세밀하게 통제하기는 어렵다.**

그래서 CUDA에서는 **사용자가 직접 관리할 수 있는 빠른 메모리 영역**을 하나 더 제공하는데, 그게 바로 **shared memory**다. 이건 캐시와는 느낌이 조금 다르다. 캐시는 “하드웨어가 자동으로 쓰는 고속 버퍼”라면, shared memory는 **프로그래머가 직접 선언하고, 직접 읽고 쓰고, 직접 재사용 패턴을 설계하는 메모리**다.

![](../../images/Pasted%20image%2020251204134901.png)

shared memory는 **global memory까지 가지 않고 블록 내부에서만 데이터를 돌려 쓸 수 있기 때문에 훨씬 빠르다.** 다만 “레지스터처럼 공짜”는 아니고, 어디까지나 메모리이기 때문에 용량도 제한적이고, 잘못 쓰면 충돌(bank conflict)도 날 수 있다. GPU 쪽에서는 보통 **shared memory**라고 부르지만, 조금 더 일반적인 용어로는 **scratchpad memory**라고도 부른다. 말 그대로 프로그래머가 직접 쓰는 “작업용 임시 메모리”인 셈이다.

![](../../images/Pasted%20image%2020251204134934.png)

shared memory의 사용 방법은 매우 단순하다. 커널 내부에서 변수를 선언할 때 앞에 `__shared__` 키워드만 붙여 주면 된다. 예를 들어 공분산 계산처럼 두 개의 타일(tile)을 캐시에 올려놓고 여러 스레드가 재사용해야 하는 경우, 다음과 같이 2차원 배열 형태의 shared memory를 선언할 수 있다.

```c
__shared__ value_t cache_x[chunk_size][chunk_size]; __shared__ value_t cache_y[chunk_size][chunk_size];
```

이렇게 선언된 `cache_x`와 `cache_y`는 **블록 내부의 모든 스레드가 함께 접근하고 재사용할 수 있는 고속 메모리 공간**이 된다. global memory에서 동일한 데이터를 반복해서 불러오는 대신, 한 번 shared memory로 가져와 여러 스레드가 공동으로 쓰기 때문에 메모리 대역폭을 크게 절약할 수 있고 연산 속도도 훨씬 빨라진다.

---
기존의 Covriance matrix를 생각해보면 2475 * 200000개의 이미지를 나타내는 행렬을 서로 곱해서 나타내게 되는데, 이때 결과물은 2475 2475 사이즈 일 것인데, 예를 들어서 J~J+7 까지 j ~j+7 까지의 하나의 공간을 나타내기 위해서는 오른쪽 그림과 같이 각각 8개 씩 들어가게 된다. 그래서 서로 곱해주기 때문에 총 64가지의 경우가 생기는데, 이때 동일한 데이터를 쓰는 경우가 발생하는데 이 점을 최적화 할 수 있다. 왼족 그림의 경우에는 global 메모리에 존재하는데, shared memory의 경우 크기가 제한적이기 때문에 타일링 그니까 끊어서 shared memory에 넣고 연산하고를 반복하게 된다.

![](../../images/Pasted%20image%2020251204140448.png)
