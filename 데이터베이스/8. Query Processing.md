
## **Recap: Basic Query Structure**


일반적인 SQL의 쿼리는 다음과 같은 형태를 가진다. 

```sql
select A1, A2, ...,An from r1, r2, ..., rm where P
```

```sql
select name
from instructor
where dept_name = 'Comp. Sci.' and salary > 80000
```

• A<sub>i</sub> : 속성 
• R<sub>i</sub> : 릴레이션 
• P : 조건

SQL 쿼리의 결과는 릴레이션이다.

---
## **Basic Steps in Query Processing**

![](../images/Pasted%20image%2020250604223917.png)

---
## **Basic Steps: Optimization**

**쿼리 최적화(Query Optimization)** 란, **같은 결과를 반환하는 여러 평가 계획(evaluation plans)** 중에서  
**비용(cost)** 이 가장 낮은 계획을 선택하는 과정을 말한다.

이때의 **비용**은 단순한 실행 시간뿐 아니라, **I/O 횟수, 중간 결과 크기, 메모리 사용량** 등을 포함할 수 있으며,  이는 **데이터베이스 카탈로그 에 저장된 통계 정보**를 기반으로 추정된다.  

> 예: 각 릴레이션에 포함된 **튜플 수**, 각 튜플의 **평균 크기**, 특정 속성의 **중복도(cardinality)** 등

---
## **Measures of Query Cost**

**쿼리 비용(cost)** 은 일반적으로 **쿼리 결과를 반환하는 데 걸리는 전체 시간**을 의미하며,  여러 요소들이 이 시간에 영향을 미친다. 대표적인 요소로는 **디스크 접근 횟수, CPU 사용량**, 그리고 분산 환경에서는 **네트워크 통신 비용** 등이 있다.

그중에서도 **디스크 접근은 일반적으로 가장 비용이 크며**,  성능을 분석하거나 최적화할 때 **핵심 요소로 간주**된다.

쿼리 수행 시 디스크 비용은 다음과 같이 추정할 수 있다:

`읽은 블록 수 × 평균 블록 읽기 비용`

`작성한 블록 수 × 평균 블록 쓰기 비용`

여기서 **블록을 쓰는 비용은 읽는 비용보다 크다.**  이는 **데이터를 성공적으로 썼는지 확인하기 위해 쓰기 이후 검증(read-after-write)** 이 필요한 경우가 많기 때문이다.

---

일부 알고리즘은 **버퍼 메모리(buffer memory)** 를 적극 활용해  **디스크 I/O를 줄일 수 있다.**

그러나 실제로 사용 가능한 버퍼 메모리 양은  **동시에 실행 중인 다른 쿼리나 운영체제 프로세스 상황에 따라 달라지며**,  이 값은 실행 시점이 되어야만 정확히 알 수 있다.

이 때문에 일반적으로는 **최악의 경우(worst-case)를 가정하여**,  **연산에 필요한 최소 메모리만 사용 가능한 상황을 기준으로 비용을 추정**한다.

또한, **필요한 데이터가 이미 버퍼에 존재하는 경우**,  해당 데이터는 **디스크에서 다시 읽을 필요 없이 바로 접근 가능**하므로 추가 I/O 비용이 발생하지 않게 된다.

---
## **Recap: I/O complexity model**

간단히 말해서, **쿼리 비용은 디스크에서 전달되는 블록의 수를 기준으로 측정한다고 보면 된다.**

> [!note] 정리
> - **M** : 메모리 크기, 즉 **메인 메모리에 적재 가능한 튜플 수**
>     
> - **B** : 블록 크기, 즉 **한 블록에 저장 가능한 튜플 수**
>     
> - **N** : 릴레이션에 존재하는 전체 튜플 수

이때 디스크 I/O 비용은 다음과 같이 근사할 수 있다:

- **Linear I/O** : $\left( \frac{N}{B} \right)$  → 릴레이션 전체를 한 번 스캔할 때 필요한 **블록 수**
    
- **Logarithmic I/O** : $O\left( \log_B N \right)O(logB​N)$ → 인덱스(B-tree 등)를 사용하여 **검색할 때 필요한 I/O 수**
    

실제로는 디스크 **탐색 비용(seek cost)**이나 **CPU 연산 비용**도 고려해야 하지만,  이론적인 분석에서는 보통 단순화를 위해 **이러한 비용은 무시**한다.  다만, **현실의 DBMS는 CPU 비용도 실제로는 함께 고려**한다.

---
## **Selection Operation**

### 1️⃣ File Scan – Linear Search (Algorithm A1)

**Algorithm A1: Linear Search**는 가장 단순한 파일 검색 방법으로,  **파일의 모든 블록을 순차적으로 스캔하며 각 레코드를 검사**하여 선택 조건을 만족하는지를 확인한다.

**I/O 비용**은 명확히 $O(N/B)$,  즉 전체 N개의 튜플을 B개씩 나눈 **블록 수만큼의 디스크 접근**이 필요하다.

이 방식은 다음과 같은 조건에 **관계없이 항상 적용 가능**하다:

- 선택 조건의 형태와 관계없이
    
- 파일 내 레코드의 정렬 여부와 무관하게
    
- 인덱스의 존재 여부와 상관없이

즉, 인덱스가 없거나 조건이 복잡해도 항상 사용할 수 있는 **기본 전략**이다.

#### 대용량 메모리가 있는 경우 (M > N)

메모리 크기 M이 전체 튜플 수 N보다 크다고 하더라도,  **레코드를 메모리에 적재하려면 여전히 모든 블록을 한 번은 디스크에서 읽어야 하므로**,  **최소한 N/B번의 디스크 I/O는 발생**한다.

즉, **메모리가 충분하다고 해도 디스크에서 데이터를 읽는 최소 비용은 피할 수 없다.**

---
### 2️⃣ Index Scan 

인덱스를 이용한 검색에서는 **selection condition이 반드시 인덱스의 search-key에 대해 주어져야** 한다.

##### **A2. Primary B+ Tree Index + Equality on Key (정확히 하나의 레코드 검색)**

- **조건**: 검색 조건이 **기본(primary) B+ 트리 인덱스의 키(key)** 에 대한 **정확한 등치 조건(equality condition)**일 때

- 예시: `WHERE id = 12345` (id가 기본 키인 경우)

- **정확히 하나의 레코드만 검색됨 (Exact match search)**

- **I/O 비용**: $O(log⁡BO(\log_B N)$ (트리 높이만큼 블록 접근)

#### **A3. Primary B+ Tree Index + Equality on Non-Key (중복 키 검색)**

- **조건**: 검색 조건이 **primary B+ 트리 인덱스의 non-key 속성**에 대한 **등치 조건**일 때

- 예시: `WHERE dept_name = 'Finance'` (중복 가능)

- 이 경우, **여러 개의 레코드가 같은 키 값을 가질 수 있음**

- T: 해당 키 값을 가지는 레코드 수라고 하면,

- **I/O 비용** : $O(\log_B N + T/B)$ → 트리 탐색 비용 + T개의 레코드를 블록 단위로 읽는 비용

#### **A4. Secondary Index + Equality on Non-Key**

보조 인덱스를 사용하는 경우, 검색 조건이 **기본(primary key)이 아닌 속성**에 대해 주어지며, 이 속성은 **보조 인덱스(secondary index)** 에 존재한다.

##### 1. Search-key가 후보 키인 경우 (즉, 유일함)

- 예시: `WHERE email = 'abc@xyz.com'` (email이 후보 키라고 가정)

- **하나의 레코드만 검색**

- **I/O 비용** : $O(\log_B N)$ → 보조 인덱스를 탐색하여 해당 레코드로 직접 접근

##### 2. Search-key가 후보 키가 아닌 경우 (즉, 중복값 존재)

- 예시: `WHERE dept_name = 'Finance'` (여러 명이 Finance 소속일 수 있음)

- **T개의 레코드가 같은 키 값을 가질 수 있고**,  이들 각각이 **서로 다른 블록에 위치**할 수 있음

- 따라서 블록을 하나씩 접근해야 하므로

- **I/O 비용** : $O(\log_B N + T)$ → 인덱스 탐색 비용 + T개의 블록을 각각 접근하는 비용


> 이 경우 비용이 상당히 비쌀 수 있다. (최악의 경우 T개의 I/O가 발생)

---
## **Selections Involving Comparisons**

 linear file scan 또는 다음과 같은 방법으로 index들을 이용해서 $\sigma_{A \geq v}(r)\text{ or }\sigma_{A \leq v}(r)$ 의 형태로 구현할 수 있다.
 
#### **A5 – Primary Index + Comparison** **(릴레이션이 A에 대해 정렬되어 있는 경우)**

- $\sigma_{A \geq v}(r)$:  인덱스를 사용해 **A ≥ v인 첫 튜플**을 찾고, 이후 **파일을 순차적으로 스캔**하여 조건을 만족하는 모든 레코드를 반환.  **효율적**이다. → $O(\log_B N + T/B)$

- $\sigma_{A \leq v}(r)$:  인덱스를 사용하지 않고, **처음부터 파일을 순차적으로 읽다가 A > v이면 중단**.  정렬을 활용한 빠른 중단 가능하다. → $O(T/B)$


#### **A6 – Secondary Index + Comparison** **(릴레이션이 A로 정렬되어 있지 않음)**

- $\sigma_{A \geq v}(r)$:  인덱스를 사용해 **A ≥ v인 첫 인덱스 엔트리**를 찾고,  **인덱스 리프를 오른쪽으로 순차 스캔**하여 포인터들을 수집한 후, 해당 레코드를 디스크에서 개별적으로 접근 → $O(\log_B N + T)$

- $\sigma_{A \leq v}(r)$:  인덱스 리프를 왼쪽부터 읽으며 **A ≤ v인 포인터**들을 수집하고,  해당 레코드를 하나씩 디스크에서 읽는다. 포인터가 가리키는 레코드들이 **디스크 곳곳에 흩어져 있기 때문에**,  **레코드 하나마다 랜덤 디스크 I/O**가 발생한다. → 비용: $O(\log_B N + T)$, T는 조건을 만족하는 레코드 수


> [!note] 왜 Linear Scan이 더 저렴할 수 있는가?
> **Linear Scan은 순차 I/O**를 수행하므로 디스크의 물리적 움직임(Seek Time)이 거의 없다. 반면 **Secondary Index 기반 검색은 레코드마다 랜덤 I/O**가 발생하기 때문에,  **T가 크면 클수록 오히려 느려질 수 있다.**


---
## **Sorting**

> 왜 릴레이션을 정렬하는가?

관계형 연산, 특히 **조인(Join)**이나 **집계(Aggregation)** 같은 연산은 **입력 릴레이션이 정렬되어 있을 때 성능이 훨씬 향상**되는 경우가 많다.  정렬된 상태는 탐색, 비교, 병합 등을 빠르게 수행할 수 있는 구조적 이점을 제공한다.

> 그럼 인덱스만 만들면 안 될까?

단순히 정렬 키에 대한 **보조 인덱스(secondary index)** 만 구축하는 것은 한계가 있다.  왜냐하면, 인덱스는 정렬된 **키 순서로 포인터를 제공**할 수는 있어도,  릴레이션 자체가 **디스크 상에서 정렬되어 있지 않다면**,  
여전히 **랜덤 I/O**가 빈번하게 발생한다.  즉, **정렬된 순서로 레코드에 "지역적으로" 접근할 수는 있어도**,  
**물리적 순차 I/O의 장점은 누리지 못한다**.

> 메모리에 다 올라가는 경우 (M > N)는?

만약 릴레이션 전체가 메모리에 적재 가능하다면,  **퀵 정렬(Quick Sort)**과 같은 **효율적인 내부 정렬 알고리즘**을 사용할 수 있다.

하지만 일반적으로 대규모 데이터는 메모리를 초과하므로,  이 경우에는 **외부 병합 정렬(External Merge Sort)** 이 가장 적절한 방법이다.  외부 정렬은 블록 단위로 데이터를 처리하며, **디스크 I/O를 최소화**할 수 있도록 설계된 알고리즘이다.

----
## **External Merge Sort**

우선 M은 메인 메모리의 크기를 말하고, B는 블록의 크기를 나타낸다. 따라서 M/B는 "**한 번에 메모리에 올릴 수 있는 블록의 개수**"를 의미한다.  즉, **메모리 내에서 동시에 처리할 수 있는 블록 수**라고 보면 된다.

##### 1. 정렬된 임시파일(runs) 생성하기
외부 정렬에서 첫 번째 단계는 **입력 릴레이션을 메모리에 적재 가능한 만큼씩 나눠서 정렬**하고,  
**정렬된 결과를 디스크에 임시 파일(run)로 저장**하는 것이다.

우선 i를 0으로 초기화 한다. 그리고 릴레이션의 끝에 도달하기 까지 다음 과정을 반복한다. 

릴레이션의 M/B block을 읽어서 메모리에 적재한다. 메모리에 들어간 블록들은 내부 알고리즘에 의해서 정렬된다. 그다음 정렬된 데이터를 디스크에 run R<sub>i</sub> 로  저장하고, i를 1더한다.

최종적으로 i = N개의 정렬된 run이 생성된다. 

---

릴레이션 전체를 한 번에 정렬할 수 없기 때문에, 우리는 **메인 메모리에 올릴 수 있는 블록 수인 M/B** 블록 단위로 나누어, 각각을 메모리 내에서 정렬한 후 디스크에 임시로 저장한다. 이렇게 정렬되어 저장되는 단위는, **메인 메모리에서 처리된 그대로 디스크에 쓰이기 때문에**,  결국 전체 릴레이션을 MMM 단위로 나누는 것과 같다고 볼 수 있다.

>즉, 전체 튜플 수가 N일 때,  이렇게 생성되는 정렬된 조각(run)의 수는 $⌈N/M⌉$개가 되고,  이 수를 우리는 **K**라고 정의한다.
##### 2. 임시 파일 병합하기
생성된 K개의 정렬된 run을 하나로 병합하기 위해, **메모리 내에서 K개의 블록을 각 입력 run의 버퍼로 할당**하고,  **추가로 1개의 블록은 병합 결과를 저장할 출력 버퍼로 사용**한다.

먼저 각 run의 **첫 번째 블록을 해당 입력 버퍼 페이지에 적재**한다.  그다음, 모든 run이 완전히 병합될 때까지 다음 과정을 반복한다.

1. **모든 입력 버퍼 페이지를 검사하여**, 정렬 기준에 따라 가장 작은 레코드를 선택한다.
    
2. 선택된 레코드는 **출력 버퍼에 기록**된다.
    
3. 출력 버퍼가 **가득 차면**, 현재까지 기록된 내용을 디스크에 저장하고 출력 버퍼를 비운다.
    
4. 선택된 레코드는 그것이 위치했던 **입력 버퍼에서 제거**된다.
    
5. 만약 해당 입력 버퍼가 **비게 되면**, 그 run에 **남아 있는 블록이 있다면** 다음 블록을 읽어와 버퍼를 채운다.
    

이 과정을 반복하여, **모든 입력 버퍼가 완전히 소진되면 병합이 완료**된다.

---

만약 정렬된 run의 개수 K가 M/B 이상이라면, **한 번의 병합으로 모든 run을 처리할 수 없으므로 여러 번의 병합 패스(merge pass)** 가 필요하다.

이 경우, **각 패스에서는 인접한 $M/B$−1개의 run을 그룹으로 묶어 병합**을 수행한다.  즉, 한 번의 패스에서 **run의 개수는 M/B−1만큼 감소** 하고, **각 run의 길이는 그만큼 증가**한다.

예를 들어, M/B=11M/B = 11M/B=11인 경우 한 번의 패스에서 **11 - 1 = 10개의 run**을 하나로 병합할 수 있으며,  만약 초기 run이 90개였다면, 병합 후에는 **9개의 run**만 남게 되고,  각 run은 **초기 run보다 10배 더 길어진다.** 이러한 병합 패스를 **모든 run이 하나로 통합될 때까지 반복**하게 된다. 결국, 전체 외부 정렬은 여러 병합 단계를 거쳐 하나의 완전 정렬된 결과를 만들어낸다.

![](../images/Pasted%20image%2020250606023611.png)

---
##### 최악의 경우 분석

![](../images/Pasted%20image%2020250606030159.png)

전체 외부 정렬의 총 I/O 비용은 $O((N/B) \cdot \log_{M/B}(N/M)-N/B)**$
