
---
## **Basic Concepts**

인덱싱 메커니즘은 데이터베이스에서 **원하는 데이터를 빠르게 접근**할 수 있도록 도와주는 구조이다. 예를 들어, 도서관의 **저자 색인(author catalog)** 처럼, 사용자가 특정 속성 값을 기준으로 자료를 빠르게 찾을 수 있도록 한다.

여기서 인덱싱에 사용되는 속성을 **Search Key(검색 키)** 라고 하며, 이는 하나 이상의 속성들로 구성될 수 있다. 즉, 파일 내에서 원하는 레코드를 찾아보기 위한 기준이 되는 속성이다.

**인덱스 파일(index file)** 은 실제 데이터를 저장하는 파일과는 별도로 존재하며, 이 파일은 다음과 같은 형식의 레코드(인덱스 엔트리)를 포함한다:

![](../images/Pasted%20image%2020250529231930.png)

`(Search Key Value, Pointer to Actual Record)`

이러한 인덱스 파일은 **실제 데이터 파일보다 훨씬 크기가 작기 때문에**, 디스크 I/O를 줄이면서 빠른 검색을 가능하게 한다.

인덱스는 크게 **두 가지 기본 유형**으로 나눌 수 있다:

1. **Ordered Indices (정렬 인덱스)**  
    검색 키들이 **정렬된 순서**로 저장되어 있으며, 범위 검색이나 순차 탐색에 유리하다. 일반적으로 B+ Tree 같은 구조가 사용된다.
    
2. **Hash Indices (해시 인덱스)**  
    해시 함수를 이용해 검색 키를 **균등하게 여러 bucket에 분산**시킨다. 특정 값을 **정확하게 찾는 질의(=point query)** 에 매우 빠르지만, 정렬이나 범위 질의에는 적합하지 않다.
    
이러한 인덱스 메커니즘은 데이터 접근 성능을 크게 향상시켜 주며, 쿼리 처리 속도를 좌우하는 핵심 구성 요소 중 하나이다.

---
## **Ordered Indices**

**Ordered index**에서는 인덱스 엔트리들이 **검색 키(search key)** 값에 따라 **정렬된 순서로 저장**된다. 이는 예를 들어 **도서관의 저자 색인(author catalog)** 과 같이 특정 속성을 기준으로 데이터를 빠르게 탐색할 수 있도록 하는 구조이다.

---

##### ✅ Primary Index (기본 인덱스, Clustering Index)

- **Sequentially ordered file**(정렬된 파일)에서, 해당 파일의 **정렬 순서를 결정하는 속성**을 검색 키로 사용하는 인덱스를 **Primary Index**라고 한다.
    
- 예: 학번 순으로 정렬된 학생 레코드 파일에 대해 학번을 검색 키로 만든 인덱스
    
- **Clustering index**라고도 불리며, 이 인덱스는 보통 **검색 키 순서와 파일의 물리적 저장 순서가 일치**한다.
    
- **Primary key**를 사용할 때가 많지만, **반드시 primary key일 필요는 없다.**
    

---

##### ✅ Secondary Index (보조 인덱스, Non-Clustering Index)

- 파일의 정렬 순서와 **무관한 속성**을 검색 키로 사용하는 인덱스는 **Secondary Index**라고 한다.
    
- 예: 학번 순으로 정렬된 학생 파일에서 이름(name)을 기준으로 만든 인덱스
    
- **데이터 파일은 정렬되지 않았고**, 인덱스만 해당 속성 기준으로 정렬됨
    
- 따라서 **하나의 키 값이 여러 레코드와 매칭될 수 있으며**, 레코드들은 흩어져 있다
    

---

##### ✅ Index-Sequential File

- **정렬된 순서의 데이터 파일**과 그 위에 구축된 **Primary Index**가 함께 존재하는 구조
    
- 즉, **정렬된 데이터 파일 + Primary Index** = Index-Sequential File
    
- 이 구조는 범위 질의나 순차 탐색에 매우 효율적이다

---
## **Dense Index Files**

Dense Index는 데이터 파일은 모든 레코드마다 각각의 Search Key 값에 대해 인덱스 엔트리가 존재하는 인덱스를 나타낸다. 

![](../images/Pasted%20image%2020250530150848.png)
위의 예시에서 Search Key는 각 번호인데, 인덱스가 다 있다. 

`dept_name`에 대한 **dense index**는 instructor 파일이 `dept_name` 기준으로 정렬되어 있을 때, **동일한 `dept_name`에 해당 레코드를 가리키는 인덱스 엔트리가 존재**하는 구조이다.

![](../images/Pasted%20image%2020250530151237.png)

---
## **Sparse Index Files**

**Sparse index**는 **일부 검색 키 값에 대해서만 인덱스 레코드를 포함하는 구조**이다.  즉, 모든 레코드에 대해 인덱스를 유지하는 **dense index**와 달리, **간격을 두고 선택된 키 값만 인덱싱**한다.

이 방식은 파일이 **검색 키 기준으로 정렬되어 있는 경우**에만 적용 가능하다.  따라서 인덱스 엔트리가 없는 키 값을 찾기 위해서는 다음과 같은 절차를 따른다:

1. **검색 키 값 K보다 작은 값 중에서 가장 큰 인덱스 엔트리**를 찾는다.
    
2. 그 인덱스가 가리키는 레코드에서부터 **파일을 순차적으로 탐색**하여 K를 가진 레코드를 찾는다.

이 방식은 **인덱스 파일의 크기를 줄일 수 있는 장점**이 있지만, 검색 시에는 **일부 순차 탐색 비용**이 추가로 발생할 수 있다.

![](../images/Pasted%20image%2020250530151535.png)

**Sparse index**는 **dense index**에 비해 다음과 같은 장단점이 있다:

> [!note] Compared to dense indices
> - **장점**:
>     
>     - 인덱스 레코드 수가 적기 때문에 **공간을 덜 차지**한다.
>         
>     - 새로운 레코드 삽입이나 삭제 시, 인덱스를 갱신해야 할 일이 적어서 **유지 관리 비용이 낮다.**
>         
> - **단점**:
>     
>     - 모든 검색 키에 대한 인덱스가 존재하지 않기 때문에, **레코드를 찾는 데 dense index보다 느릴 수 있다.**
>         
>     - 검색 시 파일 내에서 **순차 탐색**이 필요한 경우가 많다.

---

##### ✅ 좋은 절충안: **"블록마다 하나의 인덱스 엔트리"를 두는 sparse index**

- 각 인덱스 엔트리가 **파일의 블록 하나를 대표**하며, 그 블록에서 **가장 작은 검색 키 값**을 가진 레코드를 가리킨다.
    
- 검색할 때는 인덱스를 통해 해당 블록의 시작 위치까지만 빠르게 찾아가고, 그 후에는 **해당 블록 내에서만 탐색**하면 되므로 디스크 접근 횟수가 매우 줄어든다.
    
- **공간은 sparse index 수준으로 절약**하면서, **검색 성능은 dense index와 유사**하게 유지할 수 있기 때문이다. 전체 파일을 탐색하는 것이 아니라, **단 한 블록만 순차 탐색**하면 되므로 성능 저하가 크지 않다.

![](../images/Pasted%20image%2020250530151928.png)
---
dense index : O(N/B) block
dense index와 레코드의 수와 항상 같을 필요는 없다! 중복 제거 가능? 
sparse index :  O (N/B<sup>2</sup>) block 
어차피 블록 단위로 접근하기 때문에 블록 당 하나의 레코드를 인덱싱한다면 효과적일 수도?

N data = 20000000
B data = 20 recordes a block 

N data / B data = 1M
B index = 100 entries in a block 

1 M entries = N index
N index / B index = 1000000 / 100 = 10000 inner index blocks 

10000/ 100 outer index blocks 

log(N/B) N/ 2^i = B



---

**Sparse index**는 일반적으로 **블록 단위**로 인덱싱하며, 하나의 인덱스 엔트리가 하나의 **블록 내 최소 검색 키 값**을 대표한다.

총 레코드 수가 N=20,000,000개이고, 한 블록에 들어가는 레코드 수 B<sub>data</sub>=20이라면,  
**전체 블록 수**는:

$$\frac{N}{B_{\text{data}}} = \frac{20,000,000}{20} = 1,000,000 \text{ (데이터 블록)}$$

이제 인덱스 구조를 위계적으로 설계할 수 있다:

##### ✅ 1단계 인덱스 (Level 1)

- 각 인덱스 블록에는 B<sub>index</sub>=100개의 인덱스 엔트리를 저장할 수 있다고 가정
    
- 1,000,000개의 데이터 블록을 인덱싱하려면:
    
$$\frac{1,000,000}{100} = 10,000 \text{ (1단계 인덱스 블록 수)}
$$
---

##### ✅ 2단계 인덱스 (Level 2)

- 위의 10,000개 1단계 인덱스 블록들을 인덱싱하기 위해 다시:
    
$$\frac{10,000}{100} = 100 \text{ (2단계 인덱스 블록 수)}$$

---

##### ✅ 3단계 인덱스 (최상위 루트)

- 최상위 인덱스 블록은 100개의 2단계 블록을 인덱싱하면 충분하므로, 1개의 블록으로 가능
    

---

전체 구조는 **3단계 인덱스 구조** 블록 단위 접근이 기본이므로, sparse index에서는 **"블록당 하나의 엔트리만 인덱싱"** 해도 효과적이다

**총 인덱스 블록 수**:
    
    - Level 1: 10,000
        
    - Level 2: 100
        
    - Level 3 (root): 1
        

따라서, 전체적으로 **로그 계층 구조**를 가지며, 이론적으로 인덱스를 통한 탐색 비용은:

$$log_{B_{\text{index}}} \left( \frac{N}{B_{\text{data}}} \right)
$$
즉, 위의 예에서는 약 log⁡<sub>100</sub>(1,000,000)=2, 즉 **세 번의 블록 접근으로 원하는 레코드에 도달 가능**하다.


----
## **Multilevel Index**

만약 **primary index** 자체가 메인 메모리에 들어가지 못할 정도로 크다면, 이를 디스크에서 접근해야 하므로 성능이 크게 저하될 수 있다.

이 문제를 해결하기 위해, **primary index 자체를 하나의 정렬된 파일(sequential file)** 로 간주하고, 그 위에 **sparse index**를 추가로 구축하는 방식이 사용된다.

![](../images/Pasted%20image%2020250530153351.png)

> [!note] 용어 정리
> - **Inner index**: 디스크에 저장된 **primary index 파일** (search-key 순으로 정렬된 인덱스)
>     
> - **Outer index**: inner index 위에 만들어진 **sparse index** (primary index의 일부만 인덱싱)


이렇게 하면 검색 시 outer index를 먼저 탐색하고, 해당 엔트리가 가리키는 위치부터 inner index를 순차적으로 탐색함으로써 전체 접근 비용을 줄일 수 있다.

만약 **outer index조차도 메모리에 적재할 수 없을 정도로 클 경우**, 또 하나의 상위 인덱스를 만들 수 있다. 이렇게 인덱스를 **계층적(multi-level index)** 으로 구성하면, 탐색 성능은 유지하면서 메모리 요구는 줄일 수 있다.

단, 이러한 계층적 인덱스 구조에서는 **데이터 파일에 삽입 또는 삭제가 발생할 때, 모든 인덱스 레벨에 대한 갱신이 필요**하다. 즉, inner index뿐 아니라 outer index, 그보다 더 상위 레벨 인덱스까지도 **정합성을 유지하도록 동기화되어야 한다.**

---
## **Index Update : Deletion**

만약 삭제된 레코드가 해당 **검색 키 값(search-key value)** 을 가진 **유일한 레코드**였다면, 그 검색 키는 더 이상 파일 내에 존재하지 않게 된다.

따라서, 인덱스의 관점에서도 **그 검색 키에 해당하는 인덱스 엔트리 역시 삭제되어야** 한다.

**단일 수준 인덱스(single-level index)** 에서의 인덱스 항목 삭제 방식은 인덱스의 종류에 따라 다르게 처리된다.

##### ✅ Dense Index의 경우

Dense index는 **모든 레코드의 검색 키 값마다 인덱스 엔트리를 가지므로**,  레코드를 삭제하면 **해당 검색 키 값에 대응하는 인덱스 엔트리도 단순히 삭제**하면 된다.  즉, **파일에서 레코드를 지우는 것과 동일한 방식으로 인덱스에서도 처리**된다.

##### ✅ Sparse Index의 경우

Sparse index는 **일부 검색 키 값만 인덱싱**되기 때문에 삭제 시 좀 더 조심스럽게 처리해야 한다.

만약 인덱스에 해당 검색 키 ***K***의 엔트리가 있다면,  삭제 시 해당 인덱스 엔트리는 **다음 검색 키 값 ***K'*** 으로 **대체**된다.  이때 ***K′*** 는 파일 내에서 ***K*** 다음으로 등장하는 검색 키 값이다.
    
그러나 만약  ***K′*** **에 해당하는 인덱스 엔트리가 이미 존재**한다면,  중복된 인덱스 엔트리를 만들지 않기 위해, **단순히 K의 인덱스 엔트리를 삭제**한다.

---
## **Index Update: Insertion**

**단일 수준 인덱스(single-level index)** 에서의 삽입은 레코드의 **search-key 값을 기반으로 인덱스를 갱신**하는 방식이며, 인덱스 유형에 따라 처리 방식이 다르다.

##### ✅ Dense Index에서의 삽입

- 새로운 레코드를 삽입할 때, 그 레코드의 **search-key 값이 인덱스에 존재하지 않는다면**, **해당 search-key 값과 레코드 위치를 인덱스에 추가**해야 한다.
    
- 이미 존재하는 search-key 값이라면, 별도로 인덱스를 수정할 필요는 없다.  
    (Dense index는 동일한 키 값에 여러 레코드가 있을 수 있음)


##### ✅ Sparse Index에서의 삽입

- Sparse index는 일반적으로 **파일의 블록마다 하나의 인덱스 엔트리**를 갖는다.
    
- 따라서 **기존 블록에 삽입되는 경우에는 인덱스를 수정할 필요가 없다.**
    
- 하지만 **새로운 블록이 생성되는 경우**, 해당 블록에 저장된 레코드들 중 **가장 첫 번째 search-key 값**을 인덱스에 **새로운 엔트리로 추가**해야 한다.

##### ✅ 다단계 인덱스(Multilevel Index)의 삽입 및 삭제

- 다단계 인덱스의 삽입과 삭제는 위에서 설명한 **단일 수준 알고리즘을 계층적으로 적용**하면 된다.
    
- 하위 레벨(예: inner index)에 변동이 생기면, 그로 인해 **상위 레벨(outer index)** 에서도 엔트리의 삽입 또는 삭제가 발생할 수 있으며,
    
- 최종적으로는 **루트 인덱스까지 갱신될 수 있다.**

---
## **Secondary Indices**

종종, 사용자는 **primary index의 검색 키가 아닌 필드에 대해 조건을 만족하는 모든 레코드**를 찾고 싶어 하는 경우가 있다.

 > [!note] Example
> **예시 1**: `instructor` 릴레이션이 **ID 기준으로 정렬되어 저장되어** 있다고 가정할 때, 우리는 특정 **학과(dept_name)**에 소속된 모든 강사를 찾고 싶을 수 있다. 하지만 `dept_name`은 primary index의 키가 아니므로, ID 순 정렬만으로는 효율적인 검색이 어렵다.
>     
> **예시 2**: 비슷하게, 특정 **급여(salary)**를 가진 강사들이나, **특정 급여 범위 내에 속한 강사들**을 찾고자 할 수도 있다. 이 역시 `salary`가 primary search-key가 아닌 이상, 정렬 기반 탐색으로는 비효율적이다.
>     


이러한 경우에는 해당 필드(예: `dept_name`, `salary`)를 검색 키로 하는 **secondary index(보조 인덱스)** 를 만들어 사용할 수 있다.

**Secondary index**는 기본 파일의 정렬 순서와는 무관하게, 원하는 검색 키에 대한 **별도의 인덱스를 구축**하여 레코드 접근을 빠르게 만들어 준다.  각 인덱스 엔트리는 해당 **검색 키 값과, 그것에 대응하는 레코드(또는 레코드들의 위치)에 대한 포인터**를 포함한다.

![](../images/Pasted%20image%2020250530154819.png)

보조 인덱스(secondary index)에서는 **하나의 인덱스 레코드가 버킷(bucket)을 가리키고**,  그 버킷 안에는 해당 **search-key 값을 가진 모든 실제 레코드들의 포인터들이 저장**된다. 이는 search-key 값 하나에 대해 **여러 개의 레코드가 존재할 수 있기 때문**이다.  

예를 들어, `dept_name = 'Comp. Sci.'`인 강사가 여러 명 있을 경우, 그 키 값을 가진 인덱스 레코드는  모든 관련 레코드를 참조해야 하므로, **포인터 리스트(버킷)** 가 필요하다.

이러한 이유로, **Secondary 인덱스는 항상 dense index여야 한다.**  즉, **모든 검색 키 값마다 인덱스 엔트리가 반드시 존재**해야 한다.  왜냐하면 데이터 파일 자체는 해당 키 기준으로 정렬되어 있지 않기 때문에,  **인덱스를 통해 직접 모든 관련 레코드에 접근할 수 있어야 하기 때문**이다.

---
## **Primary and Secondary Indices**

인덱스는 **레코드 검색을 빠르게 수행할 수 있는 강력한 도구**로, 특히 대규모 데이터셋에서 그 효과가 매우 크다.

하지만 인덱스는 **유지 관리 비용**이 따른다.  데이터 파일이 수정될 때(삽입, 삭제, 갱신), **해당 파일 위에 존재하는 모든 인덱스도 함께 갱신되어야** 한다. 이로 인해 **쓰기 작업의 부하(write overhead)** 가 증가한다.

또한, 검색 방식에 따라 효율성에도 차이가 있다 **Primary index를 이용한 순차 스캔(sequential scan)** 은 데이터가 인덱스 순서대로 저장되어 있기 때문에, **디스크 블록이 연속적으로 로드되어 디스크 I/O가 최소화**된다. 매우 효율적인 접근 방식이다.
    
반면, **Secondary index를 이용한 순차 스캔**은 데이터가 물리적으로 흩어져 있기 때문에, **각 레코드 접근 시마다 다른 블록을 디스크에서 읽어야 할 수 있다.** 이 경우, **레코드 하나마다 디스크 I/O가 발생할 수 있어 매우 비효율적**이다.

디스크 블록 접근은 일반적으로 **5~10 밀리초(ms)** 가 걸리는 반면, 메인 메모리 접근은 **약 100 나노초(ns)** 정도에 불과하다.  즉, 디스크 접근은 **메모리보다 약 50,000 ~ 100,000배 느리다.**

따라서 인덱스는 매우 유용하지만, 그 **관리 비용과 접근 패턴에 따른 성능 특성**을 잘 이해하고 **적절한 상황에서 선택적으로 활용하는 것**이 중요하다.

---
## **B<sup>+</sup> - Tree Index Files**

**B+ 트리 인덱스(B+ tree indices)** 는 **인덱스 순차 파일(indexed-sequential files)** 에 대한 효과적인 대안이다.
##### ✅ Indexed-Sequential Files의 단점

- 파일이 커지면서 **오버플로우 블록(overflow blocks)** 이 많이 생기면 성능이 저하된다.
    
- 이를 해결하기 위해 **주기적인 전체 파일 재조직(reorganization)** 이 필요하다. 비용이 크고, 운영 중에 성능 저하가 발생할 수 있다.

##### ✅ B+ 트리 인덱스의 장점

- 삽입/삭제 시 **소규모의 국소적인(local) 구조 변경만으로 자동 정리**가 이루어진다. 전체 파일을 재조직할 필요 없이 **지속적으로 균형을 유지**
    
- **균형 잡힌 트리 구조**로 항상 일정한 검색 성능 보장
    
- 범위 질의(range query)나 순차 스캔에도 매우 효율적

---
##### ⚠️ (경미한) 단점

- 삽입/삭제 시 **약간의 오버헤드** 발생  트리 노드 분할(split) 또는 병합(merge)에 따른 비용
    
- **공간 오버헤드** 존재  : 인덱스 노드에 포인터, 중복 키 저장 등이 필요

![](../images/Pasted%20image%2020250530155639.png)

B+ 트리는 이러한 단점을 감수할 만큼 장점이 크며, **높은 성능과 안정성**을 제공하며, **대부분의 상용 데이터베이스 시스템에서 광범위하게 사용**되고 있다.

---

## **Observations about B+ Tree**

>내부 노드들의 연결은 포인터로 연결되어 있어서, 논리적으로 Block들이 물리적으로 가까울 필요는 없다. 

즉, 실제로 옆에 딱 붙어 있지 않아도 되고, 그냥 포인터로 연결하면 그만이라는 뜻이다.


>**B+ 트리에서는 리프 노드가 모든 키 값을 포함하는 dense index 구조를 가지며, 리프가 아닌 내부 노드들은 일부 키 값만 포함하는 sparse index 형태를 따른다.**  

이는 B+ 트리의 계층적 인덱스 구조 때문인데, 리프 노드는 실제 데이터 레코드에 대한 포인터를 가지며 모든 search key 값이 정렬된 상태로 저장된다. 따라서 각 레코드에 대응되는 키가 모두 존재하므로 dense index의 특성을 가진다.

반면, 리프가 아닌 내부 노드들은 하위 노드들을 탐색하기 위한 **경계값(guide key)** 역할을 하는 일부 key 값만 저장한다. 이들은 전체 키 집합을 대표할 수 있는 소수의 키만 포함하고, 나머지 키들은 하위 노드로 내려가야 접근할 수 있다. 이런 특성 때문에 내부 노드는 **sparse index**, 즉 일부 키만 선택적으로 포함하는 인덱스로 볼 수 있다.


>B+ tree는 상대적으로 낮은 수의 level 만으로 많은 데이터를 효율적으로 관리할 수 있다.

예를 들어, 각 노드가 최대 **B**개의 자식 노드를 가질 수 있다고 하면, 각 노드는 적어도 ⌈B/2⌉개의 자식을 가져야 하므로 **최소 fan-out은 ⌈B/2⌉** 라고 하자. 

- **루트 바로 아래 레벨(1단계 하위)** 는 최소한 `2 × ⌈B/2⌉`개의 리프 노드를 자식으로 가진다. (루트가 최소 2개의 자식을 가져야 하고, 그 각각의 최소 값은  ⌈B/2⌉이기 때문이다. )
    
- **그다음 레벨(2단계 하위)** 는 그 수의 각 자식이 다시 최소 `⌈B/2⌉`개의 자식을 갖기 때문에, 전체적으로 최소  `2 × ⌈B/2⌉ × ⌈B/2⌉ = 2 × (⌈B/2⌉)^2` 개의 리프 노드를 포함하게 된다.

이와 같이 하위로 갈수록 최소 노드 수는 지수적으로 증가하므로, **상대적으로 적은 높이(height)**만으로도 매우 많은 수의 레코드를 저장할 수 있다.



>**메인 파일에 대한 삽입과 삭제 연산은 인덱스가 로그 시간(logarithmic time)에 재구성되므로, 효율적으로 처리될 수 있다.**  

B+ 트리와 같은 균형 잡힌 인덱스 구조에서는 노드의 삽입이나 삭제가 발생해도 트리의 높이가 크게 변하지 않으며, 필요시 노드 분할(split)이나 병합(merge)을 통해 구조를 유지한다. 이로 인해 인덱스 재구성 비용은 트리의 높이에 비례하여 **O(log n)** 시간에 수행되며, 결과적으로 메인 파일(데이터 파일)과의 연결을 효율적으로 유지할 수 있다.

---
## **Queries on B+ Trees**


> [!note]
> 
> - **K<sub>i</sub>**: 현재 노드의 i번째 key 값
>     
> - **P<sub>i</sub>**: i번째 포인터 (보통 key 앞에 있음),  
>     
> - 내부 노드에서는 V와 비교하며 하위 노드로 이동함.
>     
> - 리프 노드에 도달하면, 실제 key 값이 존재하는지 확인하고 포인터를 따라 레코드에 접근.


##### 1. 초기화

```
C := root  // 현재 노드를 루트로 설정
```

##### 2. 리프 노드가 아닐 동안 반복

```c
While C is not a leaf node:
    ① Let i be the least index such that V ≤ Ki
    ② If such i does not exist:
          set C := last non-null pointer in C //
    ③ Else:
          if V == Ki: //맞다면 
              set C := Pi+1
          else:
              set C := Pi
```

##### 3. 리프 노드에서 값 찾기

```
Let i be the least index such that Ki == V
```

##### 4. 결과 반환

```
If such i exists:
    follow pointer Pi to the corresponding record
Else:
    no record with search-key value V exists
```

---
B+ 트리에서 검색 연산이 효율적인 이유는 fan-out, 즉 하나의 노드가 가질 수 있는 자식 노드의 수가 매우 크기 때문이다. 일반적으로 B+ 트리의 노드 크기는 디스크 블록 크기와 동일하게 설계되며, 디스크 블록은 보통 4KB 정도이다. 하나의 인덱스 항목(키와 포인터 쌍)의 크기를 약 40바이트로 가정하면, 하나의 노드에는 약 100개의 인덱스 항목을 저장할 수 있다. 이때 B=100이라고 할 수 있으며, 트리의 fan-out 역시 약 100이다.

B+ 트리는 각 노드가 최소 ⌈B/2⌉개의 자식을 가져야 한다는 조건을 만족해야 하므로, 최악의 경우에도 트리의 높이는 log base ⌈B/2⌉ of N 이하가 된다. 

>즉, N개의 search-key 값이 존재할 때 트리의 최대 높이는 ⌈log⌈B/2⌉(N)⌉로 제한된다.

> [!example] 예시
> 예를 들어, N = 1,000,000 (백만 개의 search-key 값)이 있고 B = 100인 경우를 생각해보면, 최소 fan-out은 ⌈100/2⌉ = 50이 된다. 이 경우 트리의 최대 높이는 log50(1,000,000)으로 근사되며, 이는 약 3.3 정도이고, 올림을 취해 최대 4단계의 노드를 거치게 된다. 즉, 검색 시 루트 노드에서 시작하여 리프 노드에 도달하기까지 최대 4개의 노드를 탐색하게 된다.
> 

반면, 같은 조건에서 균형 잡힌 이진 탐색 트리(binary search tree)를 사용한다고 가정하면, 각 노드는 최대 2개의 자식 노드를 가질 수 있으므로 트리의 높이는 log2(1,000,000) ≈ 20이 된다. 이는 검색 시 최대 20개의 노드를 접근해야 함을 의미한다.

이 차이는 디스크 기반 시스템에서 매우 중요하다. 각 노드 접근은 디스크 I/O를 수반하며, 디스크에서 한 블록을 읽는 데 약 20밀리초 정도 소요된다고 가정하면, B+ 트리는 검색에 최대 4 × 20ms = 80ms가 걸리는 반면, 이진 탐색 트리는 최대 20 × 20ms = 400ms가 걸릴 수 있다. 따라서 노드 접근 수가 줄어든다는 것은 곧 디스크 I/O 횟수가 줄어든다는 의미이며, 이는 전체 시스템 성능에 매우 큰 영향을 준다.

---
## **Updates on B+ Tress Insertion**

먼저 삽입하고자 하는 **Search-Key 값이 포함된 리프 노드**를 찾는다.  
만약 해당 **Search-Key 값이 이미 리프 노드에 존재한다면**, 이는 중복 키로 간주되므로, **해당 Search-Key에 대응되는 파일(데이터 영역)에 레코드를 추가하고**, 필요할 경우 **기존 포인터를 따라 연결된 bucket(중복 레코드 리스트)** 에 **새 레코드를 연결한다**.

반면, **Search-Key 값이 리프 노드에 존재하지 않는 경우**,  메인 파일에 새로운 레코드를 추가하고, **새로운 Search-Key 항목을 리프 노드에 삽입해야 한다**. 이때 리프 노드에 공간이 충분하다면, 해당 Search-Key와 레코드를 가리키는 **포인터를 쌍으로 묶어 리프 노드에 추가한다**.

그러나 **리프 노드에 공간이 부족한 경우**, 노드를 분리(split)해야 한다.

##### ✅ Splitting a leaf node
리프 노드를 분할할 때는, 먼저 **삽입할 (Search-Key, Pointer) 쌍을 포함하여** 현재 리프 노드에 있는 모든 `(Search-Key, Pointer)` 쌍을 **정렬된 순서로 정렬**한다. 이때 총 쌍의 수는 B + 1개가 될 수 있다.

그 후, 정렬된 항목 중 **앞쪽 ⌈B/2⌉ 개의 쌍은 기존 노드에 남겨두고**, **나머지 절반은 새로운 리프 노드(p)** 에 저장한다. 새 노드는 기존 리프 노드와 같은 수준의 오른쪽에 위치하게 되며, 기존 노드와 새로운 노드는 서로 **포인터로 연결**된다 (leaf-level linked list 구조 유지).

그 다음 단계는, 새로운 리프 노드 p에 있는 쌍들 중에서 **가장 작은 search-key 값 k**를 찾고, **상위 부모 노드에 (k, p)에 대한 항목을 삽입한다**. 여기서 `k`는 새로운 노드를 구분하는 경계값으로 작용하며, 부모 노드에서는 `k` 이상인 값은 오른쪽 자식(p)으로 검색을 이어가게 된다.

하지만 **부모 노드가 이미 가득 차 있는 경우**, 부모 노드 역시 같은 방식으로 분할되어야 하며, 이 **분할은 재귀적으로 상위 노드로 전파**된다. 즉, 부모 노드도 쌍을 반으로 나누고, 새로운 노드를 생성하고, 그 노드의 최소 키 값을 조상 노드에 삽입한다.

이러한 **노드 분할(splitting)** 작업은 트리의 루트 노드까지 전파될 수 있으며, **최악의 경우에는 루트 노드까지 분할이 일어나 트리의 높이가 1 증가하게 된다**. 이때 새로운 루트 노드가 생성되고, 기존 루트와 새로 생긴 노드가 그 자식이 되어 트리의 균형과 정렬 성질을 유지하게 된다.

![](../images/Pasted%20image%2020250604010419.png)

![](../images/Pasted%20image%2020250604010433.png)

> **"Adams" 추가하기**

먼저 리프 노드들을 확인해 보면, 현재 "Adams"라는 Search-Key 값은 존재하지 않는다. 따라서 먼저 메인 파일에 해당 레코드를 삽입한다. 이후 인덱스에 반영하기 위해 리프 노드에 "Adams"를 삽입하려고 보았지만, 해당 노드는 이미 가득 차 있어 분할이 필요하다.

노드를 분할하기 위해 기존에 있던 `"Brandt", "Califieri", "Crick"`에 새로 삽입할 `"Adams"`를 추가한 뒤, Search-Key 기준으로 정렬한다. 정렬된 결과는 `"Adams", "Brandt", "Califieri", "Crick"`이 된다.

이제 이 네 개의 항목 중에서 앞쪽 절반, 즉 ⌈B/2⌉ 개의 항목은 기존 리프 노드에 남겨두고, 나머지 항목은 새로 생성된 리프 노드로 옮긴다. 새 리프 노드는 기존 노드와 같은 레벨에 위치하며, 기존 리프 노드와 오른쪽으로 연결된다. 즉, 기존 노드가 새 노드를 가리키고, 새 노드는 원래 기존 노드가 가리키던 노드를 대신 가리키게 된다. 이로써 리프 노드 수준에서의 작업은 완료된다.

이제 부모 노드를 갱신해야 한다. 새로 생성된 리프 노드에서 가장 작은 Search-Key 값을 찾는다. 이 값을 `k`라고 하면, 부모 노드에는 `(k, 포인터)` 쌍이 삽입된다. 이때 `k`는 두 자식 노드를 구분하는 **경계값**으로 사용되며, 검색 시 `k` 이상인 키 값은 오른쪽 자식 노드로 탐색이 진행된다.

이때 부모 노드에 공간이 충분하다면 해당 항목을 삽입하고 작업은 종료된다. 하지만 부모 노드도 가득 차 있는 경우에는 동일한 분할 과정을 부모 노드에도 적용해야 하며, 이 작업은 루트 노드까지 전파될 수 있다. 이번 경우에는 부모 노드에 여유 공간이 있었기 때문에 추가적인 분할 없이 여기에서 삽입 과정은 마무리된다.

---


![](../images/Pasted%20image%2020250604011409.png)

> Lamport 삽입하기

먼저 리프 노드들을 탐색해 보면, `"Lamport"`라는 Search-Key 값이 존재하지 않음을 확인할 수 있다. 따라서 이를 삽입해야 하며, 해당 키가 들어갈 리프 노드를 확인해 보니 이미 **꽉 차 있는 상태**였다. 삽입을 위해 먼저 **노드 분할(split)** 이 필요하다.

##### Leaf node = Child node
기존 리프 노드에는 `"Gold"`, `"Katz"`, `"Kim"`이 있었고, 여기에 `"Lamport"`를 추가하여 Search-Key 기준으로 정렬하면 `"Gold"`, `"Katz"`, `"Kim"`, `"Lamport"` 순이 된다. B가 3이라면, 삽입 후 총 4개의 항목이 되므로 ⌈B/2⌉ = 2에 따라 앞의 두 개 `"Gold"`, `"Katz"`는 기존 노드에 남기고, `"Kim"`, `"Lamport"`는 **새로운 리프 노드**로 이동된다. 이때 새 노드는 기존 노드의 오른쪽에 연결되며, 리프 노드 간 포인터 연결도 재조정된다.

##### Non Leaf node = Parent node
이제 부모 노드를 갱신해야 한다. 새로 생성된 리프 노드에서 가장 작은 Search-Key 값은 `"Kim"`이므로, 이를 부모 노드에 `(Kim, pointer)` 형태로 삽입해야 한다. 하지만 부모 노드 역시 이미 가득 차 있는 상태였다. 이 부모 노드에는 `"Califieri"`, `"Einstein"`, `"Gold"`가 있었고, 여기에 `"Kim"`이 추가되어야 하므로 다시 **부모 노드 분할**이 필요하다.

정렬된 키는 `"Califieri"`, `"Einstein"`, `"Gold"`, `"Kim"`이고, 앞의 두 개 `"Califieri"`, `"Einstein"`은 기존 노드에 남기고, `"Gold"`, `"Kim"`은 새로운 부모 노드로 분할된다. 이때 새로 생성된 부모 노드에서 가장 작은 키 값은 `"Gold"`이며, 이를 상위 노드에 삽입해야 한다.

##### Non Leaf node = Root node
상위 노드는 바로 **루트 노드**이다. 기존 루트 노드에는 `"Mozart"`라는 키가 있었는데, 이번에 삽입할 `"Gold"`는 `"Mozart"`보다 사전 순으로 앞서므로 루트 노드에서 `"Gold"`는 `"Mozart"`보다 앞에 위치하게 된다. 그러나 중요한 점은, B+ 트리에서는 루트 노드도 내부 노드처럼 동작하므로, **자식 노드들의 경계값 역할만** 한다.

따라서 `"Gold"`는 루트 노드에 삽입되지만, **새롭게 생성된 자식 노드(즉, 부모 노드의 결과물) 내부에는 `"Gold"`가 포함되지 않는다**. 이는 `"Gold"`가 루트에서 자식 노드들의 분기 기준 역할을 하기 때문이며, 실제 데이터는 여전히 리프 노드에 위치한다.

결과적으로 `"Lamport"`를 삽입하면서 리프 노드 → 부모 노드 → 루트 노드까지 분할이 전파되었고, 트리의 **높이는 그대로 유지**되었으며, 루트 노드는 `"Gold"`와 `"Mozart"`의 두 경계값으로 세 자식 노드를 구분하게 된다.

---
#### ✅ Splitting Non-leaf node 

B+ 트리에서 노드 분할(split) 시 **leaf 노드와 non-leaf 노드(내부 노드)의 동작 방식이 다름**을 관찰할 수 있다.

리프 노드가 꽉 차서 분할되는 경우에는, 새로운 노드에 삽입된 키들 중 **가장 작은 Search-Key 값**이 **그대로 새로운 리프 노드에 포함되며**, 동시에 **부모 노드에도 경계값으로 삽입**된다. 즉, 같은 키 값이 리프 노드와 부모 노드에 모두 존재하게 된다.

반면, **non-leaf 노드(내부 노드)** 가 분할될 때는 다르다. 내부 노드의 키들 중 중간 위치의 키 값을 기준으로 분할이 이루어지며, **해당 키 값은 새로운 노드에 포함되지 않고 부모 노드에만 삽입된다**. 즉, 경계 역할을 할 키 하나는 자식 노드들로부터 _끌어올려져_, 부모 노드로 이동하고 자식 노드에서는 제외된다.

![](../images/Pasted%20image%2020250604013128.png)

이러한 차이는 B+ 트리의 **구조적 목적의 차이**에서 비롯된다.

리프 노드는 실제 레코드에 대한 포인터를 포함하고 있으며, 모든 Search-Key 값을 빠짐없이 포함하고 있어야 한다. 즉, 리프 노드는 **dense index**로 동작하기 때문에 **모든 키 값이 존재해야 한다**. 따라서 키 값을 리프 노드에서 제거하지 않고, 그대로 유지하는 것이 원칙이다.

반면, non-leaf 노드는 실제 데이터 레코드와 연결되어 있지 않고, **단순히 자식 노드들의 구간을 구분하기 위한 경계값 역할만 한다**. 이런 구조는 **sparse index**의 성격을 가지며, 모든 키 값을 유지할 필요 없이 **자식 노드 구간을 나눌 수 있는 일부 키 값만 포함**하면 된다. 따라서 분할 시 중간 키를 부모 노드로 끌어올린 후, 해당 키를 자식 노드에서는 제거해도 아무 문제가 없다.

결국 이 구조는 B+ 트리의 계층적 인덱싱 원리를 기반으로 하며, **검색 경로가 상위 노드에서부터 점진적으로 좁혀지기 때문에**, 내부 노드에는 일부 키만 있어도 전체 탐색에 지장이 없게 된다.

> [!note] 정리
> **Leaf node**에서 분리했을 때는 **새로운 노드의 가장 작은 키 값이 부모 노드에 삽입된다.**  
> 예를 들어, B = 3인 노드에 1개를 더 추가했을 때, 앞의 2개는 기존 노드에 남고, 나머지는 새로운 노드로 이동한다. 그중 **가장 작은 키 값이 부모 노드에 삽입**된다.
> 
> 반면, **Non-leaf node**에서 분리했을 때는 **애초에 중간 값을 부모 노드에 삽입한다.**  
> 예를 들어, B = 3인 노드에 1개를 더 추가했을 때, 앞의 2개는 기존 노드에 남기고, 그 다음 키는 **부모 노드에 삽입**되며, **그 다음부터는 새로운 노드로 이동**한다.

---
## **B+ Tree Deletion**

노드를 삭제하기 위해서는 먼저 **삭제할 레코드를 찾는 것부터 시작**한다.  리프 노드를 탐색하여 해당 **Search-Key 값**이 있는지 확인한 뒤, 해당 레코드가 **메인 파일에 존재하면 삭제**하고, **bucket이 존재한다면 그 안에서도 삭제**한다.

만약 해당 키에 연결된 bucket이 없거나, 삭제 이후 bucket이 비게 된다면, 더 이상 중복 레코드가 존재하지 않으므로 **리프 노드에서 해당 Search-Key 값과 그에 대응되는 포인터를 함께 삭제**하면 된다.

그런데 이 삭제로 인해 **리프 노드의 엔트리 수가 너무 적어지는 경우**가 발생할 수 있다.  즉, 노드에 남아 있는 `(key, pointer)` 쌍이 B+ 트리의 **최소 개수 조건**(보통 ⌈B/2⌉ 이상)을 위반하게 되는 경우다.

이런 상황에서는 먼저 **인접한 형제 노드(sibling)** 와의 병합 가능성을 검사한다.

#### ✅ Merge sibling

두 개의 노드에 있던 **search-key value**들과 포인터들을 모두 **하나의 노드**로 합친다.  이때 일반적으로 **왼쪽 노드**에 모든 내용을 병합하고, **오른쪽 노드는 삭제**한다.

그 다음 단계로, **삭제된 노드를 가리키고 있던 부모 노드의 엔트리도 함께 제거해야** 한다.  구체적으로는, 부모 노드에서 해당 노드(P<sub>i</sub>)를 가리키는 포인터와 그 왼쪽에 있는 키 값(K<sub>i−1</sub>)을 함께 삭제한다.  

> **(K<sub>i−1</sub>, P<sub>i</sub>) 쌍을 부모 노드에서 제거한다.**

만약 이 삭제로 인해 **부모 노드도 최소 개수 조건을 위반**하게 되면, **같은 병합 또는 재분배 절차를 상위 노드로 재귀적으로 적용**한다. 이러한 과정은 **루트 노드까지 전파**될 수 있으며, **루트 노드의 포인터가 하나만 남게 되면 트리의 높이가 1 줄어든다.**

#### ✅ Redistribute pointers

노드에서 엔트리를 삭제한 결과 **최소 개수(보통 ⌈B/2⌉)보다 적은 엔트리**만 남게 되었지만,  **형제 노드(sibling)와 병합(merge)** 할 수 없을 정도로 두 노드를 합쳐도 크기가 초과될 경우에는, **병합 대신 재분배(redistribution)** 를 수행한다.

이 경우에는 **현재 노드와 형제 노드 사이의 포인터(및 키)들을 적절히 나누어**,  **두 노드 모두 최소 개수 이상의 엔트리를 갖도록 재배치**한다. 재분배 후에는 반드시 **부모 노드에 존재하는 해당 구간의 Search-Key 값**을 **업데이트해야 한다**.  이는 자식 노드들의 경계가 바뀌었기 때문이다.

이와 같은 **삭제 후 보정 과정은 재귀적으로 부모 노드까지 전파**될 수 있으며,  부모 노드도 삭제로 인해 최소 포인터 개수를 만족하지 못하게 된다면  마찬가지로 병합 또는 재분배가 적용된다.

최악의 경우, **루트 노드까지 전파되어 루트 노드가 포인터를 하나만 가지게 되면**,  **루트 노드는 제거되고, 그 유일한 자식이 새로운 루트가 된다.**  이때 B+ 트리의 **높이는 1 줄어든다.**


![](../images/Pasted%20image%2020250604014416.png)
![](../images/Pasted%20image%2020250604023202.png)

---
## **B+ Tree File Organization**

**Index file degradation 문제**는 **B+ 트리 인덱스(B+ Tree indices)** 를 사용함으로써 해결할 수 있다.  반면, **데이터 파일의 degradation 문제**는 **B+ 트리 기반 파일 구성(B+ Tree file organization)** 을 사용하여 해결할 수 있다.

이때 **B+ 트리 파일 구성 방식**에서는 **리프 노드가 실제 레코드를 저장**하며, 기존 인덱스 구조에서처럼 레코드를 가리키는 **포인터만 저장하는 것이 아니다.**  즉, 리프 노드에 실제 데이터가 저장되는 구조다.

하지만 **리프 노드도 여전히 최소 절반 이상 채워져야 한다**는 조건은 동일하게 적용된다.  또한, **레코드는 포인터보다 크기 때문에**,  **리프 노드에 저장할 수 있는 레코드 수는**  **내부 노드에 저장할 수 있는 포인터 수보다 적다.**

삽입과 삭제 연산은 **B+ 트리 인덱스의 삽입 및 삭제 방식과 동일하게 처리**되며,  병합(merge), 재분배(redistribution), 루트 갱신 등도 같은 원리에 따라 수행된다.

![](../images/Pasted%20image%2020250604023707.png)

레코드는 포인터보다 더 많은 공간을 차지하기 때문에, **공간 활용도(Good space utilization)** 를 높이는 것이 중요하다.

공간 활용도를 개선하기 위해서는, **노드 분할(split)** 이나 **병합(merge)** 과정에서  **더 많은 형제 노드들을 재분배(redistribution)** 에 참여시키는 방식을 사용할 수 있다.

예를 들어, **두 개의 형제 노드를 함께 참여시켜 재분배를 수행하면**,  분할이나 병합을 피할 수 있는 상황이 많아지며,  그 결과 **각 노드는 최소 $\frac{2B}{3}$​개의 엔트리(entry)** 를 유지하게 되어  공간 활용도가 더욱 높아진다.

---
## **Other Issues in Indexing**

레코드가 물리적으로 이동하게 되면, 해당 레코드를 가리키는 **모든 보조 인덱스(secondary index)** 의 포인터를 함께 갱신해야 한다.  이러한 상황에서는 **B+ 트리 파일 조직(B+ tree file organization)** 에서 **노드 분할(splits)** 이 발생할 때 **레코드 위치 변경이 자주 발생**하기 때문에,  그에 따라 **보조 인덱스를 갱신하는 비용이 매우 커지게 된다.**

이 문제를 해결하기 위한 방법으로는,  **보조 인덱스에서 레코드의 물리적 포인터 대신, 기본 인덱스(primary index)의 검색 키(search key)를 저장하는 방식**이 있다.

이 방식에서는 쿼리를 처리할 때 **추가적으로 기본 인덱스를 한 번 더 탐색**해야 하기 때문에  검색 비용이 다소 증가하지만,  레코드의 물리적 위치가 변경되더라도 보조 인덱스를 **갱신할 필요가 없게 되어**  **노드 분할과 관련된 비용을 크게 줄일 수 있다.**

단, 기본 인덱스의 검색 키가 **유일하지 않은 경우**에는,  레코드를 정확히 식별하기 위해 **record-id (RID)** 같은 고유 식별자를 함께 저장해야 한다.

> Secondary Index에서 바로 실제 데이터를 가르키는게 아니라 Primary Index를 가리켜, Primary Index에서 실제 데이터를 가리키도록 한다!

---
## **B Tree Index Files**

B-트리는 B+ 트리와 유사한 구조를 가지지만, **검색 키(search key) 값이 트리 내에서 한 번만 나타난다는 점이 주요 차이점**이다.  

>즉, **중복 저장이 없기 때문에 검색 키의 저장 공간을 절약**할 수 있다.

B-트리에서는 **검색 키들이 내부 노드(non-leaf node)에만 존재**하며,  **리프 노드에는 별도로 저장되지 않는다.** 이러한 구조적 특성 때문에, **내부 노드에 있는 각 검색 키마다 해당 키보다 큰 값을 가지는 하위 노드를 가리키는 포인터가 필요**하다.  즉, B-트리의 **각 내부 노드는 검색 키 수보다 하나 더 많은 포인터 필드를 포함**해야 한다.


> B+ Tree에는 리프 노드에만 key와 값이 모두 있지만, B Tree는 내부 노드에도 key와 값이 모두 있다. 

![](../images/Pasted%20image%2020250604152907.png)

----
## **B-Tree Index File Example**

![](../images/Pasted%20image%2020250604153132.png)

B-Tree 인덱스의 이점은 B+ Tree 보다 트리의 노드가 적을 수 있다는 것이다. 그리고 리프 노드에 도달하기 전에 serach - key 값을 찾을 수 있다. 

단점은 B-트리에서는 전체 검색 키 값 중 **일부만이 상위 레벨(초기 단계)에서 발견**되며, 나머지는 하위 노드까지 내려가야 한다.  또한, **내부 노드가 더 많은 정보(키와 포인터)를 포함하므로 노드 크기가 커지고**, 그에 따라 **fan-out(한 노드가 가질 수 있는 자식 수)** 이 줄어들게 된다.  이로 인해 B-트리는 **동일한 데이터를 저장하는 B+ 트리보다 더 깊어지는 경향이 있다.**

삽입과 삭제 연산도 **B+ 트리에 비해 더 복잡하며**,  전체적으로 구조가 더 정교하고 제어가 까다로워  
**B-트리의 구현은 B+ 트리보다 더 어렵다.**

>보통 B Tree의 장점은 단점을 넘어서지 못 한다. 

---
## **Multiple Key Access**

```sql
select ID from instructor where dept_name = "Finance" and salary = 80000
```

단일 속성에 대한 인덱스를 활용하여 쿼리를 처리할 수 있는 대표적인 전략은 다음과 같다.

1. **`dept_name` 인덱스를 사용하는 방법**  
    `dept_name` 속성에 인덱스가 있다고 가정하면, 먼저 `"Finance"` 학과에 속한 모든 강사를 인덱스를 통해 찾아낸다.  그런 다음, 이 중에서 `salary = 80000` 조건을 만족하는 레코드만 필터링한다.
    
2. **`salary` 인덱스를 사용하는 방법**  
    반대로 `salary` 속성에 인덱스가 있다면, 우선 급여가 `80000`인 강사들을 인덱스로 찾고,  
    그중 `dept_name = "Finance"`인 강사만을 선택한다.
    
3. **두 인덱스를 모두 사용하는 방법 (집합 교집합 기반)**  
    `dept_name` 인덱스를 이용해 `"Finance"` 학과에 속한 레코드들의 포인터 집합을 구하고,  `salary` 인덱스를 이용해 급여가 `80000`인 레코드들의 포인터 집합을 구한다.  이 두 집합의 **교집합**을 취함으로써 조건을 모두 만족하는 레코드를 찾는다.

---
## **Indices on Multiple Keys**

>**Composite search key**란 **두 개 이상의 속성으로 구성된 검색 키**를 의미한다.  

예를 들어, `(dept_name, salary)`와 같이 두 속성을 함께 사용하는 키가 이에 해당한다.

이러한 복합 키는 일반적으로 **사전식 정렬(lexicographic ordering)** 을 기준으로 정렬된다.  즉, `(a₁, a₂)`와 `(b₁, b₂)`라는 두 개의 복합 키가 있을 때

- `a₁ < b₁`이면 `(a₁, a₂) < (b₁, b₂)`
    
- 또는 `a₁ = b₁`이고 `a₂ < b₂`이면 역시 `(a₁, a₂) < (b₁, b₂)`
    
이러한 정렬 기준은 B+ 트리나 인덱스 구조 내에서 복합 키를 정렬하고 탐색할 때 사용된다.  따라서 복합 키 인덱스를 사용할 경우, **앞쪽 속성 기준으로 범위를 좁히고**,  **같은 값 내에서 다음 속성 기준으로 정렬/탐색이 이어지는 구조**를 갖게 된다.

복합 검색 키 `(dept_name, salary)`에 대해 인덱스를 생성한 경우, 다음과 같은 쿼리에 대해 매우 효율적인 접근이 가능하다.

##### 예시 1:

```sql
WHERE dept_name = 'Finance' AND salary = 80000
```

이 경우, 복합 인덱스를 통해 **두 조건을 동시에 만족하는 레코드만 정확히 탐색**할 수 있다.  이는 단일 속성 인덱스를 따로 사용하는 것보다 훨씬 효율적이다.  (단일 인덱스를 사용할 경우, 조건 중 하나만 만족하는 레코드들도 모두 가져와서 필터링해야 함.)

##### 예시 2:

```sql
WHERE dept_name = 'Finance' AND salary < 80000
```

이 조건도 효율적으로 처리할 수 있다.  복합 인덱스 상에서 `"Finance"`에 해당하는 레코드 범위를 좁힌 후, 그 안에서 `salary < 80000` 조건을 만족하는 항목만 탐색하면 된다.

##### 예시 3:

```sql
WHERE dept_name < 'Finance' AND salary = 80000
```

이 경우는 비효율적이다.  인덱스는 **첫 번째 속성(dept_name)** 기준으로 정렬되어 있기 때문에,  
`dept_name < 'Finance'`에 해당하는 **모든 항목을 탐색한 후**, 그중 `salary = 80000`인 것만 필터링해야 한다.  따라서 불필요한 탐색이 많아져 성능이 저하된다.

---
