---

---

## **Integer Addition**

Example 7 + 6
![](../images/Pasted%20image%2020250401154607.png)

결과 값이 표현 범위를 넘어서면 **오버플로우(overflow)** 가 발생한다.  
`+ve`(양수)와 `-ve`(음수)를 더하는 연산에서는 오버플로우가 발생하지 않는다.

하지만 두 개의 `+ve`(양수)를 더했을 때 오버플로우가 발생하면, **결과의 부호 비트가 1**로 바뀌어 음수처럼 보이게 된다.  
반대로 두 개의 `-ve`(음수)를 더했을 때 오버플로우가 발생하면, **결과의 부호 비트가 0**이 되어 양수처럼 보인다.


---
## **Integer Subtraction**

Example 7 - 6 = 7 + (-6)
![](../images/Pasted%20image%2020250401235049.png)

|연산 유형|오버플로우 발생 여부|오버플로우 발생 조건|
|---|---|---|
|+ve - +ve 또는 -ve - -ve|❌ 없음|없음|
|-ve - +ve|✅ 가능성 있음|결과의 부호가 **0(양수)**일 때|
|+ve - -ve|✅ 가능성 있음|결과의 부호가 **1(음수)**일 때|


---
## **Dealing with Overflow**

C와 같은 일부 언어는 **오버플로우를 무시**한다.  
MIPS에서도 `addu`, `addiu`, `subu` 같은 명령어는 **오버플로우를 검사하지 않는다.**

반면, **Ada**나 **Fortran**과 같은 언어는 오버플로우가 발생하면 **예외를 발생시킨다.**  
MIPS에서는 `add`, `addi`, `sub` 명령어가 이에 해당하며,  오버플로우 발생 시 **예외 핸들러가 호출된다.**

이때, 현재 명령어의 주소는 **EPC(Exception Program Counter)** 레지스터에 저장되며,  
제어 흐름은 사전에 정의된 **예외 핸들러 주소**로 이동한다.  
예외 처리 후에는 `mfc0`(move from coprocessor 0) 명령어를 사용해  
EPC 값을 복원하고, 적절한 조치를 취한 뒤 **원래 실행하던 위치로 복귀**할 수 있다.

---
## **Arithmetic for Multimedia**

그래픽 처리나 8비트 벡터, 16비트 데이터 등에서 동작하도록 설계된 **멀티미디어 연산기**는  **64비트 덧셈기(adder)** 를 사용하되, **분할된 캐리 체인(partitioned carry chain)** 방식으로 구성된다.

즉, 하나의 큰 연산기를 다음과 같이 **작은 단위로 나누어 병렬 연산**이 가능하도록 만든다:

- 8 × 8비트
- 4 × 16비트
- 2 × 32비트

이처럼 한 번에 여러 데이터를 동시에 처리하는 방식은  **SIMD (Single Instruction, Multiple Data)** 구조의 대표적인 예시다.

###  Saturating Operations (포화 연산)

- 오버플로우가 발생했을 때, 결과를 **표현 가능한 최대값으로 고정**  
    → 더 이상 넘치지 않고 **“포화(saturation)”** 상태로 유지됨
- 이는 일반적인 오버플로우 시 부호가 반전되는 **2의 보수(modulo arithmetic)** 방식과는 다르다.

- **오디오 클리핑(audio clipping)**
- **비디오 색상 포화(video saturation)**

---
## **Multiplication**

![](../images/Pasted%20image%2020250402000032.png)

![](../images/Pasted%20image%2020250402000109.png)

![](../images/Pasted%20image%2020250402000219.png)

- **multiplier의 마지막 비트(LSB)** 가 `1`이면:
    - **처음이든 아니든** `multiplicand`를 `product`에 더함
        
- **multiplier의 마지막 비트**가 `0`이면:
    - **덧셈 없이** 시프트만 수행
        
- 매 단계마다:
    - `multiplicand`는 **왼쪽으로 시프트 (×2)**
    - `multiplier`는 **오른쪽으로 시프트 (÷2)**

---
## **Optimized Multiplier**

![](../images/Pasted%20image%2020250402094051.png)

곱셈 연산에서는 **덧셈(add)** 과 **시프트(shift)** 가 **병렬적으로 수행**된다.  
즉, **각 partial product(부분 곱)** 을 더할 때마다  
**한 사이클(cycle)** 이 소요되며,  
이 과정은 **매 단계마다 반복**된다.

이러한 방식은 **곱셈 연산의 빈도가 낮을 경우**에는  
성능 측면에서 **충분히 괜찮은 방식**으로 간주된다.

![](../images/Pasted%20image%2020250402094331.png)

- 처음부터 **Product 레지스터의 하위 비트**에 **Multiplier 값**이 포함됨
- 각 사이클마다 **Product의 마지막 비트(LSB)** 를 검사

#### 👉 만약 LSB가 `1`이라면:

- **Multiplicand를 Product의 상위 비트 영역에 더함**
- 그리고 Product 전체를 **오른쪽으로 시프트**
    

#### 👉 만약 LSB가 `0`이라면:

- **덧셈 없이** 그냥 **Product를 오른쪽으로 시프트**함
- 이때 오른쪽 시프트를 통해 Product의 마지막 비트는 **버려지게 됨**

---
## **Faster Multiplier**

- **여러 개의 가산기(adders)** 를 사용해  **부분 곱(partial products)** 을 동시에 더함
- **병렬 처리**를 통해 속도를 높이는 구조

- **Pipelining** 가능  → 각 연산 단계를 파이프라인으로 분리하면  여러 곱셈을 **동시에 처리** 가능
- **Cost / Performance tradeoff**  → 빠르지만 **하드웨어 자원(면적, 소비 전력 등)** 이 더 듦

![](../images/Pasted%20image%2020250402094856.png)

---
## **MIPS Multiplication**

MIPS는 곱셈 결과를 저장하기 위해 **두 개의 32비트 전용 레지스터**를 사용한다:

- `HI`: 상위 32비트 (Most-Significant Bits)
- `LO`: 하위 32비트 (Least-Significant Bits)
#### 명령어

```
mult rs, rt              // 부호 있는 곱셈
multu rs, rt             // 부호 없는 곱셈
```

결과는 64비트이며,  **상위 32비트 → HI**, **하위 32비트 → LO**에 저장됨


```
mfhi rd  → HI 레지스터 값을 `rd`로 복사 move from HI
mflo rd  → LO 레지스터 값을 `rd`로 복사 move from LO
```
    
예: 32비트 이하 결과만 필요한 경우에는 `mflo`만 사용
**HI 값이 0이 아니면**, 결과가 32비트를 초과했음을 의미 (오버플로우 판단 가능)

```assembly
mul rd, rs, rt → rs * rt해서 rd에 넣기
```

곱했을 때 32비트의 결과를 바로 rd 에 넣을 수 있다.

---

## **Division**

**나누는 수(divisor)** 와 **나눠지는 수(dividend)** 를 비교하고,  뺄 수 있을 만큼 **왼쪽으로 시프트(shift)** 하면서 **뺄 수 있으면 빼고**, 그렇지 않으면 넘어가며  **몫과 나머지를 계산**하는 방식

- **우선 빼본다** (dividend에서 divisor를 뺌)
    
- **결과가 0 이상이면**  빼는 것이 성공한 것이므로, **몫 비트에 1 저장**
    
- **결과가 0보다 작으면**  빼는 게 실패한 것이므로,  **다시 더해서 복구하고**, **몫 비트에 0 저장**
    
- 그 다음에는 **시프트 연산(왼쪽으로)** 을 수행하여  다음 비트를 처리할 준비를 한다

#### Signed Division

1. **우선 양수로 바꾸고 계산한다**
    나눠지는 수(dividend), 나누는 수(divisor) 중  **음수가 있다면 부호를 무시하고 절댓값으로 나눗셈 수행**
        
2. **나눗셈 완료 후**, 최종적으로 **몫의 부호** 결정:
    
    - **두 수의 부호가 같으면 → 양수**
        
    - **두 수의 부호가 다르면 → 음수**
        
3. **나머지(remainder)** 는 일반적으로 **dividend와 같은 부호**를 가짐



![](../images/Pasted%20image%2020250403121721.png)

복원 나눗셈은 Divisor를 상위에, Dividend를 하위에 배치한 뒤, Remainder에서 Divisor를 빼고 결과가 음수면 Remainder을 복원하고 몫에 0, 양수면 그대로 두고 몫에 1을 저장한 후 Quotient는 왼쪽, Divisor는 오른쪽으로 시프트하며 이 과정을 32~33번 반복한다.

이때 이진수의 뺄셈은 빼는 수의 보수에 + 1을 한 것을 빼지는 수에 더하면 된다.

![](../images/Pasted%20image%2020250403122012.png)


**Remainder - Divisor 연산 후 최상위 비트(MSB)가 1이면 음수이므로 복원하고, 0이면 그대로 두고 몫 비트에 1을 설정한다. 이후 Divisor는 계속 오른쪽으로 시프트하며, Remainder는 결과가 0일 때 오른쪽으로 시프트한다.**

---
## **Optimized Divider

![](../images/Pasted%20image%2020250403122305.png)

`Remainder`는 단순한 나머지 저장소가 아니라, **몫과 나머지를 함께 저장하거나 제어하는 복합 구조**이기 때문에 **시프트 연산이 가능하도록 되어 있다.** 계속 수행하다보면 왼쪽에 나머지 오른쪽은 몫이 남는다.

일단 Remainder 왼쪽 시프트
상위 4개 비트 빼기
결과에 따라 시프트 된 빈 자리에 1또는 0 삽입
32번 반복

---
## **Faster Division

**곱셈**은 단순히 partial product들을 더해가는 방식이기 때문에  여러 연산을 **병렬로 쉽게 구성**할 수 있음 하지만 **나눗셈**은 매 스텝마다 **뺄 수 있는지 판단(sign 비교)** 해야 하므로  **조건부 분기**가 많아서 병렬화가 어려움

곱하기랑 나누기랑 연산 속도가 다르다. 일반적으로 나눗셈이 더 느리다.


---
## **MIPS Division

####  **MIPS에서 나눗셈 결과 저장 방식**

- **`HI` 레지스터**: **나머지 (Remainder)** 저장
- **`LO` 레지스터**: **몫 (Quotient)** 저장

#### 관련명령어

- `div rs, rt`    // signed division
- `divu rs, rt`   // unsigned division
    

> → `rs ÷ rt` 연산 수행 후:  
> → 몫은 `LO`, 나머지는 `HI`에 저장됨

- `mflo rd`  → `LO` 값(몫)을 일반 레지스터로 가져옴
- `mfhi rd`  → `HI` 값(나머지)을 일반 레지스터로 가져옴

**오버플로우나 0으로 나누기**에 대한 **하드웨어 체크 없음**→ 즉, 직접 **소프트웨어에서 검사**해야 함

---
## **MIPS Arithmetic Instructions Summary

![](../images/Pasted%20image%2020250403123158.png)

---
## **Floating Point

#### 1. **Fixed Point (고정소수점)**

- **정수처럼 저장하지만**, **어디에 소수점이 있다고 가정**하는 방식
- 예: `16비트 정수부 + 16비트 소수부` 라고 정해두면, `점`은 중간에 있는 걸로 간주
    
- **장점**: 단순하고 빠름 (정수 연산처럼 처리 가능)
- **단점**: 표현 범위가 작고 유연성이 부족함

#### 2. **Floating Point (부동소수점)**

- 숫자를 **정규화된 형태로 표현**
    
    > **±1.xxxxxxx₂ × 2ʸʸʸʸ** (2진수 기준)
    
- `1.` 뒤에 나오는 부분이 **유효 숫자 (fraction)** 로 실질적인 숫자 정보를 담고 있다.
- `2의 지수 (exponent)`를 통해 **폭넓은 범위의 값**을 표현할 수 있다.

---
## **Floating Point Standard

다양한 컴퓨터마다 실수 표현 방식이 **제각각**이던 시절,  과학 계산의 이식성(portability)** 문제가 심각했다. 그래서 이를 **통일하기 위해 제정된 표준**이 바로 **IEEE 754-1985**
    
> 지금은 거의 모든 하드웨어에서 **사실상 표준**으로 사용됨

- Single precision (32-bit)
- Double precision (64-bit)

어디까지 x 를 넣고 어디까지 y를 넣을지 정하긴 하며 됨

---
## **IEEE Floating-Point Format

![](../images/Pasted%20image%2020250403124212.png)

##### ✅ **Sign (부호 비트)**

- 최상위 비트는 부호 판단에 사용됨
- `0`이면 양수, `1`이면 음수

##### ✅ **Significand (유효 숫자, 가수)** 
부동소수점 수는 항상 다음과 같은 **정규화된 형태**로 표현됨:

$$    1.0≤∣significand∣<2.0$$

→ 즉, **소수점 앞에 항상 1이 오도록 조정**한다. 

정규화된 수는 항상 `1.xxxxxx` 형태이기 때문에,  소수점 앞의 **1은 저장하지 않아도 된다.**


##### ✅ **Exponent (지수)**

 **±1.xxxxxxx₂ × 2ʸʸʸʸ** (2진수 기준)
 
부동소수점 수에서 **Exponent**는 숫자의 **크기(범위)** 를 조절하는 데 사용된다.
쉽게 말하면, **소수점의 위치를 얼마나 좌우로 이동시킬지**를 결정하는 부분이다.

여기서 **Exponent**는 실제 지수가 아니라, **Bias가 더해진 값으로 저장됨.

**지수 필드가 부호 없는 값(Unsigned)** 이기 때문에,  양수/음수 지수 모두 표현하기 위해 **Bias(편향 값)** 를 사용한다.

> 실제로 Single이면 **127**, Double이면 **1023**을 빼주며,  
> 지수 필드에서 이 값을 뺀 결과가 **실제 Exponent**가 된다.
> 
> 즉, **저장된 지수 값에서 127 또는 1023을 빼준 값이 진짜 지수**라고 생각하면 된다.

##### ✅ **Fraction (가수 비트)**

 `1.` 뒤의 **실제 유효 숫자 비트들**을 말하며 그냥 x의 값을 그대로 넣어주면 된다. 즉, 정규화된 수에서 소수점 이하 비트만 저장됨


 **fp32 (8비트 Exponent)**

- 지수 범위: 최솟값 `0`, 최댓값 `2⁸ - 1 = 255`    
- 단, `0`과 `255`는 **예약 값**이므로 실제 사용 가능한 범위는 `1 ~ 254`
- 여기서 **Bias 127을 빼주면**:
    
    - 최소 지수: `1 - 127 = -126`
    - 최대 지수: `254 - 127 = +127`
        
→ 따라서 지수는 `-126 ~ +127` 범위에서 표현되며, **숫자들이 정렬된 형태로 표현 가능하다.**

---
## **Single-Precision Range

#### ✅ Exponent 비트는 8비트 (총 256개)

하지만 **`00000000` (0)** 과 **`11111111` (255)** 은  **특수한 용도**로 **예약되어 있음**  
→ 그래서 **정규화된 수(normalized numbers)** 에서 실제로 사용할 수 있는 값은:

$$1∼254$$



#### ✅ Exponent 사용 범위와 의미

| 항목         | Exponent 비트값     | 실제 지수 (`E = exp - 127`) | Fraction                | 의미                         |
| ---------- | ---------------- | ----------------------- | ----------------------- | -------------------------- |
| **최소 정규값** | `00000001` (1)   | **-126**                | `0...0`                 | `1.0 × 2⁻¹²⁶` ≈ ±1.2×10⁻³⁸ |
| **최대 정규값** | `11111110` (254) | **+127**                | `1...1` (≈ 0.999999...) | ≈ `2.0 × 2¹²⁷` ≈ ±3.4×10³⁸ |
| **예약값**    | `00000000`       | —                       | —                       | **denormalized**, ±0       |
| **예약값**    | `11111111`       | —                       | —                       | **Infinity**, **NaN**      |


#### ✅ 왜 이렇게 구성했을까?

- **Bias (127)** 를 중심으로 음/양 지수 범위를 **대칭적으로** 표현
- 지수 전체는 `0~255`, 실제 사용 가능한 지수는 `-126 ~ +127`
- 가장 작은 정규 수 = `1.0 × 2⁻¹²⁶`
- 가장 큰 정규 수 ≈ `2.0 × 2¹²⁷`
    

---
## **Double-Precision Range

##### ✅ Double Precision (fp64)에서 Exponent 범위

- **Exponent 필드**는 11비트 → 총 범위: `0 ~ 2047`
- 하지만 `00000000000` (0)과 `11111111111` (2047)은 **특수한 용도**로 **예약됨**
- 따라서 정규화된 수에서 사용 가능한 지수 범위는:
    
$$    1-2046$$

##### ✅ **가장 작은 정규화된 수**

- Exponent: `00000000001` (= 1)
- 실제 지수: `1 - 1023 = -1022`
- Fraction: `000...0` → significand = `1.0`
    

$$±1.0×2^{−1022}≈±2.2×10^{308}$$


##### ✅ **가장 큰 정규화된 수**

- Exponent: `11111111110` (= 2046)
- 실제 지수: `2046 - 1023 = +1023`
- Fraction: `111...1` → significand ≈ `2.0`
    

$$2.0 \times 2^{+1023} \approx \pm 1.8 \times 10^{+308}$$


---
## **Floating-Point Precision

정밀한 표현 여부 (유효 숫자 표현 여부)

- **Single (fp32)**  
  소수점 아래 **23자리**까지 표현 가능  → **10진수 기준 약 6~7자리**
    
- **Double (fp64)**  
  소수점 아래 **52자리**까지 표현 가능  → **10진수 기준 약 16자리 정도**

---
## **Floating Point Example1

![](../images/Pasted%20image%2020250404165211.png)

-0.75 = - ( 1/2 + 1/4 )
- 0.5 = 2⁻¹ → 첫 번째 자리 1
- 0.25 = 2⁻² → 두 번째 자리 1  
    → 0.75 = 0.5 + 0.25 = **0.11₂**

**2진수 소수의 첫 번째 자리(2⁻¹)**는 “0.5를 포함하냐?”는 의미이다.  
0.75는 0.5보다 크기 때문에 → 포함된다 → 첫 번째 자리 = 1  
남은 값은 0.25인데, 이 값은 **2⁻² = 0.25** 에 해당하므로 → 두 번째 자리도 1이다.

**0.11₂**을 **정규화된 부동소수점 형식**으로 표현하면 먼저, **음수**이므로 `-1 × ...` 형태가 된다.
`0.11₂`는 소수점 기준으로 **왼쪽으로 한 자리 이동**하면 `1.1 × 2⁻¹`이 된다.


$${-0.11_2 = -1.1_2 \times 2^{-1}}$$

이걸 IEEE 754 표현으로 바꾸면, 첫 번째 자리는 **음수**니까 `1`,*single 타입**이기 때문에 **지수는 -1 + 127 = 126**, 126을 **이진수로 표현하면 `01111110`**,  **fraction 부분**은 정규화된 `1.1`에서 `1` 뒤에 있는 `.1`만 넣어주면 되고, 나머지는 0으로 채워준다.

<center>1 01111110 10000000000000000000000</center>

---
## **Floating Point Example2

![](../images/Pasted%20image%2020250404170631.png)


- **앞에는 1**이니까 → **음수**
    
- **fraction** 부분은 `010000...000` → 즉, `1 + 0.01₂ = 1.25`
    
- **exponent**는 `10000001` → 2진수로 `129`  → 실제 지수 = `129 - 127 = 2`
    

따라서,

$$(-1) \times (1 + 0.01_2) \times 2^2 = -1.25 \times 4 = \boxed{-5}$$


---
## **Integet vs. Floating Point Example

![](../images/Pasted%20image%2020250403130604.png)

`int`는 값을 있는 그대로, **정확하게 저장**하는 데 반해,  `float`은 **정수 + 소수 + 지수 범위**를 표현해야 하기 때문에  **유효 숫자(정밀도)**에 제한이 있다.

예를 들어, `float`(single precision)은 32비트 중  **23비트만 fraction(가수)** 으로 사용되며,  
이는 2⁰부터 2⁻²³까지의 값만 **정밀하게 표현**할 수 있다는 뜻이다.  

즉, **약 7자리 정도의 10진수까지만 정확하게 저장 가능하다.**

이 때문에 발생하는 현상이 있는데,  `int`로는 정확하게 표현되던 값이,  `float`으로 변환되는 과정에서 **하위 비트 일부가 잘려나가거나 반올림**되어,  **인접한 float 값으로 바뀌는 경우**가 생긴다.

이러한 정밀도 손실 현상을  
**Precision Loss(정밀도 손실)** 이라고 부른다.

---
## **Denormal Numbers**

Exponent = 0000...0

![](../images/Pasted%20image%2020250416002040.png)

실수 연산에서 결과가 너무 작아져서 표현 가능한 범위를 벗어나는 경우가 있다. 이때 값을 완전히 0으로 떨어뜨리는 대신, **exponent가 0인 비정규화 영역(denormalized region)**을 이용하여 **숨겨진 비트(hidden bit)를 1이 아닌 0으로 두고** 수를 표현한다. 이를 통해 아주 작은 수를 **점차 줄어드는 정밀도로 표현할 수 있게 된다.**

즉, **정규화된 표현에서 표현할 수 있는 가장 작은 양수**는 (단정도 기준으로)

$$2^{-126}−1×2−126$$

이지만, 그보다 더 작은 수는 **비정규화 표현을 통해 0으로 급격히 떨어지는 것을 방지하고**,  **0에 서서히 가까워지도록 표현**할 수 있게 된다.

![](../images/Pasted%20image%2020250416002633.png)

비정규화 수에서 **fraction까지 모두 0**이라면, 즉, **숫자값 자체는 0이지만**, **부호 비트(S)** 에 따라 **양의 0(+0.0)** 또는 **음의 0(-0.0)** 으로 구분할 수 있다.  이는 수학적으로는 동일한 값이지만, **계산 과정이나 방향성(예: 나눗셈, 부호 감지)** 에서 의미를 가질 수 있다.

---
## **Infinities and NaNs**

##### Exponent = 111...1, Fraction = 000...0 
이진 지수가 **모두 1(=max)** 이고, fraction(가수)이 모두 0이면 **양/음의 무한대**를 뜻한다.

##### Exponent = 111...1, Fraction ≠ 000...0
지수가 전부 1인데 가수가 **0이 아닌 경우**, 이는 **정의되지 않은 값**을 나타낸다.

- Not a Number = `NaN` 라고 한다 .
- 계산 불능 또는 수학적으로 정의되지 않은 결과를 말한다. 
- `NaN`도 메모리에 저장되며, 이후 계산에서도 `NaN`가 전파된다.
- ex) `0.0 / 0.0`,  `∞ - ∞`, `sqrt(-1)`

---
## **Floating-Point Addition**

부동소수점(FP) 덧셈을 할 때는 **기본적으로 자릿수(소수점 위치)를 맞춰야 한다.** 그래야 두 수를 **같은 기준에서 더할 수 있기 때문**이다.  
이때 **어느 쪽에 맞춰 자릿수를 조정할까?**  
바로 **지수가 더 작은 쪽을 지수가 더 큰 쪽에 맞춘다.**

즉, **지수가 작은 수의 가수(mantissa)를 오른쪽으로 시프트**해서 자릿수를 맞춘다.  
그 다음 **가수를 더하고**, **정규화(normalization)**를 수행한다.  
이 과정에서 **오버플로우나 언더플로우가 발생했는지도 확인**해야 한다.  
정규화 후에는 **필요에 따라 반올림(rounding)**을 하고,  
마지막으로 **다시 정규화**하여 결과를 완성한다.

이진수의 덧셈도 마찬가지다!

---
## **FP Adder Hardware**

정수의 덧셈에 비해 **부동소수점(Floating Point, FP) 덧셈은 훨씬 더 복잡하다.**  
단순한 정수 덧셈은 두 값을 바로 더하면 되지만,  FP 덧셈은 **지수 정렬 → 가수 정렬(시프트) → 덧셈 → 정규화 → 반올림** 등 여러 단계를 거쳐야 하기 때문이다.

이처럼 복잡한 계산을 **한 사이클(clock cycle)** 안에 모두 끝내려 하면 **오래 걸리고**,  
이를 위해 **클록을 느리게 만들면 전체 명령어 수행 속도가 저하된다.**  
즉, **FP 덧셈 때문에 전체 시스템 성능이 떨어질 수 있다는 것**이다.

그래서 **현대 CPU에서는 FP 연산기(FP Adder)를 별도로 구성**하고,  
이 연산이 **여러 클록 사이클(cycles)** 에 걸쳐 수행되도록 한다.  
또한, **파이프라인(pipelining)** 을 통해 여러 FP 연산이 **연속적으로 실행될 수 있도록 최적화**한다.


![](../images/Pasted%20image%2020250416010946.png)

---

### Compare exponents

![[Pasted image 20250416003846.png]]

부동소수점(FP) 연산에서 **가장 먼저 수행해야 할 작업은 지수(exponent)의 통일**이다.  
앞서 설명했듯이, **지수가 작은 쪽을 지수가 큰 쪽에 맞춰야** 두 가수를 제대로 더하거나 뺄 수 있기 때문이다.

이를 위해 먼저 **두 입력의 지수를 비교**하는 과정이 필요하다.  
각 부동소수점 수의 지수(exponent)는 **Small ALU로 전달되어**,  
<u>두 지수의 차이(Exponent Difference)</u> 를 계산하게 된다.

![](../images/Pasted%20image%2020250416004210.png)

> [!MUX란?]
> 
> MUX는 **Multiplexer(멀티플렉서)**의 줄임말이고,  
> **여러 개의 입력 중에서 하나를 선택해 출력하는 회로**다.
> 

Small ALU에서 두 입력의 **지수 차이(Exponent difference)** 가 계산되면,  
이 값은 Control 유닛으로 전달되어 **어느 입력이 더 작은지를 판단하는 데 사용된다.**

만약 **왼쪽 입력의 지수가 더 작다면**,  
Control은 이를 기준으로 **MUX에 선택 신호 0**을 보낸다.  
이는 왼쪽 입력이 MUX에서 **0번 입력 라인과 연결되어 있기 때문**이다.

반대로, **오른쪽 입력이 더 작다면**, Control은 **MUX에 선택 신호 1**을 보낸다.  
이 경우 MUX는 오른쪽 Fraction을 선택하게 된다.

따라서 **두 개의 MUX 각각은 Control의 판단에 따라**,

- **더 작은 수의 Fraction만을 시프트 유닛으로 보내고**,
    
- **더 큰 수의 Fraction은 그대로 유지되도록 선택하는 방식**이다.


![](../images/Pasted%20image%2020250416005154.png)

이제 지수(exponent)가 맞춰줬으니까 둘을 더한다. 

![](../images/Pasted%20image%2020250416005329.png)

부동소수점(FP) 덧셈의 결과는 항상 **정규화된 형식**, 즉 **`1.xxxxx` 형태**를 만족해야 한다.  
따라서 덧셈 결과가 정규화 조건을 만족하지 않는 경우,  **가수(Fraction)를 왼쪽 또는 오른쪽으로 시프트**하여 정규화를 수행해야 한다.

Big ALU에서 두 가수를 더한 후, 이 결과가 `1.xxxx` 형태가 아니면  가수를 **Shift Left or Right** 하게 된다. 가수를 왼쪽 혹은 오른쪽 시프트를 하면, 지수도 같이 움직여줘야 하므로 `Control` 유닛에서 이 시프트 양을 감지하고,  지수(exponent) 를 증가하거나 감소시킨다. 

이전 단계에서는 두 부동소수점 수 중 **지수가 더 큰 쪽을 기준으로 가수를 정렬하고 연산을 수행**했으며,  
이제 정규화 단계에서는 **그 기준이 되었던 지수 값을 기반으로 결과를 표현**해야 한다. 하지만 두 입력 중 **어느 지수를 기준으로 사용할지 결정해야 하므로**,  이때 **MUX가 필요**하다.

그래서 **두 입력 지수 중에서 Control 유닛이 연산 기준으로 사용했던 지수를 선택**하고, 이후 **정규화 과정에서 가수가 shift된 양에 따라** 선택된 지수를 **증가시키거나 감소시켜서 최종 지수를 계산**한다.

> `Controll` 에서 `Shift let or right` , `Increment or decrement`, 기준이 될 지수 선택을 다한다!

![](../images/Pasted%20image%2020250416010336.png)

이전 단계에서 이미 **지수와 가수의 자릿수를 맞췄기 때문에**, 이제는 **정밀도에 맞게 결과를 반올림**해야 한다.  이를 위해 **Control 유닛은 Rounding Hardware를 제어**하여 **가수(Fraction)** 를 반올림한다.

그런데 반올림 과정에서 **자리올림(carry)** 이 발생할 수 있다.  

예를 들어, 가수가 꽉 찬 상태에서 반올림하면  결과가 `10.000...`처럼 되어  **정규화 형식(1.xxxx)을 다시 만족하지 않게 될 수 있다.**

이 경우 **Control 유닛은 이를 감지하고**,  다시 한 번 **정규화 과정(가수 시프트 + 지수 보정)을 수행**해야 한다. 이때 사용되는 **MUX는 보정할 지수를 다시 선택하여**, **정규화에 필요한 지수 증가를 가능하게 하는 경로**를 제공한다.

> **선택 0은 초기 지수 비교를 위한 경로**,  
> **선택 1은 반올림 결과로 정규화가 깨졌을 때 이를 보정하기 위한 경로**이다

---
## **Floating-Point Multiplication**

부동소수점(FP)의 **곱셈 연산은 덧셈처럼 자리수를 맞추는 과정이 필요하지 않다.**  
곱셈에서는 먼저 **두 지수(Exponent)를 더하고**,  그다음 **가수(Significand, Fraction)끼리 곱한 후**,  
결과에 대해 **정규화(Normalization)** 과정을 거친다. 마지막으로 부호 정한다! 

이후에는 **형식을 맞추고, 필요하면 반올림(Rounding)** 을 수행하여  최종 결과를 IEEE 754 형식에 맞게 완성한다.

---
## **FP Arithmetic Hardware**

부동소수점 곱셈기(FP Multiplier)는 **구조적으로 FP 덧셈기와 유사한 복잡도**를 갖는다.  
다만 차이점은, **가수(Significand)를 더하는 대신 곱하는 연산기(Multiplier)** 를 사용한다는 것이다.

현대의 부동소수점 연산 하드웨어는 다음과 같은 연산들을 지원한다:

- 덧셈(Addition), 뺄셈(Subtraction), 곱셈(Multiplication), 나눗셈(Division)
- 역수(Reciprocal), 제곱근(Square Root)
- 정수 ↔ 부동소수점 간의 변환(FP ↔ Integer Conversion)
    

이러한 연산은 보통 **여러 클럭 사이클에 걸쳐 수행**되며,  
성능 향상을 위해 **파이프라인 구조(Pipelining)** 를 적용하여 병렬로 처리될 수 있다.

---
## **FP Instructions  in MIPS**

부동소수점(Floating Point) 연산은 일반적인 정수 연산과는 달리,  **별도의 부동소수점 유닛(FPU)** 에서 처리되며,  MIPS 구조에서는 이를 **coprocessor 1** 이라고 부른다.

**총 32개의 single-precision 부동소수점 레지스터**를 제공한다.   → `$f0`, `$f1`, ..., `$f31` 
2개씩 묶어서 64비트 **single-precision** 연산에 사용된다.  → 예: `$f0/$f1`, `$f2/$f3`, ...

MIPS ISA **Release 2**부터는 **32개의 64비트 부동소수점 레지스터를 직접 지원한다.**


부동소수점(FP) 명령어는 **오직 부동소수점 레지스터(FP register)** 에서만 동작한다.  
즉, FP 명령어는 **정수 레지스터를 직접 사용하지 않으며**,  정수 명령어 역시 **FP 레지스터를 사용하지 않는다.**

이는 곧, **FP 데이터와 정수 데이터 간의 직접적인 연산은 허용되지 않으며**,  FP ↔ 정수 간 변환은 **명시적인 변환 명령어**를 통해서만 가능하다.
##### FP load and store instructions

`lwc1`, `ldc1`, `swc1`, `sdc1` 

`w` : word(32bit) = register 1개 사용
`d` : double word(64bit) = register 2개 사용
`c` : coprocessor

ex) ldc1 `$f8` 32(`$sp`)  → `$f8` **및** `$f9` (paired register)에 저장

---

##### 1. single-precision, 32bit

`add.s`, `sub.s`, `mul.s`, `div.s`

```assembly
add.s f0$, $f1, $f6   # $f0 ← $f1 + $f6 (float)
```

##### 2. double-precision, 64bit

`add.d`, `sub.d`, `mul.d`, `div.d`

```assembly
mul.d $f4, $f4, $f6   # $f4 ← $f4 × $f6 (double)
```

64bit를 사용하니까, 여기서 사용되는 레지스터의 번호는 무조건 짝수여야 한다. 

##### 3. single-precision and double-precision comparision

`c.xx.s`, `c.xx.d` 여기서 `c`는 comparison

- `xx`는 비교 조건:
    - `eq`: equal (==)
    - `lt`: less than (<)
    - `le`: less than or equal (≤)
    - `ne`: not equal (!=)
    - `ge`: greater than or equal (≥)
    - `gt`: greater than (>)

비교 결과는 FP condition code bit에  참이면 1, 거짓이면 0으로 저장된다. 이 FP condition code bit는 아래와 같은 경우에 사용된다. 

`bc1t Label`: FP condition code bit 가 **참(true)** 이면 분기한다.
    
`bc1f Label`: FP  condition code bit 가 **거짓(false)** 이면 분기한다. 

---
## **FP Example: °F to °C**

C code:
```c
float f2c (float fahr) {
	return ((5.0/9.0)*(fahr - 32.0));
}
```
• fahr in $f12, result in $f0, literals in global memory space

Compiled MIPS code:

```assembly
f2c:lwc1 $f16, const5($gp)
	lwc1 $f18, const9($gp)
	div.s $f16, $f16, $f18  #사실 그냥 5/9 저장해놓으면 됨
	lwc1 $f18, const32($gp)
	sub.s $f18, $f12, $f18
	mul.s $f0, $f16, $f18
	jr $ra
```

**$gp를 기준으로 const5라는 라벨의 주소를 계산하고**,  
그 주소에 있는 **32비트 float 값**을 **부동소수점 레지스터 `$f16`** 에 로드한다.

---
## **FP Example : Array Multiplication**

X = X + Y × Z

All 32 × 32 matrices, 64-bit double-precision elements

```c
void mm (double x[][],double y[][], double z[][]) {
	int i, j, k;
	for (i = 0; i! = 32; i = i + 1)
		for (j = 0; j! = 32; j = j + 1)
			for (k = 0; k! = 32; k = k + 1)
				x[i][j] = x[i][j]+ y[i][k] * z[k][j];
}
```

• Addresses of x, y, z in `$a0`, `$a1`, `$a2`, and i, j, k in `$s0`, `$s1`, `$s2`

![](../images/Pasted%20image%2020250416014153.png)

`x[i]`는 **double형 원소 32개로 이루어진 한 행(row)** 이므로, `i`번째 행까지의 오프셋은 **`i × 32` 개의 요소**가 된다.  각 요소는 8바이트(64bit)이므로, **바이트 단위 오프셋은 `i × 32 × 8`** 이다.

`x[i][j]`는 전체 2차원 배열에서 **(i행 j열)** 위치에 해당하는 원소이며,  요소 순서로는 **`i × 32 + j`번째 요소**이고,  이를 바이트 단위 주소로 계산하면 **`(i × 32 + j) × 8`** 이 된다.

![](../images/Pasted%20image%2020250416014209.png)

---
## **Accurate Arithmetic**

IEEE 754 표준은 **더 정밀하고 예측 가능한 부동소수점 계산을 위해** 다양한 **반올림 제어 기능**을 정의하고 있다.

**추가 정밀도 비트(guard, round, sticky bits)** 를 사용하여  계산 중 발생하는 **오차를 정교하게 처리**할 수 있다. 특히 **Sticky 비트는 잘려나간 모든 나머지 비트 중 하나라도 1이 있으면 1로 설정되고**,  이를 바탕으로 **Round 비트와 함께 반올림 수행 여부가 결정**된다.

> [!note] Round to nearest even
> 일반적으로 **가장 가까운 값으로 반올림**한다.
>
> **정확히 중간일 경우 (0.5)**는 **끝자리가 짝수(even)**가 되도록 반올림한다.
> 예: `1.5 → 2`, `2.5 → 2`, `3.5 → 4`
>         

다양한 **반올림 모드(rounding mode)** 를 지원하여, 프로그래머가 계산 결과의 **수치적 동작을 세밀하게 조정**할 수 있도록 한다.

하지만 **모든 FP 하드웨어가 이 모든 옵션을 구현하지는 않으며**, 실제로는 대부분의 **프로그래밍 언어나 라이브러리에서 기본 설정(round to nearest)을 사용**한다.

---
## **Accurate Arithmetic Example**

> 2진수 기준 맨 뒤가 0이 되도록!

| Binary Input     | Round Up | Round Down | Truncate | Round to Nearest Even |
|------------------|----------|-------------|----------|------------------------|
| +0001.01 (+1.25) | +0010    | +0001       | +0001    | +0001                 |
| -0001.01 (-1.25) | -0001    | -0010       | -0001    | -0001                 |
| +0101.10 (+5.5)  | +0110    | +0101       | +0101    | +0110                 |
| +0100.10 (+4.5)  | +0101    | +0100       | +0100    | +0100                 |
| -0011.10 (-3.5)  | -0011    | -0100       | -0011    | -0100                 |
