---

---

## **ALU Control**


![](../images/Pasted%20image%2020250522141231.png)

ALU 컨트롤 신호를 생성하기 위해 먼저 **opcode(상위 6비트)** 를 참고하여 **1차 디코딩**을 수행한다. 이 과정에서 명령어가 R-type인지, I-type인지, 또는 Load/Store나 Branch 계열인지 판별하게 된다. 이후 **R-type 명령어일 경우에만** 하위 6비트에 위치한 **funct 필드를 추가로 확인하여 2차 디코딩**을 수행하고, 이를 통해 정확한 연산 종류(예: add, sub, and, or 등)를 구분해 ALU에 전달할 제어 신호를 생성한다.


---
## **The Main Control Unit**

![](../images/Pasted%20image%2020250522141418.png)

```assembly
add rd, rs, rt
```

여기서 rs와 rt는 읽기용으로 사용되며, ALU에서 덧셈을 수행한 결과가 rd에 저장된다.

```assembly
lw rt, N(rs)
```

주소 계산을 위해 rs를 읽고, 메모리에서 읽은 값을 rt에 저장하기 때문에 rt는 쓰기용이다.

```assembly
sw rt, N(rs)
```

메모리에 저장할 데이터를 rt에서 가져오고, 주소 계산을 위해 rs를 사용하므로 둘 다 읽기용이다.

lw와 sw에서 rt의 역할이 서로 다르다는 점을 확인할 수 있다.

```assembly
beq rs, rt, N
```

rs와 rt의 값을 비교해야 하므로, 두 레지스터 모두 읽기용으로 사용된다.

정리해보면, rs는 jump 명령을 제외한 대부분의 명령에서 읽기만 하며, 실제로 jump에서도 rs를 읽기는 하지만 명령 실행에 영향을 주지 않기 때문에 사실상 **모든 명령에서 rs는 읽기용**이다.

rt는 `lw` 명령을 제외하고 대부분의 명령에서 읽기용으로 사용된다. 하지만 `lw`에서도 rt를 읽는 것이 명령 실행에 영향을 주지는 않으므로, **모든 경우 rt는 기본적으로 읽기 용으로 간주하고**, `lw`일 때만 **추가로 쓰기 동작이 발생**한다고 보면 된다.

R-type 명령어와 Load 명령어는 **결과를 저장하는 레지스터의 위치(번호)가 다르다.**  R-type 명령어에서는 결과를 저장할 레지스터가 **`rd` 필드에 위치하며, 이는 명령어의 비트 15:11에 해당한다.**  반면, Load 명령어(`lw`)는 결과를 저장할 레지스터가 **`rt` 필드에 위치하며, 이는 비트 20:16에 해당한다.**

---

## **Datapath with Control**

![](../images/Pasted%20image%2020250522142354.png)


##### RegWrite
`RegWrite`는 해당 명령어가 **레지스터에 값을 쓸지 여부**를 결정하는 제어 신호로, **R-format 명령어**와 **`lw` 명령어**인 경우에는 **1**로 설정되어 값을 레지스터에 기록한다. 나머지 명령어들(`sw`, `beq` 등)은 레지스터에 값을 쓰지 않기 때문에 이 경우 `RegWrite`는 **0**이 된다.

##### RegDst
`RegDst`는 **레지스터 파일의 어느 위치에 값을 쓸 것인지를 선택하는 제어 신호**로, **R-format 명령어**의 경우 결과값을 **`rd` 필드(비트 15:11)** 에 저장해야 하므로 이때 `RegDst`는 **1**로 설정된다. 반면, **`lw` 명령어**는 결과를 **`rt` 필드(비트 20:16)** 에 저장하므로 `RegDst`는 **0**이 된다. 그 외 명령어들은 애초에 레지스터에 값을 쓰지 않기 때문에 `RegDst`의 값은 무관하며, 실제로는 `RegWrite`가 0이기 때문에 `RegDst`는 사용되지 않는다.

##### ALUSrc
`ALUSrc`는 ALU의 두 번째 입력을 결정한다. `Read data1`은 항상 ALU와 연결되어 있다. `lw`, `sw`일 때는 상수를 사용하기 때문에 `ALUSrc = 1`, `R-format`이거나 `beq`일 때는 `ALUSrc = 0`이다. 이 경우 레지스터 하나 더 읽은 값을 사용해야 하므로 `Read data2`와 연결된다.

##### PCsrc
`PCSrc`는 다음 PC 값을 결정하는 신호로, `beq` 명령어이고 ALU 결과가 zero일 때 `PCSrc = 1`이 된다. 그 외의 경우는 `PCSrc = 0`이며 기본적으로 `PC + 4`를 사용한다. 즉, `PCSrc`는 단순히 `PC + 4`를 사용할지, 분기 상수를 더한 값을 사용할지를 결정하는 신호다.

##### MemWrite / MemRead
`MemWrite` sw 일 때만 1, 나머지는 0
`MemRead` lw 일 때만 1, 나머지는 0

##### MemtoReg
`MemtoReg` 메모리에서 읽은 걸 레지스터에 저장해야 하니까 lw만 1, ALU의 결과를 사용해야 하는 R-format 은 0, 나머지는 상관없다. 

---
## **R-type Instruction**

![](../images/Pasted%20image%2020250522144036.png)

RegDst : R-type은 15-11비트에 있는 rd를 사용하기 때문에 1  
ALUSrc : rs는 항상 읽어서 ALU에 들어가고 레지스터를 하나 더 읽어서 ALU에 넣어야 하므로 0  
MemtoReg : R-format은 ALU의 결과가 rd에 들어가야 하므로 0  
RegWrite : 레지스터에 값을 써야 하므로 1  
MemRead / MemWrite : 메모리를 사용하지 않으므로 둘 다 0  
Branch : 브랜치 명령어가 아니므로 0

---
## **Load Instruction**

![](../images/Pasted%20image%2020250522144549.png)

RegDst : lw는 결과물이 rt(20-16)로 가기 때문에 0  
ALUSrc : 주소 계산에 상수를 사용해야 하므로 1  
MemtoReg : 메모리에서 읽은 값을 레지스터로 보내야 하기 때문에 1  
RegWrite : 레지스터에 값을 써야 하므로 1  
MemRead / MemWrite : 메모리에서 읽어야 하므로 MemRead는 1, MemWrite는 0  
Branch : 브랜치 명령어가 아니므로 0

---
## **Branch-on-Equal Instruction**

![](../images/Pasted%20image%2020250522144902.png)

RegWrite : 레지스터 쓰기를 하지 않으므로 0  
RegDst : 두 레지스터를 비교만 하기 때문에 사용하지 않는다  
MemtoReg : RegWrite가 0이므로 상관 없다  
ALUSrc : 두 레지스터를 비교해야 하므로 Read data2를 사용해야 하며, 따라서 0  
MemRead / MemWrite : 메모리 접근이 없으므로 둘 다 0  
Branch : beq이므로 1, 다만 Branch 신호만으로 점프하지 않고 ALU 결과가 zero일 때 함께 작동해 점프가 수행된다

---
## **Implementiong Jumps**

![](../images/Pasted%20image%2020250522145419.png)

opcode가 jump라고 판별되면, 명령어의 address 필드를 이용해 **새로운 PC 값을 계산**한다. 이때 PC는 다음과 같이 구성된다: **현재 PC의 상위 4비트 + (address 필드 << 2)**. 즉, address 뒤에 00을 붙여 왼쪽으로 2비트 시프트하고, 이 값을 현재 PC의 상위 4비트와 결합하여 **완전한 32비트의 jump target 주소**를 만든다.

![[Pasted image 20250522145804.png]]

아까까지는 PC를 계산할 때 **PC + 4**를 그대로 쓸지, 아니면 **PC + 4 + (immediate × 4)**로 분기할지를 결정하는 방식이었다. 하지만 **jump 명령어인 경우**에는 이 두 가지 경우를 **완전히 무시하고**, **(PC + 4)의 상위 4비트 + address 필드 + 00**을 조합하여 **즉시 해당 위치로 이동한다.** 즉, jump는 분기와 달리 조건 검사 없이 **절대 주소로 점프하는 방식**이다.

그래서 RegWrite, MemRead, MemWrite은 0,  `jump` control이 1이 되고, 나머지는 상관없다. 

----

## **Performance Issues**

가장 큰 delay를 가지는 연산이 전체 clock 주기를 결정하게 된다. 일반적으로 가장 긴 지연을 가지는 명령어는 `lw`이며, 이 명령은 Instruction memory → Register file → ALU → Data memory → Register file의 단계를 모두 거치기 때문에 전체 경로가 길고 시간이 오래 걸린다. 

문제는 명령어마다 수행 시간이 제각각인데, 그때그때 clock 주기를 바꾸는 것은 현실적으로 불가능하다. 따라서 모든 명령어가 **고정된 clock 주기 안에서 실행되도록 설계해야 하며**, 결국 **가장 긴 시간(lw 기준)에 맞춰 clock 주기를 설정해야 하므로 전체적으로 비효율적**이 된다.

> 이 문제를 해결하기 위한 방법이 바로 `Pipelining`이다. 

> [!note] Pipelining
> 
> clock마다 새로운 명령어가 들어오도록 하고, 명령어의 실행을 여러 단계로 나누어 각 단계에서 병렬로 처리되도록 한다. 즉, **이전 명령어가 사용한 자원이나 회로를 다음 명령어가 재사용할 수 있도록 순차적으로 넘겨주는 방식**이다. 
> 
> 이렇게 하면 **하나의 명령어가 끝날 때까지 기다리지 않고**, 각 clock 사이클마다 새로운 명령어가 들어와 **CPU 자원을 더 효율적으로 사용할 수 있게 된다.**


---
## **Pipelining Analogy**

![](../images/Pasted%20image%2020250522150610.png)

• **4개의 load 명령어가 있을 때**
	파이프라인 도입 전후의 성능을 비교한 Speedup은  **Speedup = 8 / 3.5 = 2.3** (총 8 사이클 소요되는 순차 실행 대비 3.5 사이클에 완료되었을 때)

• **Non-stop 방식으로 파이프라인이 완전하게 채워진 상태**
  **Speedup = 2n / (0.5n + 1.5) ≈ 4**,  
  이는 파이프라인의 **스테이지 수가 4단계**임을 의미한다.

---
## **MIPS Pipeline**

• IF: instruction 읽는 단계
• ID: Instruction decoding 하고, 레지스터 읽기 ( 일단 레지스터 읽고, 나중에 골라서 쓰기 )
• EX: ALU 연산 또는 주소 계산하는 단계
• MEM: 메모리에서 데이터를 읽거나 쓰는 단계
• WB: 레지스터에 결과물 쓰는 단계

MIPS는 5개의 단계로 구분한다. 

---
## **Pipeline Performance**

단계가 5개라서 5배의 성능을 보여주는 것은 아니다. 단계마다 걸리는 시간이 다르기 때문이다. 그래서 단계를 나눴지만, 가장 길게 걸리는 단계의 시간으로 cycle을 설정한다. 

![](../images/Pasted%20image%2020250522151415.png)

위의 표를 보면 단계에서 가장 길게 걸리는 시간이 200ps 이기 때문에 시간을 200ps로 설정해야 한다. 

![](../images/Pasted%20image%2020250522151637.png)

그래서 비교적 짧게 걸리는 Reg 접근 단계에서는 남는 시간이 생긴다. 


---
## **Pipeline Speedup**

모든 파이프라인 스테이지가 **균형 있게 구성되어 있다면**, 즉 각 스테이지가 **동일한 시간**을 소요한다면,  
  
  **파이프라인된 명령어 간 시간 = 비파이프라인 명령어 간 시간 ÷ 스테이지 수**가 된다.  

만약 스테이지 간 시간이 **불균형하다면**, 전체 성능 향상은 줄어들게 된다.  

파이프라이닝으로 얻는 **속도 향상(Speedup)은 처리량(Throughput)이 증가**했기 때문이며, **각 명령어의 지연 시간(Latency)**, 즉 하나의 명령어가 끝날 때까지 걸리는 시간 자체는 **줄어들지 않고 오히려 증가한다.**

---
## **Pipelining and ISA Design**

모든 instruction이 32비트로 고정되어 있기 때문에, MIPS에서는 **Decoding을 한 사이클 내에 쉽게 수행할 수 있다.** 반면, x86 아키텍처는 명령어 길이가 가변적이기 때문에 **디코딩이 복잡하고 어려운 구조**이다. 

또한 **레지스터 접근도 단순하게 설계되어 있어 읽는 작업이 용이하다.** 

Load/Store 명령어도 마찬가지로 수행이 쉽다. MIPS에서는 주소 계산 방식이 **하나로 통일되어 있기 때문에**, 주소 계산과 메모리 접근을 **각각 한 스테이지씩 할당**하면 된다. 

게다가 **메모리 주소들이 정렬(aligned)되어 있기 때문에**, 접근 또한 **간단하고 효율적으로 처리할 수 있다.**

---
## **Hazards**

다음 사이클에 instruction이 정상적으로 실행되는 것을 **방해하는 상황**들이 발생할 수 있다.

##### Structure hazards
하드웨어 자원이 동시에 여러 instruction에 의해 사용되어 **충돌이 발생하는 상황**이다.  
##### Data hazard
다음 instruction이 **연산에 필요한 데이터 값을 사용하려고 하지만**, 그 값이 **이전 instruction에서 아직 계산 중이거나 저장되지 않은 상태**일 때 발생한다.

##### Control hazard
분기(branch)나 jump와 같이 **다음에 실행할 instruction의 흐름이 이전 instruction 결과에 의존하는 경우** 발생한다.  정확한 분기 결과가 나올 때까지 어떤 instruction을 실행해야 할지 모르는 상황이다.

---
## **Structural Hazards**

금 다루고 있는 MIPS 구조에서는 이러한 문제가 발생하지 않는다. 

> 우리는 instruction이 저장되는 메모리와 데이터(레지스터) 메모리가 **서로 분리되어 있다고 가정**하고 있지만, 실제로는 instruction과 data 모두 **하나의 메모리**에 저장되는 경우가 많다. 

이 경우 instruction을 읽기 위해 메모리에 접근해야 하고, 동시에 데이터를 저장하기 위해서도 메모리에 접근해야 하는데, **메모리는 한 번에 하나의 접근만 허용**하기 때문에 **resource 충돌이 발생한다.** 이로 인해 한 cycle을 날리게 되며, 파이프라인 상에는 **무의미한 명령어(bubble)** 를 넣어 **구조적 충돌을 회피**해야 한다.

---
## **Data Hazards**

![](../images/Pasted%20image%2020250522153646.png)


지금 `add $s0, $t0, $t1` 명령어에서 계산된 결과 `$s0`는 다음 명령어에서 바로 사용되고 있다. 이때 `add` 명령어는 MEM 단계에서 실질적인 동작은 없지만, **구조 통일을 위해 파이프라인 단계는 그대로 거친다고 가정**하자. 

실제 연산은 EX 단계에서 수행되며, 결과 값이 **레지스터에 쓰이는 시점은 WB 단계**이다. 하지만 만약 바로 다음 명령어인 `sub $s2, $s0, $s3`가 실행된다면, 이 명령은 **ID 단계에서 레지스터 값을 읽는데**, 이 시점에는 아직 `$s0`의 값이 **WB 단계에서 갱신되지 않았기 때문에 이전 값이 반영된다.** 

따라서 이런 상황에서는 파이프라인 사이에 **두 사이클 정도 bubble(무의미한 명령어)**을 삽입해주면, **이전 명령의 결과가 레지스터에 반영된 이후에 읽게 되어 올바른 값으로 연산이 가능해진다.**

---
## **Forwarding (aka Bypassing)**

이처럼 bubble을 계속 삽입하면 CPI가 증가하게 된다. 이를 해결하기 위해 추가적인 최적화 작업이 필요하다. 

사실 연산 결과 자체는 **EX 단계에서 이미 계산이 완료되고**, **WB 단계에서는 단순히 그 결과를 레지스터에 저장만** 하는 것이다. 

그렇기 때문에 굳이 결과가 WB까지 도달할 때까지 기다리지 않고, **EX 단계에서 나온 결과 값을 바로 다음 instruction에 전달하는 방식**, 즉 **forwarding(또는 bypassing)** 기법을 사용하면 불필요한 bubble 삽입 없이도 데이터 의존 문제를 어느 정도 해결할 수 있다.

![](../images/Pasted%20image%2020250522154549.png)

레지스터 반영까지 기다리지 말고, 연산 결과를 적절하게 사용하자!

---
## **Load-Use Data Hazard**

위의 방식을 사용하면 모든 Data Hazard를 막을 수 있을까? 아니다.

![[Pasted image 20250522154951.png]]

아까는 R-format 명령어였기 때문에 EX 단계에서 결과물이 바로 나왔고, forwarding을 통해 다음 instruction에 값을 넘겨줄 수 있었다. 

하지만 `lw`와 같은 Load 명령어의 경우, **실제 데이터는 MEM 단계에서 메모리로부터 읽혀지기 때문에**, EX 단계에서는 아직 유효한 값이 없다. 그래서 아무리 forwarding을 사용하더라도 다음 명령어가 그 값을 바로 사용할 수 없고, **데이터 hazard가 발생한다.** 

이 경우에는 **한 사이클 정도 bubble을 삽입해야 하며**, 이를 통해 Load 명령어 이후의 instruction이 올바른 데이터를 참조할 수 있도록 한다.

> forwarding 을 하면 1 cycle 안 하면 2cycle 버블이 생긴다. 

---
## **Code Scheduling to Avoid Stalls**

다음 instruction에서 바로 load된 값을 사용하는 것을 피하기 위해, **코드의 순서를 변경하여 hazard를 회피할 수 있다.** 즉, **load 명령의 결과를 바로 사용하는 instruction을 지연시키고**, **그 사이에 이전 코드의 영향을 받지 않는 명령어를 먼저 실행**함으로써 bubble의 삽입을 줄일 수 있다. 이렇게 하면 불필요한 stall 없이 파이프라인을 효율적으로 사용할 수 있다.

![](../images/Pasted%20image%2020250523205754.png)

---
## **Control Hazards**

branch 명령어의 결과에 따라 **다음에 실행될 instruction이 결정되기 때문에**, 보통은 **EX 단계에서 분기 여부가 결정되며**, 그 전까지는 어떤 instruction을 가져올지 확정할 수 없다. 이로 인해 파이프라인에는 **최소 두 개의 bubble이 삽입**되어야 다음 명령어를 정확히 실행할 수 있다. 

이를 개선하기 위해, 하드웨어적으로 레지스터를 읽은 직후, 즉 **ID 단계와 EX 단계 사이에 간단한 비교용 ALU를 추가하여 ID 단계에서 분기 조건을 미리 판단**할 수 있도록 하면, 한 사이클 정도는 빠르게 처리할 수 있다. 

하지만 이 최적화를 적용하더라도 **분기 결과가 완전히 확정되기까지는 최소 한 사이클의 bubble이 필요**하므로, 완전히 제거할 수는 없다.

![](../images/Pasted%20image%2020250523210144.png)

bubble을 채워 넣어서 한 사이클을 멈추는 행위를 stall이라고 한다.

---
## **Branch Prediction**

branch instruction은 프로그램 내에서 굉장히 자주 등장하는 명령어이기 때문에, 매번 한 사이클씩 bubble을 채워야 한다면 전체 성능에 큰 영향을 미친다. 

이를 해결하기 위해 **branch prediction**, 즉 **분기 예측 기법**이 사용된다. 분기 결과를 미리 예측하고, **예측된 방향으로 다음 명령어를 먼저 가져와 실행**하는 방식이다. 

예측이 맞으면 그대로 이어서 실행하면 되고, **예측이 틀렸다면 그때 실행한 명령어를 취소(flush)하고 실제 분기된 경로로 다시 fetch**하면 된다. 어차피 무조건 stall하는 것보다, **성공 확률이 높은 예측을 통해 평균적인 성능을 끌어올리는 쪽이 훨씬 효율적**이다.


![](../images/Pasted%20image%2020250523211006.png)

---
## **More-Realistic Branch Predicion**

예측 방식은 매우 중요하다. 왜냐하면 **프로그램마다 taken과 not taken의 분포가 다르기 때문**이다.

##### Static branch prediction

고정된 방식으로 예측하는 방법으로, **일반적인 분기 패턴**에 기반하여 판단한다.  
예를 들어 반복문에서는 **보통 루프를 다시 반복하는 경우가 많기 때문에** backward jump는 taken, forward jump는 not taken으로 정해놓고 예측한다.  이 방식은 **구현이 단순하고 어느 정도 효과가 있지만**, 다양한 상황에서 높은 정확도를 기대하긴 어렵다.

##### Dynamic branch prediction

실행 중인 상황을 실시간으로 기록하고 그 정보를 기반으로 예측하는 방식이다.  
**코드는 반복적으로 실행되는 경우가 많기 때문에**, 이전 분기 결과를 기억해두고 다음에도 비슷한 행동을 할 거라고 가정한다.  즉, 이전에 taken이었으면 다음에도 taken으로 예측하고, **예측이 틀리면 stall한 뒤 예측 정보를 갱신**한다.  이 방식은 시간이 지날수록 예측 정확도가 높아지는 경향이 있다.

---
## **MIPS Pipelined Datapath**

![](../images/Pasted%20image%2020250523212445.png)

여기서 말하는 Register는 데이터가 **막힘 없이 흘러가는 흐름 속에서**, 중간중간에 **댐처럼 구분을 만들어주는 역할**을 한다. 파이프라인의 각 단계 사이에 있는 레지스터는 **이전 단계에서 생성된 데이터를 잠시 저장하고**, **다음 단계로 넘겨주는 경계 역할**을 하여 각 스테이지가 **독립적으로 동작할 수 있도록 구분**해준다.

![](../images/Pasted%20image%2020250523212652.png)

각 파이프라인 단계 사이에는 **레지스터가 필요하다.** 이는 **이전 사이클에서 생성된 정보를 저장**해두기 위한 용도로 사용된다. 매 Clock마다 **이 레지스터에 저장된 값이 다음 스테이지로 전달**되며, 파이프라인이 순차적으로 진행된다.

>즉, **각 단계 사이에 존재하는 중간 레지스터**가 파이프라인의 흐름을 유지시켜주는 핵심 역할을 한다.

**PC(Program Counter)** 역시 마찬가지로, **clock이 바뀔 때만 값이 갱신되는 레지스터**이다.

---
## **IF for Load, Store**

![](../images/Pasted%20image%2020250523213335.png)

1. **PC + 4**를 먼저 계산하여 다음 instruction의 주소를 미리 준비하고, 다음 명령어를 바로 실행할 수 있도록 한다.
    
2. 현재 PC 값을 이용해 **instruction memory에서 해당 instruction을 fetch**한다.
    
3. 계산된 PC + 4 값과 가져온 instruction은 **IF/ID 레지스터에 저장**되어 다음 ID 단계에서 사용될 수 있도록 한다.

---
## **ID for Load, Store**

![](../images/Pasted%20image%2020250523213712.png)

IF/ID에 저장되어 있던 데이터는 **다음 clock 사이클에 ID 단계로 넘어온다.** 레지스터에 있는 값이 실제로 사용될지 아닐지는 아직 모르지만, **일단 필요한 두 개의 레지스터 값을 모두 읽는다.** 

또한, 명령어에 포함된 **immediate 값도 추출하여 sign-extension을 수행**한다. 

이렇게 읽어들인 값들과 제어 신호 등은 **ID/EX 레지스터에 저장**되고, **다음 clock 사이클까지 대기**하게 된다.

---
## **EX for Load**

![](../images/Pasted%20image%2020250523214017.png)

다음 clock이 오면 ALU에서 주소 계산 

---
## **MEM for Load**

![](../images/Pasted%20image%2020250523214137.png)

전 단계에서 주소 계산을 했고, 그 주소가 넘어오면 그 주소에서 읽는다. 주소 읽은 값을 MEM/WB에 저장

---
## **WB for Load**

![](../images/Pasted%20image%2020250523214236.png)

WB을 수행하기 위해 다시 ID 단계에 있는 레지스터로 돌아가 값을 쓰려고 하면 문제가 생긴다. 왜냐하면 그 시점의 레지스터는 **현재 WB를 하려는 instruction의 레지스터가 아닌**, **그보다 두 세 사이클 이후에 들어온 instruction의 레지스터 정보로 덮여져 있기 때문**이다. 따라서 WB 단계에서 잘못된 레지스터에 값을 쓰게 되어 **데이터 오류가 발생하게 된다.**

따라서 제대로 된 WB을 하기 위해서 WB이 적용되어야 하는 레지스터의 번호도 같이 넘어와야한다.

![](../images/Pasted%20image%2020250523214641.png)

제대로 된 그림에서는 말한 것처럼, **처음에 Write register로 사용되는 레지스터 번호를 IF/ID → ID/EX → EX/MEM → MEM/WB** 순으로 **각 파이프라인 레지스터에 함께 전달**한다. 이렇게 해야 WB 단계에서 **정확히 어떤 레지스터에 결과 값을 써야 하는지**를 파악할 수 있고, **다른 instruction의 레지스터 정보와 혼동되지 않으며**, **정확한 위치에 WB(Write Back)** 이 이루어질 수 있다.

---
## **EX for Store**

![](../images/Pasted%20image%2020250523214843.png)

![](../images/Pasted%20image%2020250523214858.png)

Store 명령어(`sw`)는 **레지스터에 값을 쓰는 동작(WB)을 하지 않기 때문에**, 파이프라인의 **마지막 단계(WB)에서는 아무 동작도 수행하지 않는다.** 실제 데이터는 **MEM 단계에서 메모리에 저장되며**, 그 이후 단계에서는 **결과를 다시 레지스터로 되돌릴 필요가 없기 때문에** WB 단계는 단순히 통과만 하게 된다.

---
## **Multi-Cycle Pipeline Diagram**

![](../images/Pasted%20image%2020250523215723.png)



> [!note] 들어가기전에
> 네모는 **레지스터나 메모리**를 나타내며,  **실선 네모**는 **메모리**, **점선 네모**는 **레지스터**를 의미한다.  
> 네모의 **뒤쪽에 색이 칠해져 있으면 읽기**, **앞쪽에 색이 칠해져 있으면 쓰기**를 나타낸다.
> 
> 레지스터는 **읽기와 쓰기를 동시에 수행할 수 있고**,  메모리는 **한 번에 읽기나 쓰기 중 하나만 가능**하다.  
> 
> 같은 번호의 레지스터여도 상관 없다.
> 

![](../images/Pasted%20image%2020250523220017.png)

---
## **Single-Cycle Pipeline Diagram**

![](../images/Pasted%20image%2020250523220038.png)

![](../images/Pasted%20image%2020250523220330.png)

각 파이프라인 단계에서 사용되는 **Control 신호들은 모두 ID 단계에서 생성된다.** 하지만 이 신호들은 **바로 그 자리에서 사용되는 것이 아니라**, 이후 EX, MEM, WB 단계에서 사용되기 때문에, **생성된 시점(ID 단계)과 실제로 사용되는 시점 사이에 시간 차이가 있다.** 따라서 **레지스터 값들뿐만 아니라**, Control 신호들인 **RegWrite, ALUSrc, ALUOp, RegDst 등도 함께 파이프라인 레지스터를 통해 다음 단계로 전달**해줘야 올바르게 동작할 수 있다.


![](../images/Pasted%20image%2020250523220445.png)

---
## **Pipelined Control**

![](../images/Pasted%20image%2020250523221155.png)

`RegDst`는 **어떤 레지스터에 값을 쓸지를 결정하는 Control 신호**로, 목적지 레지스터가 `rt`일 수도 있고 `rd`일 수도 있기 때문에 필요하다. 다만, 이 신호는 **어떤 필드를 선택할지만 결정하는 역할**이므로, 꼭 EX 단계에서 ALU 연산과 동시에 존재할 필요는 없다. 실제로는 **EX 단계 이전에 선택만 해두고**, 이후 WB 단계에서 **결과 값을 해당 레지스터에 쓸 때 쓰기 대상이 명확히 지정되어 있으면 되기 때문에**, 반드시 EX 단계에서 사용되어야 하는 신호는 아니다.

---
## **Data Hazards in ALU Instructions(R-format)**

```
sub $2, $1,$3
and $12,$2,$5
or $13,$6,$2
add $14,$2,$2
sw $15,100($2)
```

![](../images/Pasted%20image%2020250523221542.png)

```
add $14,$2,$2
sw $15,100($2)
```

`sub` 의 결과가 반영되는 시점보다 같거나 그 뒤기 때문에 이 2개 instruction은 hazard 발생하지 않는다. 

```
and $12,$2,$5
or $13,$6,$2
```

Data Hazard는 발생하지만 forwarding으로 해결 가능하다.

![](../images/Pasted%20image%2020250523222001.png)

---
## **Forwarding Paths**

![](../images/Pasted%20image%2020250523223055.png)

EM 결과물이 ALU 상단으로 들어갈 수도 있고, ALU 하단으로 들어갈 수도 있다.  마찬가지로 WB 결과물이 ALU 상단이나 하단으로 들어가는 경우도 있을 수 있다.

이처럼 ALU 입력에 들어가는 값을 결정할 때,  **레지스터 파일에서 읽은 값을 그대로 쓸지**,  아니면 **MEM 단계나 WB 단계에서 넘어온 결과 값을 Forwarding해서 사용할지**를 판단해야 한다.

이 판단은 **Forwarding Unit**이 담당하며,  따라 ALU의 입력을 어떤 소스로 설정할지 **Control 신호를 생성**한다.  이렇게 하면 데이터 hazard를 해결하면서 bubble 없이 실행이 가능해진다.

---
## **Detecting the Need to Forward**

Forwarding Unit이 어떤 값을 전달할지 결정하기 위해서는 **단순히 현재 instruction의 정보만으로는 부족하다.** 현재 instruction이 사용하는 **레지스터 번호와**, 이전 instruction들이 **결과를 저장할 레지스터 번호가 일치하는지를 비교해야 한다.**  

>따라서 **이전 instruction의 목적지 레지스터 번호(RegisterRd)** 를 파이프라인을 통해 **계속 함께 전달해야 한다.**

이때 ID 단계에서 `RegisterRs`와 `RegisterRt` 정보를 추출할 수 있으므로,  이 값을 파이프라인 레지스터를 통해 전달하며, 예를 들어 `ID/EX.RegisterRs`, `ID/EX.RegisterRt` 형태로 EX 단계에서도 사용할 수 있도록 한다.

![](../images/Pasted%20image%2020250523224824.png)

**데이터 hazard는 다음과 같은 조건에서 발생한다.**

- 1a. `EX/MEM.RegisterRd == ID/EX.RegisterRs`
    
- 1b. `EX/MEM.RegisterRd == ID/EX.RegisterRt`
    
- 2a. `MEM/WB.RegisterRd == ID/EX.RegisterRs`
    
- 2b. `MEM/WB.RegisterRd == ID/EX.RegisterRt`
    

이러한 상황이 감지되면, **EX/MEM 또는 MEM/WB 파이프라인 레지스터에서 Forwarding이 필요**하다고 판단하여,  **Forwarding Unit은 ALU 입력에 어떤 값을 연결할지 결정하는 Control 신호를 생성**한다.  

---

![](../images/Pasted%20image%2020250523225242.png)

```shell
sw $1, N($s2)
add $4, $3, $5 
```

위 예시에서 `sw $1, N($s2)`와 `add $4, $3, $5`는 언뜻 보면 서로 아무 관련 없어 보이고, **hazard가 없어 보일 수 있다.** 하지만 만약 `sw`의 **상수 필드(즉, 즉시값)의 상위 비트**와 `add`의 `rd` 필드 값이 **우연히 일치**한다면, **겉으로는 문제가 없어 보여도 실제로는 데이터 hazard가 발생**할 수 있다.

이런 상황을 정확히 판단하기 위해서는 단순히 **레지스터 번호가 겹치는지만 확인해서는 안 되고**, 그 **레지스터가 쓰기(업데이트) 대상인지 여부**를 함께 확인해야 한다. 이를 위해 다음과 같은 조건을 고려해야 한다:

1. **이전 instruction이 R-format인지**: R-format 명령은 연산 결과를 `rd`에 저장한다.
    
2. **이전 instruction이 RegWrite를 수행하는지**: 실제로 레지스터에 값을 쓰는 명령어인지 확인해야 한다.
    
3. **이전 instruction의 목적지 레지스터(rd)가 $zero가 아닌지**: `$0` 레지스터는 항상 0으로 고정되어 있으므로, 여기에 쓰는 것은 의미가 없다.
    

즉, 정확하게 hazard를 판단하려면 단순한 **번호 일치**가 아니라, 그 **레지스터가 쓰기 대상이었는지 여부까지 확인**해야 한다. 그래야 **잘못된 forwarding이나 stall을 방지**할 수 있다.

![](../images/Pasted%20image%2020250523230314.png)

![](../images/Pasted%20image%2020250523230210.png)

---
## **Double Data Hazard**

```
add $1,$1,$2
add $1,$1,$3
add $1,$1,$4
```

```
add $1,$1,$3
add $1,$1,$4
```

이것만 보면 EX/MEM 단계의 값을 Forwading 판단한다.

```
add $1,$1,$2
add $1,$1,$4
```

이것만 보면 MEM/WB 단계의 값을 Forwarding 판단한다.

이런 경우에는 **어떤 단계의 값을 forwarding해야 할지 판단할 때**, 항상 **가장 최근에 계산된 결과값만 forwarding**해야 한다.  즉, **전전 instruction의 결과는 무시하고**, **직전 instruction(EX/MEM)** 의 결과를 우선적으로 사용해야 한다.

따라서 **MEM/WB 단계에서 forwarding을 수행하려면 다음 두 가지 조건을 모두 만족해야 한다:**

1. **레지스터 번호가 현재 instruction과 일치해야 한다.**
    
2. **EX/MEM 단계에서 이미 forwarding할 값이 없는 경우에만 수행되어야 한다.**
    

즉, **MEM/WB forwarding은 EX/MEM forwarding이 없을 때만 수행되도록 우선순위를 낮춰야 하며**,  
이를 통해 **가장 최신의, 정확한 데이터만 forwarding**되도록 제어할 수 있다.

---
## **Revised Forwading Condition**

MEM hazard가 참인지 확인도 해야하지만, EX hazard가 거짓인지도 확인해야 한다. 만약 Ex hazard까지 참이라면, EX의 rd를 반영해야겠죠?


---
## **Load Use Data Hazard**

앞에서는 R-format일 경우에 data hazard에 대해 알아봤다.

![](../images/Pasted%20image%2020250525180132.png)

ID stage에서 판단한다. 
ID 스테이지에서 rs 또는 rt가 EX 스테이지의 dst(rt)와 같고, EX 스테이지에 instruction이 load이 경우 stall 하고 버블을 채워 넣는다. 

버블을 채워 넣는다는 것은 **파이프라인 상에서 명령어를 실행하지 않고 비워두는 자리(dummy cycle)를 만드는 것**을 의미한다. 실제로는 **해당 사이클에 아무 명령도 수행하지 않도록 제어 신호(Control signals)를 모두 0으로 설정**하는 방식으로 구현한다.

버블을 삽입하려면 다음 세 가지 조치를 취해야 한다:

1. **Control signals = 0**  
    → EX, MEM, WB 단계에서 동작이 일어나지 않도록 모든 제어 신호를 0으로 만들어 "아무 동작도 하지 않는 명령"처럼 만든다.
    
2. **PC 업데이트 금지**  
    → 현재 instruction이 아직 완료되지 않았기 때문에 **다음 instruction으로 넘어가면 안 된다.** PC는 그대로 유지한다.
    
3. **IF/ID 파이프라인 레지스터도 멈춤**  
    → 다음 instruction이 IF 단계에서 들어오지 않도록 **IF/ID 레지스터의 값도 고정(stall)** 시켜야 한다.  
    → 그래야 **이번 사이클을 건너뛰고 같은 instruction을 다시 처리**할 수 있다.
    

![](../images/Pasted%20image%2020250525180622.png)

---
## **Branch Hazards**

![](../images/Pasted%20image%2020250525181844.png)

branch instruction에서는 EX 단계에서 ALU 결과가 나오고, MEM 단계까지 branch 결정이 일어난다. 앞에서는 너무 손해가 커서 branch not taken 예측 후 틀리면 branch 하든 일단 예측을 해서, 틀리면 그거에 맞는 instruction 실행했다. 

예측이 틀릴 떄마다  손해가 크다. 이걸 없애고 싶다.

---
## **Reducing Branch Delay**

하드웨어적으로 최적화를 하기 위해, **branch 판단을 EX 단계까지 기다리지 말고** 더 앞 단계인 **ID 단계에서 처리**하도록 한다. 이를 위해 거대한 ALU가 아니라, **비교만 수행하는 작은 ALU**를 사용해 **레지스터 값이 같은지만 판단**하는 간단한 로직을 **ID 스테이지에 배치**한다. 또한, **branch target 주소를 계산하는 연산기**도 함께 **ID 스테이지로 당긴다.**

이러한 연산은 복잡하지 않기 때문에 앞 단계에서도 충분히 처리할 수 있으며, **branch 결정이 빨라질수록 예측이 실패했을 때 되돌려야 할 파이프라인 스테이지 수를 줄일 수 있다.** 즉, **branch로 인한 손실을 줄이고 전체 파이프라인 성능을 향상시키는 효과**가 있다.

>**핵심은 결정은 빠르게! 손해는 최소로!** 이다.

```
36: sub $10, $4, $8
40: beq $1, $3, 7
44: and $12, $2, $5
48: or $13, $2, $6
52: add $14, $4, $2
56: slt $15, $6, $7
...
72: lw $4, 50($7)
```

![](../images/Pasted%20image%2020250525182636.png)


![](../images/Pasted%20image%2020250525182749.png)

어쨌든 이렇게 해도 한 사이클 버블이 생기는건 피할 수 없다. 

---
## **Data Hazarads of Branches**

branch 자체에서 사용하는 register에서 hazard가 발생할 수도 있다. 

![](../images/Pasted%20image%2020250525183004.png)

이런건 forwarding을 통해 해결 가능하다. 

하지만 아닌 경우도 물론 있다.

![](../images/Pasted%20image%2020250525183143.png)

비교를 하기 위한 `$1` `$4` 레지스터는 ID 단계에서 필요한테, 이전 instuction에 의해서 같은 시점에 생긴 다면 어쩔 수 없이 한 사이클 stall이 필요하다. 

한 사이클 생길 수도 있고, 두 사이클 stall이 필요할 수도 있다

![](../images/Pasted%20image%2020250525183348.png)

beq 이전에 lw가 나오고, 같은 레지스터를 사용한다면 2사이클 stall이 되고, 또 이 상황에서 예측 실패를 한다면 stall이 하나 더 늘어나게되겠죠?

실제 하드웨어는 이것보다 더 손해가 심하다. 그래서 실제로 브랜치 예측이 굉장히 주용한 문제이다.

---
## **Dynamic Branch Prediction**

**더 깊은 파이프라인**이나 **슈퍼스칼라 아키텍처**에서는 branch로 인한 페널티가 훨씬 더 커지기 때문에, 이를 줄이기 위해 **동적 분기 예측(Dynamic Prediction)** 을 사용한다.  

이를 위해 **Branch Prediction Buffer** 또는 **Branch History Table**이라 불리는 구조를 사용한다.  이 테이블은 **최근에 실행된 branch instruction의 주소를 인덱스로 사용**하며, 그 명령어의 **과거 분기 결과(taken / not taken)** 를 저장하고 있다.
모든 주소를 저장하는 것은 아니고, 일부 주소만 저장한다. 

분기 명령어가 실행되면,  해당 테이블을 참조해 **과거와 동일한 분기 결과를 예측**하고,  **fall-through(분기 안 함)** 또는 **target 주소(분기 함)** 로부터 명령어 fetch를 시작한다.

만약 예측이 틀렸다면,  **파이프라인을 flush(비우고)** 예측을 반대로 뒤집어(예: taken → not taken),  **올바른 경로로 다시 fetch를 시작한다.**

---
## **1-Bit Predictor: Shortcoming**

![](../images/Pasted%20image%2020250525214357.png)

이중 for문과 같이 **분기 패턴이 규칙적으로 반복되는 경우**, 1-bit predictor는 한계가 있다.

실제: TTTTNTTTTNT...`
예측: TTTT**T**NTTTT**T**NT...

예를 들어 실제 분기 동작이 `TTTTNTTTTNT...`처럼 **계속 taken 하다가 한 번 not taken**, 다시 taken, 또 not taken…과 같은 패턴이라면,  1-bit predictor는 **이전 결과 하나만 기억**하기 때문에, 상태가 바뀔 때마다 **두 번 연속 오답을 내게 된다.**

지금은 이전 결과를 한 비트만 저장하니까, 즉 이전 결과만 저장해서 문제가 발생한다. 그렇다면 저장 비트를 늘리면 어떨까?

---
## **2-Bit Predictor**

 이전 결과를 한 비트만 저장하니까, 즉 이전 결과만 저장해서 문제가 발생한다. 그렇다면 저장 비트를 늘리면 어떨까?
 
![](../images/Pasted%20image%2020250525215331.png)

>11 / 10 이면 Taken 예측  
>01 / 00 이면 Not Taken 예측

taken으로 예측을 하는 상태에서, 실제로 not taken이 발생했다. 그렇다면 다음 예측은 not taken이 되는 것이 아니라, 한번 더 taken 이라고 예측하고, 여기서마저 not taken이 실제 발생했다면, 그제서야 not taken으로 예측을 한다. 

>실제 TTTTNTTTT  
>예측 TTTTTTTTT

이렇게 되서 2번씩 틀리던 것이 1번만 틀리게 된다.

---
## **2-bit Predictor (another ver)**

![](../images/Pasted%20image%2020250525220007.png)

위의 예측이랑 다른 형식인데, 이전 방식에서는 taken 예측을 두 번 했을 때, 두 번 다 not taken이 실제 발생했다면 거기서 not taken으로 예측을 한다. 그리고 여기서 만약 taken이 실제 발생했다면, 다시 taken을 예측한다. 그러나 지금 모델에서는 not taken 예측도 두 번 하고, 둘 다 taken이 실제 발생해야 다시 taken 예측을 시작한다.

---
## **Calculating the Branch Target**

Not Taken이라고 예측하면, PC+4를 계산하면 되지만, Taken으로 예측하면 PC+4가 아니라 Target 주소를 계산해야 한다.

prediction table은 branch instruction의 **주소 하위 비트**를 보고 예측한다.

target buffer는 branch instruction의 **정확한 주소**를 보고 target address를 fetch한다.

---
## **Instruction-Level Parallelism (ILP)**

Pipelining은 여러 instruction을 **병렬적으로 동시에 실행**할 수 있도록 하는 구조이다. 이렇게 여러 instruction이 병렬적으로 처리되는 특성을 **Instruction-Level Parallelism(ILP)** 이 있다고 하며, ILP를 높이는 것은 시스템의 **처리량을 향상시키는 중요한 방법** 중 하나이다.

ILP를 높이는 첫 번째 방법은 **파이프라인을 깊게 만드는 것**이다. 전체 단계를 더 세분화하면, 한 스테이지에서 수행해야 할 작업이 줄어들고, 그만큼 **각 clock cycle의 시간도 짧아진다.**

두 번째 방법은 **동시에 여러 instruction을 동시에 발행**하는 것이다. 이를 위해 **공유해야 하는 자원을 제외한 나머지 파이프라인 구조를 복제**한다. ( Multiple Issue )

> 즉, **파이프라인 스테이지를 복제하여 다중 파이프라인 구조를 만들고**, **하나의 clock cycle마다 여러 개의 instruction을 시작**하게 하는 것이다.
    

이 경우 CPI는 1보다 작아질 수 있기 때문에, **Instructions Per Cycle (IPC)** 를 대신 사용한다.

> [!example]
> 4GHz 클럭에서 4-way multiple-issue 구조
> 
> - **최대 16BIPS(billion instructions per second)** 처리 가능
>     
> - **최대 CPI는 0.25**,
>     
> - **최대 IPC는 4**가 된다.
>     


하지만 실제로는 **데이터 의존성과 분기 등으로 인해 이론적인 성능에 도달하기는 어렵다.**


---
## **Multiple Issue**

**Static multiple issue**  (SW)
PC, PC+4를 항상 함께 fetch하여 **한 번에 두 개의 instruction을 실행**한다. 하지만 이 방식은 **두 instruction 사이에 의존성이 없어야 동작이 안전**하다. 이러한 의존성 문제는 **컴파일러가 미리 분석하고, instruction 재배치를 통해 해결**한다. 예전에는 PC, PC+4, PC+8에 하나씩 instruction을 배치했다면, 이제는 **PC, PC+4를 하나의 패키지로 묶고**, 이런 묶음을 **issue slot**이라고 부른다.

**Dynamic multiple issue**  (HW)
CPU가 여러 개의 instruction을 **동시에 fetch**하고, 그중에서 **상호 의존성이 없는 것들만 골라내어 동시에 issue**하는 방식이다. 이 방식에서는 의존성 판단과 스케줄링을 **CPU가 실시간으로 처리**하며, 컴파일러의 재배치 없이도 실행 효율을 높일 수 있다.

CPU는 매 사이클마다 **instruction stream을 분석하여 동시에 issue할 수 있는 instruction들을 선택**한다.  
컴파일러는 **instruction의 순서를 재배치**함으로써 이러한 동작을 도와줄 수 있다.  그리고 CPU는 **런타임에 의존성(hazard)을 감지하고**, 이를 해결하기 위해 **고급 기법들(forwarding, dynamic scheduling 등)** 을 사용한다.

---
## **Speculation**

만약 두 개의 instruction 순서를 **재배치**하기 위해 **의존성을 확인**했더니, **레지스터 번호상으로는 문제가 없어서** 재배치를 수행했다고 하자. 하지만 레지스터 번호에는 문제가 없어 보여도, **레지스터가 실제로 가지고 있는 값의 의미나 타이밍에 따라 의존성 문제가 발생할 수도 있다.**

사실 이 과정에서 우리가 한 것은 **"정확한 보장"이 아니라 단지 추정(speculation)** 일 뿐이다.  
즉, 문제가 없을 거라고 **"예측"한 것이지, 실제로 안전하다고 증명한 것은 아니다.**

그래서 가능한 빨리 추정을 기반으로 실행을 시작하고,

- 만약 **추정이 맞았다면** 그대로 작업을 **완료**하고,
    
- **추정이 틀렸다면**, 그동안 수행한 작업을 **롤백(rollback)**하여, 잘못된 작업이 반영되지 않도록 한다.
    

이러한 **추정 기반 실행(speculative execution)** 은 성능을 높이기 위해 널리 사용되며,  
추정이 성공할 경우 처리 속도를 높일 수 있지만, **실패 시에는 되돌릴 수 있는 메커니즘이 반드시 필요**하다.

---
## **Compiler/Hardware Speculation**

컴파일러가 instruction을 재배치할 때마다, **해당 재배치가 올바른지 확인하는 과정이 필요하다.** 단순히 레지스터 번호만 보고 판단하는 것이 아니라, **실제로 실행 결과에 영향을 주는지까지 고려**해야 한다. 따라서 컴파일러 수준에서도 **재배치가 유효한지 검증하는 코드나 로직이 필요**하다.

한편, 하드웨어 측면에서도 다음과 같은 방식으로 대응할 수 있다.

하드웨어는 미래 명령어들을 **미리 들여다보고 실행 가능한 것부터 실행**할 수 있다.

**실행 결과를 즉시 반영하지 않고 버퍼에 저장**해 두고, 나중에 그 결과가 **정말 필요하다고 확인되었을 때 반영**한다. 만약 **예측이 틀렸다면**, 버퍼에 저장된 중간 결과를 **모두 폐기(flush)** 하고, **정상적인 흐름으로 되돌린다.**
    

---
## **Static Multiple Issue**

컴파일러는 한 사이클에 여러 instruction을 **issue packet**으로 묶어 그룹화한다. 이때 컴파일러는 **하드웨어의 파이프라인 자원들(예: 몇 개의 ALU, load/store 유닛이 있는지 등)을 미리 알고 있어야 하며**, 이를 기반으로 **어떤 instruction들을 동시에 실행할 수 있을지 결정**해야 한다.

이처럼 multiple issue를 수행하는 구조에서는 **여러 개의 명령어를 하나의 복잡한 instruction처럼 묶어 처리**하게 되며, 이를 **VLIW (Very Long Instruction Word)** 라고 한다.  
즉, VLIW는 **여러 개의 단순 명령어를 하나의 긴 instruction으로 묶어 한 사이클에 동시에 issue**함으로써 **하드웨어는 단순화되고**, **ILP(Instruction-Level Parallelism)는 컴파일러가 책임지게 되는 방식**이다.

---

## **Scheduling Static Multiple Issue**

컴파일러가 여러 instruction을 하나의 **issue packet**으로 묶을 때는, 그 안에 **조금의 hazard(의존성 충돌)** 도 있어서는 안 된다. 따라서 packet을 구성할 때 **instruction들의 순서를 재배치**하기도 하고, 동시에 **instruction 사이에 데이터 의존성이 없도록 보장**해야 한다.

하지만 아무리 여러 instruction을 묶으려고 시도해도, **모든 instruction들이 서로 의존성을 가지고 있어 동시에 실행할 수 없다면**, 그 자리는 **`nop`(no operation)** 으로 채운다.  
즉, **실행할 명령어가 없더라도 하드웨어 구조상 issue slot을 채워야 하므로**, 안전하게 **아무 동작도 하지 않는 nop을 삽입**하는 것이다.

---
## **MIPS with Static Dual Issue**

![](../images/Pasted%20image%2020250526153709.png)

파이프라인을 길게 만들고 **완전히 2개를 복사**하게 되면, **모든 경로마다 동일한 일을 할 수 있도록** 자원을 2배로 확보해야 하므로 **하드웨어 자원 측면에서 비효율적**이다.

그래서 현실적으로는 **두 파이프라인의 역할을 분리**하여 구성한다. 예를 들어, 하나는 **ALU / Branch 전용**, 다른 하나는 **Load / Store 전용**으로 역할을 나누는 방식이다.
    
이렇게 하면 **자원을 덜 쓰고도 파이프라인을 병렬화**할 수 있다.  하지만 만약 어떤 사이클에 두 역할 중 **하나만 필요한 경우**, **남는 자리는 `nop`으로 채워야** 한다.  

![](../images/Pasted%20image%2020250526154420.png)


레지스터를 **동시에 4개 읽어야 하므로** **레지스터 파일의 입력 포트와 출력 포트가 기존보다 2배**로 필요하다.  

즉, **입력 2개 → 4개**, **출력 2개 → 4개** 또한, 한 파이프라인은 **ALU 연산용**, 다른 파이프라인은 **lw/sw 명령어의 주소 계산용**이기 때문에,  **ALU 연산기 1개를 추가**로 더 필요하다 (총 2개) 

마지막으로,동시에 두 개의 instruction이 실행되므로, **레지스터에 결과를 쓰는 포트도 2개** 필요하다.

---
## **Hazards in the Dual-Issue MIPS**

위에처럼 하면 이론상 instuction을 두 배씩 실행 시킬 수 있어서 효율적으로 보이지만, 사실 병렬적으로 돌기 때문에 hazard 관리는 더 어려워진다.

single issue라면 forwarding 을 통해 stall을 피할 수 있지만, 
Forwarding avoided stalls with single-issue
• Now can’t use ALU result in load/store in same packet
• add $t0, $s0, $s1
load $s2, 0($t0)
• Split into two packets, effectively a stall

load-use hazard의 경우 한 사이클 정도 nop으로 채워 보낸다면 2 instrucion이 한번에 병렬적으로 사용되기 때문에, 2배로 손해를 본다. 

따라서 순서재배치 같이 사전에 막는 aggressive한 스케줄링이 필요하다.

---
## **Scheduling Example**

![](../images/Pasted%20image%2020250526155946.png)
