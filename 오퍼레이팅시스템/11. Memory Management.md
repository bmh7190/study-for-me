
## **Background**
---
![](../images/Pasted%20image%2020250528095311.png)

프로그램이 실행되기 위해서는 디스크에 저장된 내용을 메인 메모리로 불러와야 한다. 메인 메모리와 레지스터는 오직 CPU에서만 직접 접근할 수 있으며, 메모리 유닛은 주소와 함께 read 요청 또는 주소와 데이터와 함께 write 요청만 처리한다.

레지스터는 CPU가 한 clock 내에 접근할 수 있지만, 메모리는 여러 clock 사이클이 걸리기 때문에 메인 메모리에 접근하면 stall이 발생할 수 있다. 이러한 성능 저하를 줄이기 위해 CPU 레지스터와 메인 메모리 사이에 Cache가 존재한다.

또한, 메모리 공간에 대한 protection이 보장되어야 프로그램이 정확하게 동작할 수 있다.

---
## **Base and Limit Registers**

![](../images/Pasted%20image%2020250528095722.png)
운영체제(OS)에 대한 기본적인 정보는 메모리에 상주하며, 각 프로세스가 생성될 때마다 해당 프로세스는 일정한 메모리 공간을 점유하게 된다. 이때 프로세스가 사용하는 메모리의 시작 주소를 **base**라고 하며, 프로세스가 할당받은 메모리 공간의 크기를 **limit**이라고 한다.  

어떤 프로세스가 특정 주소에 접근하려고 할 때, **그 주소가 해당 프로세스가 할당받은 메모리 범위(base ~ base + limit) 안에 있는지만 확인**하면 된다.  이렇게 확인함으로써 프로세스가 자신에게 허용되지 않은 메모리 영역에 접근하지 않도록 보호할 수 있다.

---
## **Hardware Address Protection**


![](../images/Pasted%20image%2020250528100153.png)

허용된 메모리에서 접근하는 방법은 간단하다! 단순히 base보다 크고 base + limit보다 작은지 확인하면 된다. 이 범위 안에 없으면 OS에 Trap을 한다. 

이런 시스템이 프로세스마다 돌아가기 위해서는 프로세스마다 base와 limit 값을 따로 저장해야 할 것이다.

---
## **Address Binding**

우리가 소스 코드를 사용할 때는 메모리 주소를 직접 표현하지 않고 변수로 대신 사용한다. 실제 주소가 드러나는 시점은 컴파일 시점이지만, 이때도 절대 주소로 변환되는 것이 아니라 상대적인 주소로 표현된다. 컴파일된 결과물은 보통 심볼 영역, 코드 영역, 데이터 영역 등으로 구성되며, 각 모듈이 메모리의 어디에 위치할지를 알려주는 정보가 포함된다. 이러한 여러 모듈을 하나로 합치는 과정을 링킹(linking)이라 하고, 실제로 메모리에 적재하는 과정을 로딩(loading)이라고 한다. 이 과정에서 주소 재배치가 이루어지며, 비로소 절대 주소가 할당되어 실제 주소가 결정된다.


![](../images/Pasted%20image%2020250528101012.png)

---
## **Logical VS Physical Address**

##### Logical address

CPU에 의해 생성되는 주소로, 프로그램 내에서 명시된 주소를 의미한다. 모든 프로세스는 자신의 주소 공간을 0번부터 시작한다고 가정한다.

##### Physical address

프로세스가 실제로 메인 메모리에 올라갈 때는, 해당 logical address를 physical address로 변환하여 메모리에 적재하게 된다.


---
## **Memory - Management Unit (MMU)**

logical address를 받아서 physical address로 변환하는 유닛을 Memory Management Unit(MMU)라고 한다. 이는 소프트웨어가 아니라 하드웨어(HW) 구성 요소이다.

![](../images/Pasted%20image%2020250528101435.png)

위의 그림에서 예를 들면, logical address가 346일 때 MMU에서 relocation register의 값이 14000이므로, 이 둘을 더한 값인 14346이 실제 메인 메모리에서 사용되는 physical address가 된다.

---
## **Contiguous Allocation**


메인 메모리는 운영체제(OS)와 사용자(USER) 프로세스 모두를 지원해야 한다. 하지만 메인 메모리는 용량이 제한되어 있기 때문에, 효율적으로 분배되어야 한다.

Contiguous 할당은 가장 먼저 고안된 메모리 할당 방식으로, 모든 프로세스가 하나의 연속된 메모리 공간을 할당받는 방식을 의미한다.

이때 메인 메모리는 일반적으로 두 부분으로 나뉘는데, OS는 컴퓨터가 켜지는 순간부터 꺼질 때까지 항상 존재해야 하므로 메모리의 낮은 주소 공간에 고정되어 할당된다. 반면, 메모리의 높은 주소 공간은 사용자 프로세스들이 점유하며, 각 프로세스는 하나의 연속된 메모리 블록을 할당받는다.

![](../images/Pasted%20image%2020250528102355.png)

앞서 언급한 것처럼, logical address를 physical address로 변환하기 위해서는 limit register와 relocation register(base)만 있으면 된다.

예를 들어, 어떤 load 명령을 통해 주소에서 데이터를 불러오려 할 때, 이 주소는 사실 logical 주소이다. 먼저 해당 logical 주소가 limit register보다 작은지를 확인하여, 프로세스가 할당받은 메모리 공간 내의 주소인지 검증한다. 그다음, relocation register를 이용해 실제 physical address를 계산하고, 해당 주소에서 데이터를 메모리로부터 가져오게 된다.

---

메모리 공간 안에 얼마나 많은 partition을 배치하느냐에 따라 동시에 실행될 수 있는 프로그램의 수가 결정된다. 그리고 당연히 각 프로세스마다 사용하는 메모리 공간의 크기는 다르기 때문에, 프로세스마다 서로 다른 크기의 메모리 공간을 할당하는 것이 더 적절하다. 그러나 이렇게 프로세스마다 메모리를 개별적으로 할당하고, 이후에 해제를 반복하는 과정에서 메모리 내에는 사용되지 않는 빈 공간(구멍, hole)이 생기게 된다.

![](../images/Pasted%20image%2020250528102641.png)

새로운 프로그램이 실행되면, 이 프로그램은 메모리 내 충분한 크기의 hole에 할당된다. 만약 인접한 빈 공간들이 있다면 이를 하나로 합쳐 더 큰 공간을 만들기도 한다. 이 메모리 할당의 주체는 CPU이며, CPU는 효율적인 할당을 위해 어느 프로세스가 어떤 메모리 영역을 점유하고 있는지, 그리고 어떤 부분이 비어 있어 사용 가능한지를 정확히 파악하고 있어야 한다.

---
## **Contiguous Allocation Problem**


#### Fragmentation

연속적인 공간을 할당하는 방식에서는, 할당과 해제가 반복될수록 프로세스에게 딱 맞는 크기의 공간을 확보하기가 점점 어려워진다.

예를 들어, 어떤 프로세스가 18,264Byte의 메모리를 필요로 하는데, 가장 근접한 hole의 크기가 18,300Byte라면 이 공간에 할당할 수밖에 없다. 이 경우 36Byte의 남는 공간이 발생하게 되는데, 이렇게 아주 작은 단위의 공간은 실제로 사용되기 어렵다. 이처럼 할당 외부에 남는 사용 불가능한 공간을 external fragmentation이라고 한다.

이론적으로 전체 빈 공간을 모두 합치면 하나의 프로세스를 수용할 수 있는 충분한 메모리가 되지만, 물리적으로 연속되어 있지 않기 때문에 사용할 수 없게 된다.

이러한 파편화를 줄이기 위한 방법 중 하나는 메모리를 2의 제곱 크기 단위로 할당하는 것이다. 그러나 이 방식은 항상 프로세스가 실제로 필요한 메모리보다 큰 공간을 할당받게 되므로, 할당된 블록 내에서도 사용되지 않고 낭비되는 부분이 생긴다. 이렇게 블록 내부에서 낭비되는 공간을 internal fragmentation이라고 한다.

---

#### Compaction

이렇게 파편화된 공간을 해결하는 간단한 아이디어는, 이미 메모리를 점유하고 있는 프로세스들을 한쪽으로 밀어 정렬하는 것이다. 한쪽으로 모아 배치하면 중간에 흩어져 있던 작은 hole들이 하나로 합쳐져 큰 연속된 공간이 생기게 된다.

하지만 이 방법은 실제로 구현하기가 쉽지 않다. 메모리에 있는 데이터를 하나하나 읽고 이동시킨 뒤, 해당 프로세스가 사용하는 주소들을 모두 수정해줘야 하기 때문이다. 특히 이 작업은 많은 I/O 작업을 수반하게 되고, 이 동안에는 다른 작업들이 일시적으로 중단되거나 대기 상태가 되므로 전체 시스템 성능에 영향을 줄 수 있다.

---
# **Swapping**

스토리지 내부에는 **backing store**라는 별도의 큰 공간을 마련해두고, 현재 메인 메모리에서 사용되지 않는 프로세스는 이 공간으로 옮겨둘 수 있다. 즉, 실행 중이 아닌 프로세스는 반드시 메인 메모리에 있을 필요가 없기 때문에, backing store로 옮겨놓음으로써 실제 메인 메모리의 사용 가능 공간을 확장하는 효과를 얻게 된다.

이러한 과정은 **swap out**(또는 **roll out**)과 **swap in**(또는 **roll in**)이라는 단계로 이루어진다. swap out은 프로세스를 메인 메모리에서 backing store로 옮기는 것이고, swap in은 반대로 backing store에 있는 데이터를 다시 메인 메모리로 불러오는 것이다. 이때 운영체제(OS)는 어떤 프로세스의 우선순위가 높은지, 어떤 프로세스를 swap 대상으로 삼을지를 결정해야 한다.

swap 과정에서 가장 많은 시간이 소요되는 부분은 바로 메모리와 backing store 간에 데이터를 실제로 옮기는 **데이터 전송 과정**이다. 따라서 swap 대상이 되는 데이터의 크기를 줄이면, 이 데이터 이동에 필요한 시간도 함께 줄어들게 된다.

![](../images/Pasted%20image%2020250528104857.png)

---
## **Context Switch Time Including Swapping**

만약 context switch 대상이 된 프로세스가 메인 메모리에 존재하지 않고 backing store에 있다면, 해당 프로세스를 메모리로 불러오는 작업이 필요하게 되므로 context switch 시간도 그만큼 늘어나게 된다.

예를 들어, 한 프로세스가 메인 메모리에서 100MB를 사용하고 있고, 이를 backing store로 옮기는 데 하드 디스크 전송 속도가 50MB/s라면, **swap out**에만 약 2초(2000ms)가 소요된다. 반대로 backing store에 있는 다른 프로세스를 메모리로 가져오기 위해 공간을 비워야 하는 경우, 또 다른 100MB의 데이터를 다시 backing store로 옮겨야 할 수 있다. 이 역시 2초가 걸리므로, 결국 context switch 한 번에 총 4초가 소요되는 상황이 발생할 수 있다.

이러한 비효율을 줄이기 위해서는, 사용하지 않는 메모리 공간을 **즉시** backing store로 옮길 수 있도록 `request_memory`, `release_memory`와 같은 system call을 적절히 활용하는 것이 중요하다. 시스템 호출을 통해 적극적으로 메모리 사용을 관리하면, 불필요한 swapping 공간을 줄이고 context switch 시간도 단축할 수 있다. 즉, **swapping되는 메모리 크기 자체를 줄이는 것이 핵심**이다.

---
## **Swapping on Modern OS**

이러한 대용량 swapping은 현대 운영체제에서는 일반적으로 사용되지 않는다. 그 이유는 현대의 운영체제는 메모리를 **contiguous(연속적)** 하게 할당하지 않기 때문이다. 대신 메모리를 **페이지 단위**로 나누어 관리하며, 이로 인해 전체 프로세스를 통째로 옮기는 방식의 swapping은 거의 발생하지 않는다.

그럼에도 불구하고 **swap**이라는 개념 자체는 여전히 존재할 수 있다. 단, 이 경우는 보통 아주 작은 크기의 데이터나, 일시적으로 사용되지 않는 페이지를 대상으로 하며, 전체 프로세스를 swapping하는 방식과는 다르다.

또한 일부 운영체제에서는 아예 swap 기능 자체를 사용하지 않기도 한다. 특히 **Flash 메모리**(예: USB, SSD, 스마트폰 등)를 사용하는 시스템에서는 swap을 꺼리는 경향이 있다. 이는 Flash 메모리의 특성상 **쓰기(write)** 횟수가 제한되어 있기 때문이다. 데이터를 자주 쓰고 지우는 swap 작업은 Flash 메모리의 수명을 단축시키며, 결국 해당 공간을 **영구적으로 사용할 수 없게** 만들 수 있다. 이러한 이유로, Flash 기반 시스템에서는 swap을 최소화하거나 아예 사용하지 않는 방식을 채택하는 경우가 많다.

압축된 메모리인 zRAM을 사용하는 경우도 있다. 

---
# **Segmentation**

ontiguous Allocation은 여러 가지 문제점을 가지고 있었다. 가장 큰 문제는 프로세스의 모든 데이터를 연속적인 메모리 공간에 배치해야 한다는 점이다. 이로 인해 **fragmentation(단편화)** 문제가 발생하며, 시간이 지날수록 메모리 활용 효율이 떨어지게 된다. 또한, 프로세스 간의 소통을 위해 메모리의 일부 영역을 공유해야 할 때도 있는데, 모든 데이터를 연속적으로 배치하는 방식에서는 이러한 **부분적인 공유**가 어렵다는 한계가 있다.

이러한 문제를 해결하기 위한 방법으로, 프로그램을 **여러 개의 segment(세그먼트)** 로 나누어 각각을 독립적으로 관리하는 방식을 도입할 수 있다. 예를 들어, 메인 프로그램, 함수 객체, stack, heap, data, code 등을 각각 별도의 세그먼트로 나누고, 이들을 개별적으로 할당하고 관리하는 것이다. 이렇게 하면 **공유가 필요한 세그먼트만 선택적으로 공유**할 수 있고, 메모리 사용의 유연성도 훨씬 높아지게 된다.

---
![](../images/Pasted%20image%2020250528141737.png)

프로그램 실행 중에는 `code` 영역에 있는 데이터는 변경되지 않는다. 즉, code 자체를 수정하는 `store` 명령이 수행되어서는 안 되며, 따라서 이 영역은 **read-only**로 관리되어야 한다. 이처럼 segment를 나누게 되면, **각 segment의 성격에 맞게 접근 권한과 속성을 다르게 설정**할 수 있다는 장점이 있다.

Contiguous allocation 방식에서는 하나의 프로세스에 대해 단일한 `base`와 `limit` 값을 유지하면 되었지만, **segmentation 방식에서는 각 segment마다 개별적인 base와 limit 값을 관리해야 한다.** 즉, 한 프로세스가 여러 segment로 나뉘고, 그 각각의 segment에 대해 **독립적인 base와 limit 정보**가 필요하다.

또한, 각 메모리 접근이 어떤 segment를 가리키는지를 구분할 수 있어야 한다. 가장 직관적인 방법은 주소의 **상위 비트**를 사용하여 segment를 구분하고, **하위 비트**는 해당 segment 내에서의 offset(주소)를 나타내는 것이다. 그러나 이 방식의 단점은 **각 segment마다 크기의 최대값이 제한**된다는 점이다. 상위 비트 수에 따라 segment 개수와 크기가 제한되므로 유연성이 떨어질 수 있다.

또 다른 방법으로는 instruction 자체가 어느 segment를 사용할지 명시적으로 지정하는 방식도 있지만, 이 방식은 구현이 복잡하고 활용도도 낮아 **현대 시스템에서는 잘 사용되지 않는다.**

---
## **Logical View of Segmentation**

![](../images/Pasted%20image%2020250528142817.png)



----
## **Segmentation Architecture**

이전의 contiguous allocation 방식에서는 프로세스마다 하나의 base와 limit만 관리하면 되었지만, segmentation 방식에서는 **각 segment마다 개별적인 base와 limit을 저장해야 한다.** 이때 각 segment의 base와 limit을 하나의 쌍으로 하여 **segment table**에 저장하여 관리하게 된다.

앞서 언급한 바와 같이, 주소의 상위 비트는 **segment number**를 나타내고, 하위 비트는 해당 segment 내부에서의 **offset**을 의미한다.

하지만 segment가 많아지면 segment table의 크기도 커지게 되어, 이 테이블 전체를 CPU 내부의 레지스터에 보관하는 것이 불가능해진다. 그래서 segment table은 **메모리 상에 위치**하게 되며, CPU는 이 테이블이 메모리의 어디에 있는지를 알고 있어야 한다.

이를 위해, **STBR(Segment Table Base Register)** 와 **STLR(Segment Table Length Register)** 라는 두 개의 레지스터를 사용한다.


> [!note]
> - **STBR**은 segment table이 **메모리에서 어디에 위치하는지**를 나타낸다.
>     
> - **STLR**은 해당 프로세스가 사용하는 **segment의 개수**, 즉 segment table의 길이를 나타낸다.

![](../images/Pasted%20image%2020250528143934.png)

여기서 `s`는 **segment 번호**, `d`는 해당 segment 내부의 **offset**을 의미한다.

먼저, **STBR**과 **STLR**을 통해 메모리 내에 존재하는 **segment table의 시작 위치**와 **세그먼트의 개수**를 알 수 있다. 이후 주소의 상위 비트인 `s`를 이용해 segment table에서 해당 segment의 `base`와 `limit` 값을 가져온다.

가져온 `limit` 값과 offset인 `d`를 비교하여, `d < limit`인지 확인한다. 만약 조건을 만족하면, 해당 offset은 유효한 범위 내에 있으므로, `base + d`를 통해 **physical address**를 계산하고, 이를 **MMU**가 이용하여 실제 메모리의 위치에 접근하게 된다.

또한 segment table에는 각 segment의 접근 권한을 나타내는 **protection bit**도 포함되어 있다. 이 비트를 통해 해당 segment가 **read-only**인지, **write 가능한지** 등의 정보가 명시된다.

---
# **Paging**

egmentation은 분명한 이점을 제공한다. 하나의 큰 프로그램 메모리를 segment 단위로 나누면, **다른 프로세스와 특정 segment만 선택적으로 공유**하기가 쉬워지고, 각 segment에 대해 **접근 권한이나 특성(read-only, read/write 등)을 개별적으로 제어**할 수 있다는 장점이 있다.

그러나 이러한 segmentation 방식도 한계가 있다. 메모리를 segment 단위로 나누었음에도, **각 segment의 크기 자체가 여전히 크기 때문에**, segment 내부에서 **남는 공간이 많이 발생할 수 있다.** 즉, 여전히 **external fragmentation** 문제가 존재하며, 메모리 공간을 완전히 효율적으로 사용하지 못한다.

그래서 **fragmentation을 최소화하자**는 관점에서 등장한 방법이 바로 **Paging**이다.

---

메인 메모리 공간은 고정된 크기로 나누며, 이 나뉜 공간의 한 칸을 **frame** 혹은 **physical page**라고 부른다. 이 frame은 일반적으로 **2의 N승 크기**로 나뉘며, 현대 운영체제에서는 보통 **4KB(약 4,096바이트)** 크기를 사용한다.

> 프로세스가 사용하는 **logical 메모리**도 동일한 크기로 나뉘며, 이를 **page** 또는 **logical page**라고 한다.

따라서 프로그램이 N개의 page를 필요로 한다면, 메인 메모리에서 **N개의 빈 frame**을 찾기만 하면 된다. 이 frame들은 **연속적일 필요가 없으며**, 흩어져 있어도 상관없다. 이것이 paging의 큰 장점 중 하나다.

하지만 이 방식을 사용하려면 운영체제는 반드시 **어떤 frame이 비어 있는지**에 대한 정보를 알고 있어야 한다. 또한 각 **page가 어느 frame에 매핑되어 있는지**도 관리해야 하며, 이 정보를 저장한 것이 **page table**이다. paging에서는 page 크기가 **고정되어 있기 때문에**, segment 방식처럼 **limit 값은 필요하지 않다**.

paging은 **external fragmentation** 문제를 해결해 주지만, 각 page가 프로세스가 필요한 크기보다 약간 더 클 수 있기 때문에 **internal fragmentation**은 여전히 존재한다.

---
## **Address Translation Scheme (MMU)**

> [!example]
> 예를 들어, 전체 메모리가 **4GB**라고 하면 이는 2<sup>32</sup> 바이트이므로, **주소를 32비트**로 표현할 수 있다.
> 
> 또한, **page size = frame size = 4KB**라면 이는 2<sup>12</sup> 바이트이다.  따라서 전체 메모리를 4KB 단위로 나누면, **총 2<sup>20</sup>개의 frame**(또는 page)이 존재하게 된다.
> 
> 이때, 어떤 **page 번호**를 나타내기 위해서는 **20비트**가 필요하다.  따라서 32비트 주소 중 상위 **20비트는 페이지 번호**를, 하위 **12비트는 해당 페이지 내의 offset(위치)** 를 나타내게 된다.
> 

![](../images/Pasted%20image%2020250528151135.png)

> [!note] 정리
> m : 전체 메모리 크기 2<sup>m</sup>
> n : frame 크기 2<sup>n</sup>
> 
> m - n =page number 
> n  = offset


![](../images/Pasted%20image%2020250528151310.png)

결국 주소 변환 과정에서 실제로 **변환이 필요한 부분은 페이지 번호(Page Number)** 뿐이다. 

**Offset**은 그대로 유지된다. 왜냐하면 page와 frame의 크기가 동일하므로, offset은 **frame 안에서의 위치**와 **page 안에서의 위치**가 완전히 동일하기 때문이다. 따라서 해야 할 일은, **해당 page가 메모리의 어느 frame에 매핑되어 있는지만 알아내는 것**이다.


---
## **Paging Hardware**

![](../images/Pasted%20image%2020250528151424.png)

1. **Logical address**의 상위 비트에서 page number를 추출한다.
    
2. **Page table**을 참조하여 해당 page가 매핑된 **frame 번호**를 찾는다.
    
3. 그 frame 번호와 **offset(하위 비트)**를 결합하여 **physical address**를 생성한다.

---
## **Example of Paging**

![](../images/Pasted%20image%2020250528151732.png)

---
## **Calculating Internal Fragmentation**

> [!info]
> Page size = 2048 bytes = 2KB
> Process size = 72766 bytes
> 
> 72766bytes / 2048bytes = 35 page + 1086bytes
> 
> 나머지 1086bytes를 하나의 페이지를 더 써서 넣게 되면 2048bytes - 1086bytes = 962bytes
> 즉 마지막 페이지에서 962bytes는 사용되지 않는다. 
> 
> worst case framentation
> 최악의 경우는 1byte가 남았을 경우다. page size - 1byte 가 낭비가 된다. 
> 
> average fragmentation
> 1/2 page size가 낭비된다. 


위의 예시를 토대로 보면, **page size를 줄이면** 각 페이지가 작아지므로 **internal fragmentation**이 줄어들고, 메모리를 보다 **세밀하게 관리**할 수 있게 된다. 따라서 낭비되는 메모리 공간은 줄어드는 경향이 있다.

하지만 **무조건적으로 page size를 줄이는 것이 항상 좋은 것은 아니다.**

page size가 **4KB(= 2¹²)** 일 경우, 전체 주소 공간이 **2³²(= 4GB)** 이므로 총 페이지 수는 **2<sup>20</sup>**개의 page가 존재한다. 각 page마다 어떤 frame에 매핑되는지를 나타내야 하므로, 필요한 **frame 번호**도 최대 2<sup>20</sup>개 중 하나를 가리켜야 하며, 이를 위해 **20비트**가 필요하다.
    

결국, page table은 총 **2<sup>20</sup>**개의 엔트리를 가지며, 각 엔트리에 20비트가 저장된다.
    
$$2^{20} \times 20\text{비트} = 20 \times 2^{20} \text{비트} = 2.5\text{MB}$$

이렇게 약 **2.5MB의 메모리**가 단지 주소 변환용인 page table을 위해 사용된다. 하지만 이 page table은 **실제 데이터를 저장하는 것이 아니라**, 단지 **주소를 변환**하는 용도로만 사용된다.  즉, **유의미한 계산이나 정보 자체를 담고 있는 것이 아니라 단순 매핑 정보**만 갖고 있는 구조이기 때문에, 이 만큼의 메모리를 소비하는 것은 **비효율적이고 낭비**로 간주될 수 있다.

---
## **Free Frames**

![](../images/Pasted%20image%2020250528153442.png)

---
## **Implementation of Page Table**

page table도 segment table과 마찬가지로 **크기가 크기 때문에** CPU 내부 레지스터에 모두 저장할 수 없고, 결국 **메인 메모리에 저장**된다.  이때 page table의 위치는 다음 두 레지스터를 통해 지정된다:

> [!info]
> - **PTBR (Page Table Base Register)**: page table이 메인 메모리에서 **어디에 위치**하는지를 나타냄
>     
> - **PTLR (Page Table Length Register)**: 해당 프로세스가 사용하는 **page의 개수**, 즉 page table의 **길이**를 나타냄
>     


이 구조에서는 주소 변환 시 메모리 접근이 **2번 발생**하게 된다:

1. **page table에 접근**하여 page number에 해당하는 **frame number**를 찾고,
    
2. 그 frame과 offset을 조합해 **실제 데이터를 얻기 위해 메모리에 다시 접근**
    

하지만 메인 메모리 접근은 시간이 많이 걸리는 작업이기 때문에, 이런 2단계 접근은 성능에 큰 영향을 준다.

이를 해결하기 위한 장치가 바로 **TLB(Translation Lookaside Buffer)** 이다.  TLB는 최근에 사용된 **page number → frame number 변환 정보를 캐시처럼 저장**하는 고속 메모리이다. 프로세스는 보통 **spatial locality** (인접한 주소들을 자주 접근) 성향을 보이므로, **최근 접근한 page 정보만 저장해도 상당히 많은 변환 요청을 처리**할 수 있다.

---


**일부 TLB는 각 엔트리에 Address-Space Identifier (ASID)를 저장**한다.  이는 각 TLB 엔트리가 **어느 프로세스의 주소 공간에 속하는지를 명확히 구분**하기 위한 것으로, **프로세스마다 고유한 식별자 역할**을 한다.
    
**ASID가 없으면**, 매번 context switch가 발생할 때마다 기존 TLB 내용을 **모두 flush(삭제)** 해야 한다.  왜냐하면 다른 프로세스의 page table 정보를 잘못 참조할 위험이 있기 때문이다.
    
**TLB는 일반적으로 작다**. 보통 **64개에서 1,024개** 사이의 엔트리를 가진다. 캐시처럼 동작하므로 빠른 접근이 가능하지만 공간은 제한적이다.
    
**TLB miss**가 발생하면, CPU는 page table에 접근하여 필요한 정보를 가져오고, 해당 값을 **TLB에 다시 적재(load)** 한다. 이후 동일한 주소 접근 시에는 TLB hit로 빠르게 처리할 수 있다.

**교체 정책(Replacement policy)** 도 중요하다.  공간이 제한되어 있기 때문에, 새로운 엔트리를 넣기 위해 기존의 어떤 엔트리를 제거할지 결정해야 하며,  이를 위해 **LRU (Least Recently Used)** 나 **FIFO**와 같은 정책이 사용된다.

![](../images/Pasted%20image%2020250528155013.png)

----
## **Effective Access Time** ( Cache 고려 X )

• TLB에 접근하는 시간 : t<sub>T</sub>
• 메모리에 접근하는 시간 : t<sub>M</sub>
• hit ratio : ɑ

EAT(Effective Access Time ) =  ( t<sub>T</sub> + t<sub>M</sub> ) * a + ( t<sub>T</sub> + t<sub>M</sub> + t<sub>M</sub>) * ( 1- a )

---
## **Additional Bits of Page Table Entry**

페이지마다 read-only나 read-write 여부를 비트(rw bit)를 통해 지정하여 메모리를 보호할 수 있다. 상태는 execute-only일 수도 있으며, 그 외에도 다양한 접근 권한 상태가 존재한다.

또한, 페이지 테이블의 각 엔트리에는 valid/invalid 비트를 함께 둔다. valid 비트는 해당 페이지가 프로세스의 논리 주소 공간에 포함된 유효한 페이지임을 나타내고, invalid 비트는 해당 페이지가 프로세스의 논리 주소 공간에는 정의되어 있으나 실제로는 사용되지 않음을 의미한다.

![](../images/Pasted%20image%2020250531161816.png)


실제 사용중인 페이지는 6개이고, 그 밖에 페이지는 사용 중이 아니라면, 그 페이지는 page table에서는 invalid 비트가 켜지는 거죠

---
## **Shared Pages**

![](../images/Pasted%20image%2020250531161944.png)

여러 개의 프로세스는 하나의 페이지를 공유할 수 있다. 동일한 내용을 사용하는 페이지라면, 메모리에 해당 페이지가 하나만 존재해도 되며, 각 프로세스의 페이지 테이블에서 동일한 프레임 번호로 매핑되도록 하면 된다. 다만, 각 프로세스가 개별적으로 사용하는 데이터는 공유하지 않기 때문에, 이러한 데이터는 서로 다른 페이지에 각각 저장된다.

보통 프로세스 간에 공유하는 영역은 코드(segment)인 경우가 많지만, 필요에 따라 데이터도 공유할 수 있다. 공유를 위해서는 하나의 복사본만 메모리에 올려두고, 각 프로세스가 해당 영역을 동일한 물리 주소로 매핑하도록 하면 된다. 특히 read-write 가능한 영역을 공유하게 되면, 이를 통해 프로세스 간 통신(inter-process communication, IPC)도 가능해진다.

---
## **Page Table Size**

32비트의 logical address를 가진다고 생각해보자. 32비트의 logical address를 가진다는 것은 process가 사용하는 메모리 크기가 최대 4GB라는 것이랑 똑같다. 

Page size : 4KB(2<sup>12</sup>)
Entries of Page table : 1million ( 2<sub>32</sub>/2<sub>12</sub> )
Entry entry : 4 bytes → 2<sup>20</sup> * 4 = 4MB

우리는 4KB 크기의 페이지(Page)와 프레임(Frame)을 사용하는데, 이 경우 페이지 테이블의 크기가 4MB에 이르면 1024개의 연속된 프레임을 필요로 하게 된다. 이는 너무 큰 공간이며, 기본적으로 페이징(Paging)을 사용하는 이유는 연속적인 물리 메모리를 사용하지 않기 위해서였고, 외부 단편화(fragmentation) 문제를 피하기 위함이기도 하다. 따라서 메인 메모리에 페이지 테이블이 연속적으로 저장되는 것은 바람직하지 않다.

---
## **Hierarchical Page Tables**

그래서 페이지 테이블도 계층적으로 구성하며, 각 페이지 테이블이 어디에 위치하는지를 나타내는 **outer page table**을 하나 추가로 둔다. 이 outer page table은 조각나서 흩어져 있는 **inner page table**들이 어떤 프레임에 저장되어 있는지를 가리키는 역할을 한다. 이를 통해 페이지 테이블 자체도 연속적인 물리 메모리에 저장하지 않아도 되므로, 메모리의 효율적 사용과 단편화 문제 해결에 도움이 된다.

![](../images/Pasted%20image%2020250531163725.png)


![](../images/Pasted%20image%2020250531164530.png)

PTBR(Page Table Base Register)을 통해 페이지 테이블들이 어디에 위치하는지 알 수 있다. 논리 주소의 상위 비트를 이용해 PTBR이 가리키는 outer page table로 접근하고, 해당 비트를 기반으로 실제 inner page table이 위치한 프레임을 찾는다. 이후 inner page table의 내용을 참조하여, 최종적으로 해당 페이지가 물리 메모리의 어느 프레임에 있는지를 확인하게 된다.


---
# **Case Studies**

## **The Intel IA-32 Architecture**

![](../images/Pasted%20image%2020250531173452.png)

대부분의 프레임 크기는 4KB 단위로 나누어 사용하지만, 일부 프로그램은 큰 용량의 연속된 메모리를 요구하기도 한다. 이런 경우에는 한 번에 4MB와 같이 더 큰 크기의 프레임을 할당하는데, 이를 **large page** 또는 **huge page**라고 한다. 이러한 페이지는 TLB 효율을 높이고 페이지 테이블 크기를 줄이는 데에도 도움이 될 수 있다.

이때 huge page의