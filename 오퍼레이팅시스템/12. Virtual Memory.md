
지금까지 다뤘던 외부 단편화(external fragmentation)를 줄이기 위한 방법인 **페이징(Paging)** 은, 메인 메모리에 프로세스가 원하는 데이터가 이미 존재한다는 가정을 바탕으로 설명되었다. 이제부터 다룰 **가상 메모리(Virtual Memory)** 는, 메인 메모리에 원하는 데이터가 존재하지 않을 수도 있다는 상황까지 포함하는 개념이다. 즉, 가상 메모리는 실제 메모리에 전부 올리지 않고도 프로그램을 실행할 수 있게 해주는 확장된 메모리 관리 기법이다.

---
## **Motivation of Virtual Memory**

프로그램이 실행되는 매 순간을 살펴보면, 실제로 그들이 사용하는 코드나 데이터 전체가 항상 필요한 것은 아니다. 실행 상황에 따라 사용되는 코드가 달라지고, 전체 코드가 모두 사용되는 경우는 드물다. 예를 들어, 오류 처리 코드(error code)나 특이한 경로의 루틴(unusual routines) 등은 프로그램 실행 중에 한 번도 사용되지 않을 수 있다.

페이징을 통해 외부 단편화를 줄일 수는 있었지만, 페이지 단위로 메모리에 적재할 때 굳이 사용되지도 않을 데이터를 모두 불러올 필요는 없지 않을까?라는 의문이 생겼고, 결국 필요한 부분만 메모리에 가져오기 위한 방법이 고민되었다.

그 해결책이 바로 **프로그램을 부분적으로 나누어 필요한 부분만 가져오자!** 는 접근이다. 이렇게 하면 프로그램은 더 이상 물리적 메모리 크기에 제약을 받지 않게 된다. 예를 들어, 8GB짜리 게임이 있다고 해도, 실제 실행 시 필요한 부분만 메모리에 불러온다면, 메인 메모리 크기가 4GB여도 실행이 가능해지는 것이다.

또한 각 프로그램이 실행 중에 사용하는 메모리의 양이 줄어들게 되므로, 전체적으로 더 많은 프로세스를 동시에 메모리에 적재할 수 있게 된다. 이로 인해 **CPU utilization**과 **throughput**도 자연스럽게 향상된다.

뿐만 아니라, 메모리에 실제로 데이터를 로드하거나 교체(swap)하는 횟수가 줄어들게 되므로, 불필요한 I/O가 감소하고 결과적으로 프로그램의 실행 속도도 빨라진다. 이러한 개념과 기법이 바로 **가상 메모리(Virtual Memory)** 이다.

---
## **Virtual Memory**

**Logical 메모리와 Physical 메모리를 분리**하면, **논리 주소 공간(logical address space)** 은 실제 물리 주소 공간(physical address space)보다 훨씬 커질 수 있다. 그 이유는, 어차피 실행 시점에 **실제로 필요한 데이터만 메모리에 가져오면 되기 때문**이다.

즉, 모든 데이터를 한꺼번에 물리 메모리에 올릴 필요가 없으므로, 전체 논리 주소 공간이 물리 메모리의 크기를 넘어도 문제가 되지 않는다. 이러한 분리를 통해 **프로세스는 매우 큰 주소 공간을 할당받는 것처럼 동작할 수 있으며**, 이는 가상 메모리 덕분에 가능하다. 결과적으로 주소 공간의 제약이 사라지고, 더 유연하고 효율적인 메모리 관리가 가능해진다.

**Virtual address space**는 "프로세스가 메모리에 어떻게 저장되는가"에 대한 **논리적인 관점(logical view)** 을 제공하며, 이는 어떤 프로세스든지 동일한 방식으로 사용된다.

> [!note]
> - 가상 주소 공간은 보통 **주소 0부터 시작하여**, **연속적인 주소들**로 끝까지 이어지는 형식을 갖는다.
>     
> - 반면에 실제 물리 메모리는 **페이지 프레임(page frame)** 단위로 나뉘어 저장된다.
>     
> - 따라서 **MMU(Memory Management Unit)**는 논리 주소(logical address)를 물리 주소(physical address)로 적절히 **매핑(mapping)**해 주어야 한다.

Virtual 메모리는 Demand paging, Demand Segmentation으로 구현할 수 있다.

![](../images/Pasted%20image%2020250531180248.png)

현재 사용되는 데이터만 올라간다. 유효하긴 하지만 현재 사용되지 않는 애들은 메모리에 있을 수도 있고, 디스크에 있을 수도 있다. 

---

![](../images/Pasted%20image%2020250531181502.png)

> **가상 주소 공간은 0번 주소부터 시작해서 최대 주소까지 연속된 메모리 공간처럼 보인다.**

사용자가 보기엔 연속된 메모리이지만, 실제 물리 메모리는 전혀 그렇지 않고, 이공간에는 코드, 데이터, 힙, 스택 등이 배치된다.

> **스택과 힙 사이에는 사용되지 않는 (reserved or guard) 주소 공간이 존재할 수 있다.**

힙은 위로, 스택은 아래로 성장하기 때문에 둘 사이에 **비워진 가상 주소 공간이 존재**한다.  
이 영역은 아직 물리 메모리로 매핑되지 않았지만,  **힙 또는 스택이 확장될 경우를 대비해 예약된 공간**으로 볼 수 있다.

> **시스템 라이브러리(shared libraries)는 각 프로세스의 가상 주소 공간에 매핑된다.**

물리 메모리에서는 같은 페이지를 여러 프로세스가 공유하므로 공간 절약을 할 수 있다. 또 매핑만 다르고 물리적 내용은 동일하다. 

> **공유 메모리는 읽기-쓰기 권한을 가진 페이지를 여러 프로세스의 가상 주소 공간에 매핑함으로써 구현된다.**

예: `mmap`, `shmget`, `shmat` 등을 사용한 IPC. 실제로는 하나의 물리 페이지가 여러 가상 주소로 접근되는 구조.

> **fork() 시 부모 프로세스의 메모리 페이지를 자식과 공유(Copy-on-Write 방식)하면 프로세스 생성이 빨라진다.**


![](../images/Pasted%20image%2020250531181639.png)

shared library같은 경우 stack heap 사이 어딘가가 있을 것이고, 그냥 shared pages 에서 잘 맵핑해주면 된다. 

---
## **Demand Paging**

**Demand paging**은 실행 시점에 **필요한 데이터만 메모리에 적재**하는 방식이다. 불필요한 데이터는 메모리에 올라오지 않기 때문에, **불필요한 I/O가 줄고**, **메모리 사용량도 절약**된다.

과거에는 컨텍스트 스위치 시 프로세스 전체 메모리를 모두 불러와야 했기 때문에 시간이 오래 걸렸지만, Demand paging은 실행에 필요한 페이지만 메모리에 적재하므로 **프로세스 생성 및 전환 속도**가 빨라진다.

이 방식은 **paging system과 swapping 개념과 유사**하지만, 중요한 차이가 있다.  기존의 **swapping**은 프로세스 전체를 통째로 디스크와 메모리 사이에서 옮겼던 반면,  Demand paging은 **페이지 단위로 데이터를 디스크에서 가져오거나 내보낼 수 있다.**

어떤 페이지가 필요한지는 **실제로 접근하는 순간에 확인된다.**  해당 페이지가 메모리에 없으면 운영체제가 **page fault**를 발생시키고, 그 접근이 올바른 경우라면 디스크에서 해당 페이지를 불러온다. 접근 자체가 잘못되었다면, 해당 프로세스는 **abort(비정상 종료)** 된다.
    
이처럼, **필요할 때만 페이지를 메모리에 적재하는 방식**은 **Lazy Swapper** 또는 **Demand Paging**이라고 하며, 시스템의 **메모리 효율성과 응답성**을 크게 향상시킨다.

![](../images/Pasted%20image%2020250531182518.png)

기존의 MMU(Memory Management Unit)는 단순히 **논리 주소를 물리 주소로 변환하는 역할**만 수행했다.  하지만 Demand Paging이 도입되면서, 이제 MMU는 **주소 변환뿐만 아니라 해당 페이지가 메모리에 존재하는지도 확인**해야 한다.

만약 요청한 페이지가 이미 메모리에 존재한다면, 기존 방식과 동일하게 정상적으로 접근하면 된다.  하지만 **해당 페이지가 아직 메모리에 존재하지 않는다면**, MMU는 **page fault 예외를 발생시키고**,  운영체제가 디스크에서 해당 페이지를 읽어와 메모리에 적재한 뒤, 다시 접근을 시도하게 된다.

이 모든 과정은 **프로그램의 동작 흐름에 영향을 주지 않고**, **자동으로 투명하게 처리되어야 한다.**  
즉, 프로그래머는 이 과정에 대해 신경 쓰지 않아도 되며, **프로그램 코드 역시 변경할 필요가 없다.**

---
## **Valid-Invalid Bit**

MU는 주소를 변환하는 과정에서 **해당 페이지가 실제 메모리에 존재하는지도 확인**해야 한다. 이때 사용할 수 있는 것이 바로 **페이지 테이블의 Valid/Invalid 비트**이다.

처음에는 대부분의 페이지 엔트리가 **Invalid(i)** 상태로 표시되어 있으며, 이는 해당 페이지가 아직 메모리에 적재되지 않았음을 의미한다.

만약 변환된 주소가 **Invalid로 표시된 페이지**를 참조하면, 운영체제는 **디스크에서 해당 페이지를 메모리로 로딩**해야 한다. 이 과정은 매우 느리다. 왜냐하면 **디스크 접근 속도는 메모리보다 훨씬 느리기 때문**이다.

아무리 하나의 페이지를 불러오는 작업이라 하더라도, 수천 배 이상 느린 디스크 I/O가 발생하게 되며, 이 때 발생하는 예외 상황을 **Page Fault**라고 한다.

![](../images/Pasted%20image%2020250531183820.png)

---
## **Page Fault**

내가 Page를 접근하려고 하는데, Page에 대한 처음 접근이라면, trap을 발생시킨다! 이게 page fault !

Page fault가 발생하면 OS는 일단 유효한 주소에 대한 접근인지 확인을 해야한다.