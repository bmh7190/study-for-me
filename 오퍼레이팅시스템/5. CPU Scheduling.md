---

---
# CPU Scheduler

✅ 프로세스 상태 변화와 큐 간 이동

운영체제는 **다양한 큐(예: Ready Queue, I/O Queue 등)** 를 유지하면서  **프로세스의 상태 변화에 따라 해당 큐 간에 프로세스를 이동시킨다.**

![](../images/Pasted%20image%2020250328172852.png)

✅ 단기 스케줄러 (Short-Term Scheduler or CPU Scheduler)
**Ready Queue** 에 있는 프로세스들 중에서  **어떤 프로세스를 CPU에 할당할지 선택하는 역할**을 한다.

**CPU 스케줄러는 가장 자주 호출되는 스케줄러**이며,  → **밀리초 단위로 매우 자주 실행되므로 빠르게 동작해야 한다.**

일부 시스템에서는 **short-term scheduler가 유일한 스케줄러**일 수 있다.

---
# Basic Concept of CPU scheduling

**CPU를 최대한 활용**하려면, **시간 공유(Time-sharing)** 시스템에서는  **CPU에 할당된 프로세스를 빠르게 전환(Switch)해주는 것**이 중요하다.

### CPU burst 와 I/O burst

대부분의 프로세스 실행은 다음 두 가지 주기로 구성된다:

1. **CPU Burst**: CPU를 사용하여 계산 수행
2. **I/O Burst**: I/O 작업을 기다리는 시간 (예: 디스크, 네트워크 등)
        
        
일반적인 실행 흐름은 다음과 같다:  → **CPU Burst → I/O Burst → CPU Burst → ...**
    
따라서 CPU 스케줄링에서 중요한 점은 **CPU Burst의 분포(distribution)** 를 잘 파악하고  그에 맞게 **효율적인 스케줄링 정책**을 적용하는 것이다.

---
# CPU Scheduler

**CPU 스케줄러**는 **메모리 상에서 실행 준비(ready) 상태에 있는 프로세스들 중 하나를 선택**하여  **CPU를 할당**한다.

CPU 스케줄러는 **다음과 같은 경우에 스케줄링 결정을 내린다:**

1. 프로세스가 **Running → Waiting 상태**로 전환될 때  (예: I/O 요청 등)
2. 프로세스가 **Running → Ready 상태**로 전환될 때  (예: 타이머에 의한 시간 할당 종료 등)
3. 프로세스가 **Waiting → Ready 상태**로 전환될 때  (예: I/O 작업 완료 등)
4. 프로세스가 **종료(Terminated)** 될 때


- **1번과 4번**은 **Non-preemptive(비선점)** 상황  → 현재 프로세스가 **자연스럽게 CPU를 반납**
- **2번과 3번**은 **Preemptive(선점)** 상황  → CPU를 **강제로 다른 프로세스로 전환**할 수 있음


---

CPU 스케줄러는 **시스템 설계 원칙 중 하나인 정책과 메커니즘의 분리(Separation of Policy and Mechanism)** 에 따라 설계된다.

- **스케줄링 정책 (Scheduling Policy)**
    - 어떤 프로세스를 선택할지 결정하는 **전략(what to do)**
    - 예: FCFS, SJF, Round Robin, Priority 등
        
- **디스패처 (Dispatcher)**
    - 선택된 프로세스를 **실제로 CPU에 할당**하는 **동작(how to do)**
    - 컨텍스트 스위칭, 사용자 모드 전환, 프로그램 카운터 복원 등의 기능 포함

![](../images/Pasted%20image%2020250329234422.png)

---
# Dispatcher

**Dispatcher 모듈**은 **CPU 스케줄러가 선택한 프로세스에게 CPU 제어권을 넘겨주는 역할**을 한다.  
이 과정에는 다음 작업이 포함된다:

- **컨텍스트 스위칭**
- **사용자 모드로 전환**
- **사용자 프로그램의 재시작 위치로 점프**

#### ✅ Dispatcher는 어떻게 제어를 유지할까?

- **CPU는 한 번에 하나의 작업만 수행 가능**하다.
- 즉, **사용자 프로세스가 실행 중일 때는 디스패처는 실행되지 않는다.**

#### ✅ Dispatcher는 어떻게 제어를 다시 얻는가?

#####  **Non-Preemptive 방식**

- 운영체제가 **프로세스를 신뢰**하고,  
    → 프로세스가 **자발적으로 CPU를 반환**하거나 시스템 콜, I/O 요청 등을 통해  
    → **디스패처에게 제어를 넘겨주기를 기대**함.
    
- 하지만 이 방식은 **프로세스가 오작동하거나 반환하지 않으면 시스템 전체가 멈출 수 있음**.  
    → **신뢰 기반, 위험 존재**
    
#####  **Preemptive 방식**

- **디스패처에게 알람 시계를 제공**하여 강제로 제어권을 회수함.
    
- **타이머 하드웨어와 인터럽트(Interrupt)** 를 사용하여  
    → 일정 시간마다 **타이머 인터럽트를 발생시켜 커널로 제어를 전환**  
    → 디스패처가 다시 실행되어 **스케줄링 결정 수행 가능**

#### ✅ 운영체제로의 제어 권한 반환 (Control Returns to OS)

운영체제는 **다양한 이벤트를 통해 제어를 다시 획득**한다.  
이 이벤트는 **내부적인 것(traps, faults)** 과 **외부적인 것(interrupts)** 으로 나뉜다.

#####  Traps & Faults (내부 이벤트 – User Process 내부에서 발생)

- **시스템 콜 (System Call)**  → 사용자 프로세스가 OS의 서비스를 요청할 때
- **부동 소수점 예외 (Floating Point Exception)**  → 0으로 나누기 등 잘못된 계산 발생 시
- **페이지 폴트 (Page Fault)**  → 접근하려는 메모리 페이지가 메모리에 없을 때

#####  Interrupts (외부 이벤트 – User Process 외부에서 발생)

- **키보드 입력**  → 사용자가 터미널에 문자를 입력한 경우
- **디스크 전송 완료**  → I/O 장치에서 작업이 끝났을 때 OS에 알림    
- **타이머 인터럽트**  
    → OS가 **시간을 강제로 회수**하기 위해 설정한 타이머가 만료되었을 때  
    → **프로세스가 CPU를 독점하지 않도록 보장**

---
#### ✅ 디스패처는 어떻게 상태를 저장하고 복구하는가?

→ **Context Switch 메커니즘**을 통해 이루어진다.

#### Context Switch란?

- 현재 실행 중인 **프로세스의 상태(컨텍스트)** 를 저장하고,  
    다음에 실행할 프로세스의 상태를 복원하는 과정이다.
- 이 과정은 **디스패처(dispatcher)** 가 수행하며,  
    → 다른 프로세스에게 CPU를 넘기기 위해 반드시 필요하다.


####  반드시 저장해야 하는 것들

> 다음 프로세스가 **손상시킬 수 있거나 영향을 줄 수 있는 모든 것**을 저장해야 한다.

- **Program Counter (PC)**
- **Processor Status Word (PSW)**: CPU 상태 및 제어 플래그
- **General Purpose Registers**: 범용 레지스터
- **Floating-Point Registers**: 부동소수점 연산용 레지스터 (필요한 경우)


####  메모리는 전부 저장해야 할까?

- **모든 메모리를 저장하는 것은 현실적으로 비용이 너무 큼**  
    → 메모리는 용량이 크기 때문에, **모든 내용을 저장/복구하는 것은 비효율적**
    
- 따라서 **필요할 경우에만 일부 메모리를 디스크로 스왑(swap)** 한다  
    → 예: 페이지 교체, 프로세스 일시 중단 등

---
# Scheduling Policy

#### 디스패처가 통제권을 가졌을 때, 다음 프로세스를 어떻게 결정할까?

**방안 1:** 프로세스 테이블을 스캔하여 **가장 먼저 발견되는 실행 가능한 프로세스를 선택한다**.  
→ 하지만 이 방법은 **검색에 시간이 오래 걸릴 수 있고**,  
→ **이상한 우선순위 결과**를 낳을 수 있다.
→ 프로세스가 실행 가능한지 어떻게 알까?

**방안 2:** 실행 가능한 프로세스들을 **하나의 큐로 연결**한다.  
→ 디스패처는 **큐의 맨 앞에 있는 프로세스**를 선택하여 실행한다.  
→ 새롭게 실행 가능한 프로세스는 **큐의 맨 뒤에 삽입**된다.

**방안 3:** 각 프로세스에 **우선순위(priority)** 를 부여한다.  
→ 큐를 **우선순위에 따라 정렬하거나**,  
→ **우선순위 별로 큐를 따로 유지**할 수 있다.  
→ 디스패처는 **높은 우선순위 큐에서 먼저 선택**한다.

---
##  누가 우선순위를 결정하고, 어떻게 선택되는가?

- **누가?**  
    → **운영체제 내에서 스케줄러(scheduler)** 가 우선순위를 결정한다.
    
- **왜 디스패처가 아닌가?**  
    → 이는 **정책(policy)** 과 **메커니즘(mechanism)** 의 분리라는 개념 때문이다.
    
스케줄러는 "어떤 프로세스를 선택할 것인가?"를 결정하는 정책을 담당하고, 디스패처는 "선택된 프로세스를 어떻게 실행할 것인가?"를 수행하는 메커니즘을 수행한다. 

---

# Scheduling Policies

## Scheduling Criteria

- **CPU Utilization (CPU 이용률)**  
    → 가능한 한 **CPU를 바쁘게 유지**하는 것이 목표  
    → 값이 높을수록 자원을 효율적으로 사용하고 있다는 뜻
    
- **Throughput (처리량)**  
    → 단위 시간당 **완료된 프로세스 수**  
    → ex) 초당 5개 프로세스 완료
    
- **Turnaround Time (반환 시간)**  
    → **프로세스가 시작부터 종료까지 걸린 전체 시간**  
    → = 완료 시간 - 도착 시간
    
- **Waiting Time (대기 시간)**  
    → 프로세스가 **Ready Queue에서 기다린 시간의 총합**  
    → CPU를 실제로 사용하지 않고 대기한 시간
    
- **Response Time (응답 시간)**  
    → **요청이 제출된 시점부터 첫 번째 응답이 나올 때까지 걸린 시간**  
    → _Time-sharing 시스템에서 중요한 지표_  
    → 최종 결과가 아니라 **첫 반응이 나오는 시간**

---

## Basic Concept of CPU scheduling

- **CPU 사용률(CPU utilization)** 을 최대화해야 하며, **시간 공유(Time Sharing)** 환경에서는 **프로세스를 빠르게 전환(switch)** 하여 CPU를 효율적으로 활용해야 한다.

###  CPU Burst 와 I/O Burst

- 프로세스 실행은 **CPU 수행 시간(CPU burst)** 과 **I/O 대기 시간(I/O burst)** 의 반복으로 구성된다.
    
- 일반적인 실행 흐름:  → **CPU burst → I/O burst → CPU burst → ...**
    
- **CPU burst의 분포(distribution)** 가 스케줄링 정책 설계에서 중요한 고려 요소이다.  
    → 예: 짧은 CPU burst가 많은 경우에는 SJF(Sortest Job First) 같은 정책이 효과적일 수 있다.


---
## Scheduling Alogrithm

- **CPU 스케줄러가 사용하는 알고리즘**들을 **스케줄링 정책(Scheduling Disciplines)** 이라고 한다.
- 대표적인 스케줄링 알고리즘 종류:
    
    1. **FIFO (First-In, First-Out)** (**FCFS**)
        → 먼저 도착한 프로세스를 먼저 실행
        
    2. **RR (Round Robin)**  
        → 모든 프로세스에게 **고정된 시간 할당량(time quantum)** 을 주고 **순차적으로 CPU를 할당**
        
    3. **SJF (Shortest Job First)**  
        → **CPU burst 시간이 가장 짧은 프로세스**부터 실행
        
    4. **MLFQ (Multilevel Feedback Queue)**  
        → 여러 개의 큐와 **우선순위**, **동적 이동**을 이용해 다양한 작업 유형을 처리  
        → **interactive vs batch jobs** 구분에 적합

---
## First-Come, First-Served(FSFS)

####  핵심 아이디어:

- **처음 온 프로세스가 끝날 때까지 실행**하게 한다.
- 이 방식은 **FIFO 스케줄링** 또는 **비선점형(non-preemptive) 스케줄링** 이라고도 불린다.
- 간단한 상황에서는 이 방식이 **단일 프로그램(uniprogramming)** 환경을 의미할 수 있다.
- 일반적으로 **"끝남(finished)"** 은 **blocked 상태로 전환됨**을 의미한다.  → 예: I/O 대기, 세마포어 대기 등
- 한 프로세스가 blocked 되면, 다른 프로세스가 CPU를 사용하고,  다시 준비되면 **run queue의 맨 뒤로 이동한다.**
    
#### 문제점:

- **하나의 프로세스가 CPU를 독점**할 수 있다.  → 다른 프로세스들은 장시간 대기하게 됨
    
#### 해결책: Time Slice (시간 할당량)

- **하나의 프로세스가 context switch 없이 실행할 수 있는 최대 시간을 제한**한다.  
    → 이 시간을 **Time Slice** 또는 **Time Quantum** 이라고 한다.
    
- 일정 시간마다 **강제로 컨텍스트 스위치**를 발생시켜  
    → **모든 프로세스가 공평하게 CPU를 사용할 수 있도록 한다.**
    


![](../images/Pasted%20image%2020250330165855.png)

P₁ → P₂ → P₃ 순으로 실행 된다고 했을 때, P₁의 실행 시간이 24이기 대문에 P₂의 waiting time은 24, P₃ 의waiting time 24 + 3 = 27이다. 그래서 평균 waiting time은 17이다.

아래의 경우를 보자

![](../images/Pasted%20image%2020250330170200.png)

아래의 경우를 보자 실행 시간이 가장 긴 P₁을 가장 마지막에 배치하면 P₂, P₃의 waiting time은 많이 줄어들게 된다. 최종적으로 평균 시간은 3이다.

### Convoy effect

- **긴 프로세스가 앞에 실행되면**, **뒤따르는 짧은 프로세스들이 모두 대기하게 되어 전체 평균 대기 시간이 증가**한다.
    
- 이러한 현상을 **Convoy Effect** 라고 하며,  → 시스템 전체의 응답성을 저하시킬 수 있다.


---
## Shortest Job First ( SJF )

#### ✅ 핵심 동작 원리 

- 각 프로세스에 대해 **다음 CPU burst 시간의 길이를 추정**하고,
- **가장 짧은 CPU burst를 가진 프로세스부터 실행**한다.
- SJF는 **이론적으로 최적의 스케줄링 알고리즘**이다.  → **모든 프로세스에 대해 평균 대기 시간을 최소화**할 수 있다.

#### ✅ 한계점

**다음 CPU burst 시간이 정확히 얼마일지 사전에 알기 어렵다.**  
→ 예측에 기반한 스케줄링이 필요하며,  실제 시스템에서는 완벽한 SJF 구현이 어려울 수 있다.


#### ✅ SJF의 두 가지 형태: Non-preemptive vs Preemptive

##### **Non-preemptive SJF**

- 현재 CPU를 사용 중인 프로세스가 **CPU burst를 모두 마칠 때까지 실행**된다.
- **도중에 다른 프로세스가 도착하더라도**,  기존 프로세스를 선점(preempt)하지 않는다.**
    
#####  **Preemptive SJF**

- **새로운 프로세스가 도착했을 때**,   그 프로세스의 **CPU burst 시간이 현재 실행 중인 프로세스의 남은 시간보다 짧으면**,   **현재 프로세스를 선점하고(new process takes over)** 새로 온 프로세스를 실행한다.
    
- 이 방식은  **SRTF (Shortest Remaining Time First)** 또는   **STCF (Shortest Time to Completion First)** 라고도 불린다.


![](../images/Pasted%20image%2020250330171832.png)

non-preemptive일 경우 처음 P1이 돌아가고 있을 때 P2, P3, P4가 차례대로 들어와도, burst time이 작은 순서대로 재배열 되어 실행된다. 


![](../images/Pasted%20image%2020250330172008.png)

**Preemptive**방식에서는 **새로운 프로세스가 도착했을 때**,  **현재 실행 중인 프로세스의 남은 시간보다 더 짧은 burst time**을 가지면,  선점(preemption)** 이 발생하여 **새로운 프로세스가 실행**된다.

1. **P1**이 먼저 실행되고 2가 지난 시점에 **P2** 도착
    - P1의 **남은 시간: 5**
    - P2의 **burst time: 4** → 더 짧으므로 **P2가 P1을 선점**
        
2. **P2**가 실행 중 2가 지난 시점에 **P3** 도착
    - P2의 **남은 시간: 2**
    - P3의 **burst time: 1** → 더 짧으므로 **P3가 P2를 선점**
        
3. **P3** 실행 후 종료되었을 때 **P4** 도착
    - P4의 **burst time: 4**
    - 하지만 **P2의 남은 시간: 2** → 더 짧기 때문에 **P2가 계속 실행**

이런 방식은 context switching이 자주 발생 가능하기 때문에 더 많은 시간이 필요할 수도 있다.

---

### ✅ 다음 CPU Burst 예측의 어려움

- **정확한 CPU burst 시간을 알 수 없기 때문에**,  **과거의 실행 시간을 바탕으로 추정(predict)** 해야 한다.
- 일반적으로 **이전 CPU burst 시간과 비슷할 것이라고 가정**한다.  이를 기반으로 **다음 burst가 가장 짧을 것으로 예측되는 프로세스를 선택**하는 방식이 **SJF**에서 사용된다.

$$τ_{n+1}​​=α⋅t_n​+(1−α)⋅τ_n$$​

- $t_n$​: 실제 측정된 **n번째 CPU burst 시간**
- $t_n$​: **이전** CPU burst의 예측값
- $τ_{n+1}$​: **다음** CPU burst의 예측값
- α: **가중치 계수 (smoothing factor)**, 0≤α≤1

최근 값의 비중 늘리고 싶으면 α를 올리면 되고, 예측 값 비중을 늘리고 싶으면 α를 내리면 됩니다.

![](../images/Pasted%20image%2020250330173139.png)

실제 값과 실제 값을 통해 예측된 값이 비슷한 양상을 보인다.

$$τ_{n+1}​​=α⋅t_n​+(1−α)⋅τ_n$$​
이 식을 계속 전개하면,

$$τ_{n+1}​=αt_n​+(1−α)αt_{n−1}​+(1−α)^2αt_{n−2}​+⋯+(1−α)^nτ_0$$​

각 항은 **이전 burst 시간들에 대한 가중합**이다. **가중치는 시간이 지날수록 점점 줄어든다.**  
α,(1−α)≤1이기 때문에  **가장 최근의 burst 시간(tₙ)에 가장 큰 영향을 주고**,  **이전 값들은 점점 덜 반영된다.**

---
## Round Robin

#### ✅ 핵심 작동 원리

- 각 프로세스는 **고정된 시간 조각(time quantum, q)** 만큼 CPU를 할당받는다.
- 일반적으로 **10~100ms** 사이로 설정된다.
- **q 시간이 지나면**, 해당 프로세스는 **선점(preempt)** 되고  **Ready Queue의 맨 뒤로 이동**한다.
- **타이머 인터럽트(timer interrupt)** 가 **time quantum마다 발생**하여  다음 프로세스를 스케줄링한다


#### ✅ 성능

- **q가 크면** RR은 거의 **FIFO(First-Come First-Served)**처럼 동작하고,  짧은 프로세스가 손해**를 본다.   
- **q가 작으면** **Context Switching이 자주 발생**하여  오버헤드가 증가**하고 CPU 낭비가 발생할 수 있다.


**대부분의 현대 운영체제는 RR의 변형을 사용**한다.

![](../images/Pasted%20image%2020250330174155.png)


각 프로세스는 **최대 4단위 시간** 동안 CPU를 사용한다 4단위 시간이 **끝나기 전에 종료되면** 그대로 종료하고, 4단위 시간이 **끝나도 작업이 남아 있으면** **선점(preempt)** 되고 **Ready Queue 맨 뒤로 이동**


n개의 프로세스가 **Ready Queue**에 있고, **time quantum**이 q일 때,  
각 프로세스는 **최대 q 시간 단위로 한 번에 1/n의 CPU 시간을 할당받는다.**  
이때, **어떤 프로세스도 (n-1)q 시간 이상 대기하지 않는다.**


### ✅ Round Robin의 단점

**Round Robin** 스케줄링은 경우에 따라 **효율적이지 않은 결과**를 초래할 수 있다.  

예를 들어, 10개의 프로세스가 각각 **100의 time quantum**을 필요로 할 때,  
**Round Robin** 방식은 **1000 time quantum**이 걸린다.  
반면 **FIFO** 방식은 **평균적으로 500 time quantum**만으로 작업을 끝낼 수 있다.  
따라서 **Round Robin**은 **공평함**을 보장할 수 있지만, **효율성** 면에서는 부족할 수 있다.

---

## **Priority Scheduling**

**우선순위 숫자는 각 프로세스와 연관**되어 있다.  
예를 들어, **실시간 CPU 스케줄러**는 **우선순위가 중요한 요소**로, **가장 중요한 작업을 먼저 실행**해야 한다.

**CPU는 가장 높은 우선순위의 프로세스에게 할당**된다.

- 높은 우선순위는 **가장 작은 숫자**로 나타낸다.
- 스케줄링은 **Preemptive**와 **Non-preemptive** 방식으로 구분된다.

**SJF**(Shortest Job First) 알고리즘은 **예상되는 CPU burst time의 반대 우선순위**를 가진다.  
→ **짧은 burst time**을 가진 프로세스는 **우선순위가 높고 먼저 실행**된다.

#### 문제점

**낮은 우선순위**를 가진 프로세스는 **절대 실행되지 않을 수 있는 위험**이 있다.  이를 **Starvation**이라고 한다.
    
#### **해결책

시간이 지날수록 우선순위를 높여주는 방법**이 있다.  이 방법은 **Starvation을 방지**하고, **낮은 우선순위 프로세스도 결국 실행**될 수 있도록 보장한다.

![](../images/Pasted%20image%2020250402134354.png)


---
## **Multilevel Queue**

**Ready Queue는 여러 개의 큐로 분할**되어 관리될 수 있다. 

- **Foreground (Interactive)**: 사용자와의 상호작용을 위한 프로세스
- **Background (Batch)**: 배치 작업을 위한 프로세스

각 큐는 **자체적인 스케줄링 알고리즘**을 갖는다:    

- **Foreground 큐**: **Round Robin (RR)**
- **Background 큐**: **First-Come, First-Served (FCFS)**

#### ✅ 큐 간 스케줄링

- 큐들 간에도 스케줄링이 **필요하다.**  예를 들어, **고정된 우선순위 스케줄링**을 사용하여,**먼저 Foreground 큐**의 프로세스를 모두 처리한 뒤 **Background 큐**의 프로세스를 처리하는 방식이다.
        
- 하지만 이 방법은 **Starvation**의 문제를 일으킬 수 있다.  
    → **Foreground 큐**의 프로세스가 **우선 실행되기 때문에**,  
    → **Background 큐**의 프로세스가 **오래 대기할 수 있다.**

#### ✅ 해결책: Time Slice

- **Time Slice**: 각 큐는 CPU 시간을 일정 비율로 할당받는다.  
    
    - **80%는 Foreground 큐 (RR)** 에 할당되고
        
    - **20%는 Background 큐 (FCFS)** 에 할당된다.
        
- 이렇게 하면 **Starvation을 방지**하고, 각 큐에서 **공평하게 CPU를 사용할 수 있도록** 한다.

![](../images/Pasted%20image%2020250402135526.png)

---
## **Multilevel Feedback Queue**


**Multilevel Feedback Queue (MLFQ)** 스케줄러는 프로세스가 **다양한 큐 사이에서 이동**할 수 있는 방식이다.  이 스케줄러는 여러 파라미터에 의해 정의된다:


1. **큐들의 수**: 여러 개의 큐가 존재하며, 각 큐는 **다른 우선순위**를 가지고 있다.
        
2. **각 큐에 따른 스케줄링 알고리즘**: 각 큐는 서로 다른 스케줄링 알고리즘을 사용할 수 있다.
            
3. **프로세스 업그레이드 조건**:
    
    - **프로세스가 더 높은 우선순위 큐로 업그레이드**될 때, 이를 결정하는 기준이 필요하다.
        
    - 예를 들어, **인터랙티브 작업**은 빠르게 반응해야 하므로, 일정 시간 후에 **상위 큐로 이동**할 수 있다.
        
4. **프로세스 다운그레이드 조건**:
    
    - **프로세스가 더 낮은 우선순위 큐로 다운그레이드**될 때, 이를 결정하는 기준도 필요하다.
        
    - 예를 들어, **CPU bound 프로세스**는 시간이 길어질수록 **하위 큐로 이동**할 수 있다.
        
5. **프로세스가 어느 큐로 들어갈지 결정하는 방법**:
    
    - 프로세스가 **처음 시작하거나 큐에 들어갈 때**, 어느 큐로 배정할지를 결정하는 방법이 필요하다.
        
    - 예를 들어, **새로 시작하는 프로세스**는 보통 **가장 높은 우선순위 큐**에서 시작할 수 있다.

#### Example

![](../images/Pasted%20image%2020250402140057.png)


**4개의 큐 (Q0, Q1, Q2, Q3)** 가 있으며, 각 큐는 **RR (Round Robin)** 알고리즘을 사용하고 **time quantum**이 다르게 설정된다:
    
- **Q0**: Time quantum = **1ms**
- **Q1**: Time quantum = **2ms**
- **Q2**: Time quantum = **4ms**
-  **Q3**: Time quantum = **8ms**

**새로 실행 가능한 프로세스**는 **Q0**에 배정된다.
    
프로세스가 **time slice를 모두 소진**하고 **I/O 요청 없이 실행을 끝낼 경우**,  해당 프로세스의 **우선순위가 1단계 낮아진다**.
    
$$ Q0 → Q1
 , Q1 → Q2
 , Q2 → Q3$$
        
**우선순위 감소**는 **blocking 없이** 실행한 프로세스가 **시간을 오래 사용**했을 때,  **다음 큐로 내려가게 하여 CPU를 더 많이 차지**하지 않도록 한다.

두 프로세스가 있다. 
- **P1**:**1ms 실행 후 I/O 요청**을 하고 **10ms 대기**.
- **P2**: **I/O 요청 없이 계속 실행**된다.

#### ✅ 실행 시나리오

1. **P1**은 1ms 동안 실행된 후 **I/O 요청**을 하여 **블록(block)** 된다.
2. **P2**는 1ms 동안 실행되고 **블록되지 않음**. **P2**는 **Q0에서 Q1로 이동** (time quantum 2ms)
3. **P2**는 2ms 동안 실행되고 **블록되지 않음**. **P2**는 **Q1에서 Q2로 이동** (time quantum 4ms)
4. **P2**는 4ms 동안 실행되고 **블록되지 않음**. **P2**는 **Q2에서 Q3로 이동** (time quantum 8ms)
5. **P2**는 3ms 동안 실행되며 **I/O 응답을 받아 preemption**된다.
6. **P1**은 1ms 동안 실행되며 **I/O 요청** 후 **블록됨**.
7. **P2**는 8ms 동안 실행되며 **블록되지 않음**.
8. **P1**은 1ms 동안 실행되며 **다시 블록됨**.
9. **P2**는 8ms 동안 실행되며 **블록되지 않음**.
10. **P1**은 1ms 동안 실행되고 **블록됨**.
11. **P2**는 실행을 계속하고, **P1이 준비될 때까지 기다린 후 P1을 선점(preempt)**.
    

---
## **Thread Scheduling**

**User-level 쓰레드**와 **Kernel-level 쓰레드**는 구분된다.

**쓰레드가 지원될 때**, 실제로 **스케줄링되는 것은 프로세스가 아닌 쓰레드**이다.  
→ 각 프로세스 내에서 여러 쓰레드가 동시에 실행될 수 있다.

#### ✅ Process-Contention Scope (PCS)

- **PCS**는 **하나의 프로세스 내에서 쓰레드 간 경쟁**을 의미한다. → **Many-to-One** 모델이나 **Many-to-Many** 모델에서, **사용자 수준의 쓰레드 라이브러리**가 **커널 수준 쓰레드(LWP, Lightweight Process)** 에 매핑하여 **사용자 쓰레드를 스케줄링**한다.
    
- **프로그램이 설정한 우선순위**에 따라 스케줄링된다.
#### ✅ System-Contention Scope (SCS)

- **SCS**는 **시스템 전체에서의 쓰레드 간 경쟁**을 의미한다.  
    → **커널 수준의 쓰레드**는 **사용 가능한 CPU**에 할당된다.
    
- 이 경우, **시스템 전반에서 쓰레드가 경쟁**하기 때문에, 각 쓰레드는 **전체 시스템 자원과 경쟁**한다.


---
# **Operating System Examples**

## **Linux Scheduling

리눅스는 공평한 스케줄링**을 사용하며, 여러 스케줄링 클래스가 존재한다.
    
**각 스케줄링 클래스는 고유한 우선순위**를 가진다.  **스케줄러는 가장 높은 우선순위를 가진 작업**을 선택하여 실행한다.

#### ✅ 시간 할당 기반 스케줄링

**고정된 시간 할당(quantum)** 대신, **CPU 시간의 비율에 기반한 가변적인 시간 할당**을 사용한다.  
→ 즉, **각 프로세스가 CPU 시간을 일정 <u>비율</u>로 분배받으며**,  **고정된 시간 할당량이 아니라 <u>비율</u>에 따라 유동적으로 실행 시간**이 조정된다.

**기본 클래스(Default)** 와 **실시간 클래스(Real-Time)** 가 제공된다.  
Default 클래스**는 일반적인 프로세스를 위한 스케줄링을,  Real-Time 클래스**는 **실시간 프로세스**를 위한 높은 우선순위 스케줄링을 담당한다.
    
**추가적인 스케줄링 클래스**도 필요에 따라 시스템에 추가할 수 있다.

#### ✅ Quantum과 Nice Value

**Quantum**은 **-20에서 19 사이의 nice value**에 의해 계산된다.
    
**낮은 nice value가 더 높은 우선순위**를 가진다.
**Nice 값이 낮을수록** 프로세스는 **더 높은 우선순위를 가지며 CPU를 더 많이 사용할 수 있다.**
        

#### ✅ Target Latency

**Target Latency**는 **작업이 최소한 한 번 실행되어야 하는 시간 간격**을 나타낸다.
    
**활성화된 작업의 수**가 증가하면, **Target Latency**는 **늘어날 수 있다.**  더 많은 작업이 활성화되면, 각 작업이 실행될 수 있는 기회가 줄어들기 때문이다.

---

## **CFS (Completely Fair Scheduler) 동작 원리

- **CFS 스케줄러**는 각 프로세스에 대해 **가상 실행 시간(vruntime)을 유지한다.
    
    - **vruntime**은 프로세스가 **실제로 실행한 시간**을 바탕으로 계산된다.
        
- **우선순위에 기반한 감쇠 계수(decay factor)**를 사용하여,**우선순위가 낮을수록 더 높은 감쇠율**을 가진다.  낮은 우선순위의 프로세스는 더 빨리 실행 기회를 얻기 위해 **vruntime이 더 빨리 증가**한다.
        
- **기본적으로 vruntime은 실제 실행 시간**과 동일하다.
- 우선순위가 **정상인 프로세스**는 **vruntime이 실제 실행 시간**에 해당한다.
        
- **다음 실행할 작업을 결정하기 위해**, 스케줄러는 vruntime이 가장 낮은 작업**을 선택한다.  즉, **가장 적은 시간 동안 실행된 프로세스**가 가장 먼저 실행된다.
        

---

### ✅ Task의 Time Slice 계산

- **Task의 Time Slice**는 다음과 같이 계산된다:
    

$$
\text{Time Slice} = \text{Target Latency} \times \left( \frac{\text{Task Weight}}{\sum \text{Weights}} \right)
$$


- **Target Latency**는 작업이 실행되는 최소 시간 간격을 의미한다.
- **Task Weight**는 해당 작업의 가중치를 의미하며, **가중치가 클수록 더 많은 CPU 시간을 할당받는다**.
- **∑Weights**는 전체 작업의 가중치 합이다.  
    → 즉, 모든 작업의 상대적인 가중치를 고려하여 각 작업에 할당되는 CPU 시간 비율이 결정된다.
        

---

### ✅ Virtual Run Time (vruntime) 계산

- **vruntime**은 **실행시간**을 바탕으로 다음과 같이 계산된다:
    

$${vruntime}_t = \frac{\text{실행시간} \times 1024}{\text{Weight}}$$
    
- **실행시간**은 프로세스가 실제로 CPU를 사용한 시간이다.
- **Weight**는 해당 프로세스의 **우선순위**를 나타내며, **우선순위가 높을수록 작은 weight**를 갖는다.
- **1024**는 스케줄링의 정밀도를 높이기 위한 스케일링 팩터이다.
        

---

### ✅ Real-time 작업의 우선순위

- **Real-time 작업**은 **정적인 우선순위**를 가지고 있다. 우선순위는 **0에서 99 사이**의 값으로 설정된다.
    
- **Real-time 작업**과 **일반(normal) 작업**은 **전역 우선순위(global priority scheme)**로 매핑된다.
    
- **Nice value**에 따라 **전역 우선순위**가 다르게 매핑된다:
    
    - **Nice value -20**은 **전역 우선순위 100**에 해당한다.
    - **Nice value +19**는 **전역 우선순위 139**에 해당한다.

![](../images/Pasted%20image%2020250402145838.png)


---
## **Example of CFS

Target latency = 10ms

![](../images/Pasted%20image%2020250402145930.png)


---
## **Advanced Topic of Scheduling**

**멀티 프로세서 시스템**에서 CPU 스케줄링은 **단일 프로세서 시스템**보다 더 복잡하다. 여러 개의 **CPU**가 동일한 시스템 자원을 공유하면서 작업을 처리하기 때문이다. 여기서 **다양한 형태**의 CPU 시스템들이 존재한다.

### **Asymmetric Multiprocessing (비대칭 멀티프로세싱)**

- **하나의 프로세서만** 시스템 데이터 구조에 접근할 수 있다.
- 다른 프로세서들은 **작업을 분담**하되, **공유된 데이터에 접근하지 않는다**.
- **간단한 데이터 공유**가 필요하지 않기 때문에 **시스템 구조가 단순**하다.
- 주로 **하나의 프로세서**가 **메인 제어 역할**을 맡고, 나머지 프로세서들은 특정 작업을 분담한다.
    

### **Symmetric Multiprocessing (대칭 멀티프로세싱)**

- 각 프로세서는 **자기 자신이 스케줄링을 담당**하고, 모든 프로세스는 **공통의 준비 큐(ready queue)** 에서 처리될 수 있다.
- 또는 각 프로세서가 **자기만의 준비 큐**를 가지고 있을 수도 있다.
- **현재 대부분의 멀티 프로세서 시스템**에서 사용하는 방식이다.
- 각 CPU가 **독립적으로 작업을 처리**할 수 있기 때문에 **효율적인 병렬 처리**가 가능하다.

##### 1. **Common Ready Queue (공통 준비 큐)**

- **모든 스레드**는 하나의 **공통 준비 큐**에 들어간다.
    
- **모든 CPU**는 이 **공통 큐**에서 스케줄링된 스레드를 가져다 실행한다.
    
- **장점**: 큐가 하나만 있으면 **스케줄링 관리**가 간단하다.
    
- **단점**: **모든 프로세서가 동일 큐에 접근**해야 하므로, **동기화** 문제가 발생할 수 있고, **경쟁 조건**이 생길 수 있다.
    

##### 2. **Per Core Ready Queue (각 코어별 준비 큐)**

- 각 **CPU** 또는 **코어**는 **자기만의 준비 큐**를 가지고 있다.
    
- 각 코어는 **자기 큐에서만 스케줄링된 스레드를 처리**하고, 다른 코어의 큐와 **독립적으로 동작**한다.
    
- **장점**: 각 코어가 독립적으로 큐를 관리하므로 **경쟁을 줄일 수** 있고, **효율적인 스케줄링**이 가능하다.
    
- **단점**: **스레드 배분**이 불균형하게 될 수 있고, **다른 코어와의 상호작용**이 필요할 수 있다.

![](../images/Pasted%20image%2020250411211529.png)

---
## **Load Balancing**

**SMP(Symmetric Multiprocessing)** 시스템에서 운영체제(OS)는 **모든 CPU가 효율적으로 동작**하도록 해야 한다. 이를 위해 **로드 밸런싱(load balancing)** 을 통해 작업을 **균등하게 분배**하려고 한다.

1. **Push Migration (푸시 마이그레이션)**:
    
    - **정기적인 작업 확인**을 통해 **각 프로세서의 로드 상태**를 점검한다.
    - **과부하가 걸린 CPU**를 찾고, 그 CPU에서 **다른 CPU로 작업을 밀어낸다**.
    - 이렇게 하면 **과부하가 걸린 CPU의 부하를 분산**시킬 수 있다.
        
2. **Pull Migration (풀 마이그레이션)**:
    
    - **유휴 상태인 CPU**가 **작업이 대기 중인 CPU**로부터 작업을 **끌어온다**.
    - 유휴 CPU가 다른 프로세서에서 **대기 중인 작업을 가져와** 작업을 시작한다.

---
## **Read-Time CPU Scheduling**

**Soft Real-Time 시스템**:
Critical real-time process**가 언제 스케줄될지에 대한 보장이 없다.
유연성**이 있지만, **엄격한 시간 요구사항**이 없어서 **일정 시간 내에 작업을 완료하지 못할 수 있다**.
        
**Hard Real-Time 시스템**:
**엄격한 시간 요구사항**이 있다. **태스크**는 반드시 **마감 기한 내에 서비스**를 받아야 한다. 즉, **기한을 놓치면 시스템이 실패한 것으로 간주**된다.


##### **두 가지 종류의 레이턴시 (Latency)**

 **Interrupt Latency (인터럽트 레이턴시)**:
 
- **인터럽트가 발생한 시점**부터 **ISR(인터럽트 서비스 루틴)이 시작되는 시점**까지의 시간 차이.
- 시스템이 **인터럽트를 인식하고 해당 작업을 처리**하기까지 걸리는 시간이다.
        
 **Dispatch Latency (디스패치 레이턴시)**:
 
- **컨텍스트 스위칭**을 통해 **다음 프로세스를 실행할 준비가 완료되는 시간**.
- **프로세스의 상태를 저장하고, 새로운 프로세스를 실행하기 위한 준비**에 소요되는 시간이다.

![](../images/Pasted%20image%2020250411213229.png)


---
## **Priority-based Scheduling**

**Real-time scheduling**에서는 스케줄러가 **선점형(priority-based)** 스케줄링을 지원해야 한다. 그러나 이는 **소프트 실시간**(soft real-time)만 보장한다.

- **소프트 실시간** 시스템은 **정확한 마감 기한**을 보장하지 않지만, 시스템이 **가능한 한 빠르고 효율적으로** 작업을 처리한다.
    
- **하드 실시간**(hard real-time) 시스템에서는 태스크가 **정확한 기한 내에 처리**될 수 있도록 보장해야 한다. 즉, **기한을 넘기면 시스템이 실패**하는 것으로 간주된다.
    

##### **주기적인 프로세스의 특성**

- **주기적인 프로세스**는 **CPU 자원**을 **일정 간격**으로 요구한다.
    
- **각 프로세스**는 **처리 시간 t**, **마감 기한 d**, **주기 p**를 가진다.
    
    - **0 ≤ t ≤ d ≤ p** 
    - (처리 시간 `t`는 마감 기한 `d` 이내여야 하며, 마감 기한 `d`는 주기 `p` 이내여야 한다.)
        
- **주기의 비율**은 **1/p**로, 즉 **주기가 짧을수록 더 자주 CPU를 요청**하게 된다.

![](../images/Pasted%20image%2020250411213545.png)

---
## **Rate Monotonic Scheduling**

**우선순위**는 **주기의 역수**에 따라 할당된다. 즉, **짧은 주기를 가진 프로세스**가 **높은 우선순위**를 가지며, **긴 주기를 가진 프로세스**는 **낮은 우선순위**를 가진다.

##### **예시** 1

|     | 프로세스 | 주기 ( p ) | 처리 시간 ( t ) | 마감 기한 (d) | CPU utilization |
| --- | ---- | -------- | ----------- | --------- | --------------- |
| 1   | P1   | 50       | 20          | 다음 주기의 시작 | 20/50  = 40%    |
| 2   | P2   | 100      | 35          | 다음 주기의 시작 | 35/100 = 35%    |

**P1**은 **주기 p = 50**이므로 우선순위가 **높다**. (주기가 짧기 때문에 더 자주 실행해야 하므로 우선순위가 높다) **P2**는 **주기 p = 100**이므로 우선순위가 **낮다**. (주기가 길어 실행 빈도가 적어 우선순위가 낮다)

![](../images/Pasted%20image%2020250411213850.png)


##### **예시** 2
|     | 프로세스 | 주기 ( p ) | 처리 시간 ( t ) | 마감 기한 (d) | CPU utilization |
| --- | ---- | -------- | ----------- | --------- | --------------- |
| 1   | P1   | 50       | 25          | 다음 주기의 시작 | 25/50  = 50%    |
| 2   | P2   | 80       | 35          | 다음 주기의 시작 | 35/80 = 43.75%  |
![](../images/Pasted%20image%2020250411214330.png)



$$
\sum_{i=1}^{N} \text{Utilization}_i < N \times \left( 2^{\frac{1}{N}} - 1 \right)
$$

**N 개의 프로세스**가 있을 때, 이 조건을 만족하면, **Rate Monotonic Scheduling**을 사용할 때 **deadline을 보장할 수 있다**. 

---
## **Earliest Deadline First Scheduling (EDF)**

**우선순위**는 **마감 기한(deadline)** 에 따라 할당된다. **마감 기한이 빠를수록 우선순위가 높고**, **마감 기한이 늦을수록 우선순위가 낮다**.

|     | 프로세스 | 주기 ( p ) | 처리 시간 ( t ) | 마감 기한 (d) | CPU utilization |
| --- | ---- | -------- | ----------- | --------- | --------------- |
| 1   | P1   | 50       | 25          | 다음 주기의 시작 | 25/50  = 50%    |
| 2   | P2   | 80       | 35          | 다음 주기의 시작 | 35/80 = 43.75%  |
**P1**은 **주기 p = 50**으로, 마감 기한이 더 빠르므로 우선순위가 **높다**. **P2**는 **주기 p = 80**으로, 마감 기한이 **P1보다 늦기** 때문에 우선순위가 **낮다**.

$$
\sum_{i=1}^{N} \text{Utilization}_i <  1 
$$

위의 식을 무조건 만족한다.