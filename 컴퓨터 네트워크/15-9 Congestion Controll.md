### 복습 Packet Switching vs Circuit Switching

우리가 통신을 하는 방식은 크게 **Packet Switching** 과 **Circuit Switching** 두 가지로 나눌 수 있다.  이 두 방식의 가장 큰 차이점은 **“경로를 어디서, 어떻게 설정하느냐”** 에 있다.

먼저 **패킷 교환 방식**은 중앙에서 전체 경로를 미리 정하지 않는다. 송신지와 수신지의 주소만 알면 되고, 중간 경로는 각 라우터가 그때그때 네트워크 상황에 따라 **동적으로 결정**한다.  
데이터는 일정 크기의 **패킷 단위**로 쪼개져 각각 독립적으로 전송되며, 서로 다른 경로를 통해 도착할 수도 있다.  이 때문에 모든 패킷이 반드시 같은 경로를 거치지는 않는다.  

중앙에서 경로를 통제하지 않기 때문에 **모니터링이나 제어가 어렵고**, 네트워크의 혼잡도에 따라 **전송 지연 시간이 일정하지 않다.**  하지만 여러 사용자가 네트워크 자원을 효율적으로 공유할 수 있고, 필요할 때만 전송하므로 전체적인 자원 활용률이 높다는 장점이 있다.  

우리가 사용하는 **인터넷이 바로 이 패킷 교환 방식**을 기반으로 동작한다.

반면 **회선 교환 방식**은 통신을 시작하기 전에 송신자와 수신자 사이의 **경로를 중앙에서 미리 설정**한다.  즉, 데이터를 주고받기 전에 하나의 **전용 회선(회로)** 을 확보하고, 통신이 끝날 때까지 그 경로가 **고정적으로 유지**된다.  

이 회선은 다른 트래픽의 영향을 받지 않기 때문에 **일관된 속도와 안정적인 품질**을 보장할 수 있다.  하지만 모든 사용자가 동시에 회선을 요청하면 사용할 수 있는 경로가 부족해 **연결 자체가 불가능한 상황**이 발생할 수도 있다. 또한 한 번 연결된 회선은 통신이 끝날 때까지 점유되므로, 자원 활용 효율이 낮다는 단점이 있다.  

전화 통신이 대표적인 회선 교환 방식의 예다.

---

우리가 지금 보려는 개념은 **네트워크의 혼잡(Congestion)** 이다.  

![](../images/Pasted%20image%2020251014004547.png)


만약 라우터와 라우터 사이의 **전송 용량이 100Mbps**라고 가정하자.  
이때 어떤 하나의 경로에서 데이터가 이 **100Mbps 전송 용량을 모두 사용하고 있다면**,  
그 구간은 **혼잡한(congested)** 상태라고 할 수 있다.

즉, 라우터가 처리할 수 있는 용량(대역폭, Bandwidth)을 이미 모두 사용하고 있기 때문에  
추가적인 데이터가 들어오면 **지연(latency)** 이 발생하거나 **패킷이 손실(loss)** 될 가능성이 커진다.  
이런 상태를 **네트워크 혼잡**이라고 부르며,  
혼잡이 심해질수록 전체 네트워크 성능이 급격히 저하될 수 있다.

![](../images/Pasted%20image%2020251014005528.png)


여기 그래프를 보면, **x축은 Load(부하)**, 즉 **데이터를 보내는 양**을 나타내고, 
**y축은 Delay(지연 시간)** 을 나타낸다.

처음에는 네트워크 부하가 적을 때, 데이터를 조금씩 더 보내더라도 지연 시간은 거의 증가하지 않는다.  하지만 부하가 점점 커져서 **라우터나 링크의 전송 용량(Capacity)** 에 가까워질수록, 즉 **최대 처리 속도(예: 100Mbps)** 에 도달할수록 **지연 시간(Delay)** 이 **급격하게 증가**하는 것을 볼 수 있다.


![](../images/Pasted%20image%2020251014005714.png)

이번 그래프에서 **x축은 데이터 전송량(Load)**, 즉 네트워크에 보내는 데이터의 양을 나타내고,  
**y축은 처리량(Throughput)**, 즉 단위 시간당 실제로 전송이 성공적으로 완료된 데이터의 양을 나타낸다.

처음에는 데이터 전송량이 증가함에 따라 처리량도 함께 증가한다. 그러나 일정 수준을 넘어가면서 **네트워크에 혼잡(Congestion)** 이 발생하면 상황이 달라진다.  

혼잡이 생기면 라우터의 **버퍼(Buffer)** 가 가득 차게 되고, 새로 들어오는 패킷은 **버퍼에 저장되지 못하고 즉시 버려지게 된다**. 이때 송신자는 패킷이 손실되었음을 직접 알 수 없기 때문에, **ACK(확인 응답)** 이 오지 않거나 **Timeout** 또는 **Fast Retransmission** 메커니즘을 통해 손실된 패킷을 **다시 재전송**하게 된다.

문제는 이러한 재전송이 **혼잡 상태에서는 계속 반복될 수 있다는 점**이다.  

즉, 네트워크가 과부하 상태일수록 손실과 재전송이 늘어나고, 그 결과 실제로 단위 시간당 성공적으로 전달되는 데이터의 양(Throughput)은 오히려 **감소**하게 된다.

결국 그래프를 보면, **처리량은 초기에는 부하 증가와 함께 상승하다가**, **최대 용량(Capacity, 예: 100Mbps)** 을 넘는 시점부터는 혼잡으로 인해 급격히 **하락**하는 모습을 보인다.  

이 구간이 바로 네트워크의 **혼잡 구간(Congestion Region)** 이며, TCP 혼잡 제어 알고리즘이 동작해야 하는 핵심 구간이다.

---
## Slow start, exponential increase

네트워크에서 혼잡이 발생하더라도, TCP는 이를 스스로 감지하고 조절할 수 있는 **혼잡 제어(Congestion Control)** 메커니즘을 가지고 있다.

우리가 앞서 배운 **흐름 제어(Flow Control)** 에서는 수신 측이 받을 수 있는 데이터의 양을 의미하는 **rwnd (Receiver Window)** 를 기준으로 윈도우 크기를 조절했다. 그러나 실제 전송 속도를 결정하는 데에는 수신 측의 상태뿐 아니라, **네트워크 전체의 혼잡도**도 고려되어야 한다. 이때 TCP는 **cwnd (Congestion Window)** 라는 개념을 추가로 사용한다.

즉, **rwnd**는 “수신자가 얼마나 받을 수 있는가”를 나타내는 값이라면, **cwnd**는 “현재 네트워크가 얼마나 감당할 수 있는가”를 나타내는 값이다.  TCP는 이 두 값 중 더 작은 값을 실제 윈도우 크기로 선택하여 전송량을 조절한다. 이때 cwnd는 중앙에서 알려주는 값이 아니라, 송신 측이 스스로 네트워크 상태를 관찰하며 동적으로 계산한다.

만약 cwnd가 존재하지 않는다면, 수신 측이 매우 큰 rwnd를 보내왔을 때 송신 측은 한 번에 엄청난 양의 데이터를 전송하게 된다. 그 결과 네트워크가 한순간에 과부하되어 **혼잡(Congestion)** 이 발생할 수 있다. 이를 방지하기 위해 TCP는 처음에는 **cwnd를 1 MSS (Maximum Segment Size)** 로 설정한 뒤, 네트워크의 상태를 살펴보며 점진적으로 전송 속도를 늘려 나간다.

![](../images/Pasted%20image%2020251014204555.png)

이 과정이 바로 **Slow Start Algorithm(느린 시작 알고리즘)** 이다.

이름은 ‘느린 시작’이지만, 실제로는 매우 빠르게 증가한다. 처음에는 cwnd가 1 MSS로 시작하고, 데이터를 전송한 뒤 **ACK을 받을 때마다 cwnd를 두 배씩 증가**시킨다. 즉, 첫 번째 라운드에서는 cwnd = 1, 두 번째에는 2, 세 번째에는 4, 그다음에는 8 MSS로 증가하는 식이다. 이처럼 지수적으로 성장하기 때문에 네트워크의 여유 용량을 빠르게 탐색할 수 있다.

다만 cwnd가 무한정 커지면 결국 다시 혼잡이 발생할 수 있으므로, TCP는 **threshold(임계값)** 를 정해두고, cwnd가 이 값에 도달하기 전까지는 두 배씩 증가시키지만, 이후부터는 증가 속도를 줄여 점진적으로 늘려 나간다. 이 임계값은 네트워크 상태를 고려하기보다는 시스템이 설정한 **기본값(default 값)** 에 의해 정해진다.

결국 **Slow Start Algorithm**은 이름처럼 처음에는 천천히 시작하는 것이 아니라, “Flow Control에 비해 상대적으로 느린 시작을 보인다”는 의미를 가진다.

---
## 혼잡 회피

TCP의 **혼잡 제어(Congestion Control)** 는 단순히 전송 속도를 늘리거나 줄이는 것이 아니라,  
네트워크의 상태를 관찰하면서 **점진적으로 안전한 수준의 전송량을 유지**하려는 과정이다.

앞서 설명한 **Slow Start 단계**에서는 cwnd(Congestion Window)가 **ACK을 받을 때마다 2배씩 증가**했다. 그러나 cwnd가 **임계값(Threshold, ssthresh)** 에 도달하면 TCP는 더 이상 지수적으로 증가시키지 않고, **혼잡 회피(Congestion Avoidance)** 단계로 진입한다.

![](../images/Pasted%20image%2020251014205230.png)

임계값을 넘어서면 cwnd는 갑자기 감소하거나 멈추는 것이 아니라, 이제부터는 **점진적으로 1씩 증가**한다. 즉, cwnd의 증가 속도가 **지수적(2배)** → **선형적(1씩)** 으로 바뀌는 것이다.

실제 네트워크 상황에서는 송신 측이 한 번에 여러 개의 세그먼트를 전송한다. 즉, cwnd 크기만큼의 세그먼트가 동시에 전송되고, 이 각각의 세그먼트에 대해 **ACK** 이 순차적으로 도착하게 된다.

송신 측은 **해당 RTT(Round Trip Time)** — 즉, 데이터를 보내고 ACK이 돌아오는 한 주기 —  
동안 모든 세그먼트의 ACK을 다 받았을 때를 기준으로 “지금은 혼잡하지 않다”고 판단한다.  
그때마다 cwnd를 **1 MSS씩 증가**시킨다.

이렇게 cwnd를 천천히 늘려가며 네트워크의 여유 용량을 점진적으로 탐색하는 것이 혼잡 회피의 핵심이다.

---
## TCP 혼잡 전체 보기

TCP는 네트워크 혼잡이 발생하면 스스로 전송 속도를 조절하여 안정적인 통신을 유지한다.  
이를 위해 사용하는 핵심 변수는 **cwnd**와 **ssthresh (Slow Start Threshold)** 이다.

처음 연결이 시작되면 **cwnd = 1 MSS** 로 설정되고, 데이터를 전송하며 ACK을 받을 때마다 cwnd가 점점 커진다. 이때 **ssthresh(임계값)** 에 도달하기 전까지는 cwnd가 **2배씩 증가(Slow Start)** 하고, 임계값을 넘어서면 **1씩 증가(Congestion Avoidance)** 하며 네트워크 상태를 조심스럽게 관찰한다.

![](../images/Pasted%20image%2020251014210022.png)

TCP는 네트워크에서 **패킷 손실(Packet Loss)** 이 발생했을 때 이를 **혼잡(Congestion)** 으로 간주한다. 실제로 전체 패킷 손실의 약 99%는 네트워크 혼잡으로 인해 발생하기 때문이다. 따라서 TCP는 패킷이 손실되었다고 판단하는 순간, **혼잡이 발생했다**고 인식하고 전송 속도를 줄인다.

### Congestion Avoidance
TCP는 **혼잡 회피(Congestion Avoidance)** 구간에서 네트워크의 여유를 관찰하며 천천히 cwnd를 1씩 증가시키며 전송량을 늘린다. 하지만 네트워크가 일정 수준 이상으로 바빠지면, 결국 **혼잡(Congestion)** 이 발생할 수 있다.

이때 TCP는 패킷 손실을 통해 혼잡을 감지하며, 혼잡이 발생했다고 판단하는 상황은 두 가지로 구분된다. 하나는 **3번의 중복 ACK이 도착한 경우**, 다른 하나는 **Timeout(재전송 타이머 초과)** 이 발생한 경우다.

같은 ACK 번호가 **3번 연속으로 도착**했다는 것은 중간에 특정 세그먼트가 손실되었음을 의미한다. 즉, 네트워크에 **부분적인 혼잡**이 생긴 상황이다.

이 경우 TCP는 다음과 같이 동작한다:

1. **혼잡 인식:** 3개의 중복 ACK 수신
    
2. **cwnd 조정:** 현재 cwnd의 절반으로 줄인다.
    
3. **전송 재개:** cwnd를 1씩 증가시키며 천천히 회복 (선형적 증가)


만약 송신 측이 전송한 데이터에 대한 ACK을 **일정 시간 동안 전혀 받지 못한다면**, 이는 네트워크가 매우 심각하게 혼잡하거나 중단된 상태로 판단한다.

이 경우 TCP는 보다 강력한 복구 절차를 수행한다:

1. **혼잡 인식:** Timeout 발생
    
2. **cwnd 초기화:** cwnd를 다시 **1 MSS** 로 리셋
    
3. **ssthresh 조정:** 새로운 threshold = (Timeout 시점의 cwnd의 절반)
    
4. **Slow Start 재진입:** cwnd = 1부터 다시 시작, 이후 2배씩 증가


즉, Timeout은 단순한 혼잡이 아니라 **네트워크 붕괴 수준의 혼잡**으로 간주되어  
TCP는 다시 처음부터 전송 속도를 탐색하는 **Slow Start 단계**로 돌아간다.

---
### Slow start
지금까지 살펴본 혼잡 제어는 **Threshold를 넘은 이후**, 즉 **Congestion Avoidance(혼잡 회피)** 구간에서 혼잡이 발생했을 때의 동작이었다. 하지만 혼잡은 Threshold에 도달하기 전, 즉 **Slow Start 단계**에서도 발생할 수 있다.

이 경우에도 TCP는 마찬가지로 혼잡을 감지하는 두 가지 신호 — **3중 중복 ACK** 과 **Timeout** — 을 통해 대응하지만, 그 반응 방식은 Congestion Avoidance 단계와 조금 다르다.

##### 3중 중복 ACK이 발생한 경우 

Slow Start 구간에서는 cwnd가 **지수적으로(2배씩)** 빠르게 증가한다. 이 시점에서 동일한 ACK이 **3번 연속으로 수신**되면, 네트워크에 혼잡이 생겨 일부 패킷이 손실된 것으로 판단한다.

이때 TCP는 다음과 같이 동작한다:

1. **혼잡 인식:** 3개의 중복 ACK 수신
    
2. **cwnd 조정:** 현재 cwnd의 절반으로 줄인다.
    
3. **상태 변경:** Slow Start 단계를 종료하고 **Congestion Avoidance 단계**로 전환
    
4. **전송 재개:** cwnd를 1씩 증가시키며 전송 (선형적 증가)

즉, 원래는 2배씩 증가하던 cwnd가 혼잡을 감지한 순간 **절반으로 줄고**, 이후부터는 **1씩 증가하는 완만한 모드**로 전환된다. 이것이 **Slow Start → Congestion Avoidance** 로의 전환 지점이다.

##### Timeout이 발생한 경우

반면, **Timeout**이 발생했다는 것은 단순한 혼잡이 아니라 네트워크가 **심각하게 정체된 상황**이라는 뜻이다. 이때는 Congestion Avoidance 상태로 가지 않고, TCP는 다시 **Slow Start 단계의 처음으로 되돌아간다.**

즉, 다음과 같은 동작이 이루어진다:

1. **혼잡 인식:** Timeout 발생
    
2. **cwnd 초기화:** cwnd를 다시 **1 MSS** 로 리셋
    
3. **ssthresh 재설정:** 새로운 ssthresh = (Timeout 발생 시 cwnd의 절반)
    
4. **Slow Start 재진입:** cwnd = 1부터 시작해 2배씩 증가
    

이렇게 함으로써 TCP는 완전히 혼잡한 네트워크를 피하기 위해 전송 속도를 다시 최소한의 수준으로 줄이고, 안전하게 네트워크 용량을 재탐색한다.

---
### Congestion Example

![](../images/Pasted%20image%2020251014212242.png)

그래프를 보면 알 수 있듯이, **TCP의 혼잡 윈도우(cwnd)** 값은 절대로 0이 되지 않는다.  
그 이유는 TCP의 전송 구조 자체가 **윈도우 크기(Window Size)** 에 의해 결정되기 때문이다.

TCP에서 한 번에 전송할 수 있는 데이터의 양, 즉 **윈도우 크기**는 다음과 같은 공식으로 결정된다:

> **Window Size = min(rwnd, cwnd)**

여기서 **rwnd (Receiver Window)** 는 수신 측의 버퍼 여유 공간, **cwnd (Congestion Window)** 는 네트워크 혼잡 상태를 반영한 송신 측의 제어 변수이다.

만약 cwnd가 0이 된다면, 결국 `Window Size = 0` 이 되어 송신 측은 **어떠한 데이터도 전송할 수 없게 된다.** 

문제는 여기서 끝이 아니다.

TCP는 cwnd를 조정하기 위해 **ACK(확인 응답)** 을 받아야 하는데, cwnd가 0이면 **데이터를 전송하지 못하므로 ACK을 받을 수도 없다.** 즉, cwnd를 갱신할 수단 자체가 사라지는 **교착 상태(deadlock)** 에 빠지게 된다.

따라서 TCP는 설계상 cwnd가 0이 되지 않도록 한다. 혼잡이 발생해 cwnd를 줄일 때에도 **최소 1 MSS**(Maximum Segment Size) 이하로는 내려가지 않으며, 이 최소 단위를 유지한 채 다시 네트워크 상태를 탐색할 수 있도록 한다.

---

## 왜 TCP는 공평하다고 할까?

TCP는 네트워크를 사용하는 여러 연결(connection) 간에 **공평하게 대역폭을 분배**하도록 설계되어 있다.  즉, 동일한 네트워크 환경에서 여러 TCP 연결이 존재할 경우, 각 연결이 **비슷한 전송 속도(throughput)** 를 가지도록 조절한다.

![](../images/Pasted%20image%2020251016173857.png)
### RTT가 동일한 경우 — 공평함(Fair)
두 개의 TCP 연결이 있다고 가정하자.  

두 연결의 **RTT(Round Trip Time)** 가 동일하다면,  
각 연결은 RTT마다 **cwnd(혼잡 윈도우)** 를 1씩 증가시키게 된다.

따라서 두 연결 모두 같은 속도로 윈도우 크기가 증가하므로, 그래프에서 cwnd 증가량을 x축, y축으로 나타내면 **y = x** 관계가 성립한다. 즉, 두 연결의 전송 속도(throughput)는 동일하게 증가하며, TCP는 **공평하게(fair)** 대역폭을 분배한다.


이때 만약 네트워크 혼잡이 발생하여 **3중 중복 ACK (Fast Retransmission)** 이 일어나면, 각 연결의 cwnd는 절반으로 줄어든다. 그러나 두 연결이 같은 비율로 cwnd를 감소시키고, 같은 속도로 다시 증가시키므로 여전히 **기울기(증가 비율)는 1** 이다.

이 과정을 여러 번 반복하면, 결국 두 연결의 평균 전송 속도는 같아지고,  
TCP는 **RTT가 같은 연결 간에는 공평하게 대역폭을 점유**하게 된다.

### RTT가 다른 경우 — 불공평(Non-Fair)
하지만 두 연결의 **RTT가 다를 경우**, 상황은 달라진다.  
TCP에서 cwnd는 **RTT 주기마다 1씩 증가**하기 때문에, RTT가 짧은 연결일수록 **더 자주 ACK을 받게 되어 cwnd가 더 빠르게 증가**한다. 결과적으로 RTT가 빠른 연결은 윈도우 크기가 더 빨리 커지고, 혼잡 제어 주기도 짧아져 더 많은 데이터를 전송할 수 있다.

그래프 상으로 보면, RTT가 두 배 느린 연결의 경우 기울기가 절반이 되어 **y = (1/2)x** 형태가 된다. 즉, RTT가 짧을수록 네트워크를 더 많이 점유하고, RTT가 긴 연결은 불리해지는 현상이 발생한다.

따라서 TCP는 **RTT가 동일할 때만 공평(Fair)** 하고,  
RTT가 다르면 **RTT가 짧은 쪽이 네트워크를 더 많이 차지**하게 된다.
### 다중 플로우(Multiple Flows)의 영향 — P2P의 비공평성
또 다른 불공평의 원인은 **하나의 연결에서 여러 개의 흐름(Flow)을 가지는 경우**이다.  
라우터는 각 연결의 내부 구조(몇 개의 프로세스나 스트림이 있는지)를 알 수 없기 때문에,  
단순히 **흐름 단위(Flow 단위)** 로 네트워크 자원을 분배한다.

예를 들어,

- 연결 1이 2개의 플로우(Flow 1-1, Flow 1-2)를 가지고,
    
- 연결 2가 1개의 플로우만 가진다면,
    

라우터 입장에서는 총 3개의 독립된 흐름이 존재하는 것으로 보인다.  따라서 전체 대역폭은 세 흐름에게 균등하게 분배되고, 결과적으로 **연결 1이 전체 대역폭의 2/3**, 연결 2가 **1/3** 을 차지하게 된다.

이렇게 한 연결이 여러 개의 흐름을 만들어 **네트워크 점유율을 인위적으로 높이는 행위**를 **P2P (Peer-to-Peer)** 통신 구조에서 자주 볼 수 있다.  
이 경우 공평성이 깨지고, 다른 일반 사용자들의 네트워크 속도는 현저히 저하된다.

특히 가정집처럼 소규모 환경에서는 체감이 덜할 수 있지만, 기숙사나 공용 네트워크 환경에서는 **P2P 트래픽이 전체 대역폭을 잠식**하여 다른 사용자의 인터넷 속도를 심각하게 떨어뜨릴 수 있다.

---
## UDP vs TCP

지금까지 살펴본 TCP는 **신뢰성 있는 연결 지향형 프로토콜**이다. TCP는 데이터를 전송하기 전에 **연결 설정(Setup)** 과정을 통해 송신자와 수신자 간의 논리적인 연결을 수립하고, 이후에 도 다양한 메커니즘을 통해 **데이터의 신뢰성과 안정성**을 보장한다.

TCP의 주요 특징은 다음과 같다:

1. **연결 설정 (Connection Setup)**
    - **3-way handshake** 를 통해 통신 상대와 연결을 수립한다.
    - 이 과정을 통해 서로의 초기 시퀀스 번호와 상태를 동기화한다.
        
2. **신뢰성 보장 (Reliability)**
    - **ACK, 시퀀스 번호, 재전송** 등을 통해 데이터 손실이나 중복을 감지하고 복구한다.
    - 수신자는 받은 데이터를 순서대로 재조립하여 애플리케이션 계층에 전달한다.
        
3. **흐름 제어 (Flow Control)**
    - 수신 측의 버퍼 크기에 맞춰 송신 속도를 조절한다.
    - **rwnd(Receiver Window)** 를 이용하여 수신자 과부하를 방지한다.
        
4. **혼잡 제어 (Congestion Control)**
    - 네트워크의 혼잡 상태를 감지하여 전송 속도를 동적으로 조절한다.
    - **cwnd(Congestion Window)** 와 **ssthresh** 를 이용해 네트워크 과부하를 예방한다.

이렇게 TCP는 연결 설정부터 전송, 종료까지 전 과정을 정교하게 관리하기 때문에  
**데이터의 정확성과 신뢰성**을 보장한다.  
따라서 애플리케이션 계층은 TCP로부터 받은 데이터를 **“믿고 사용하면 된다.”**

---

반면 **UDP(User Datagram Protocol)** 은 이러한 기능을 제공하지 않는다. UDP는 **비연결형(Connectionless)** 프로토콜로, 데이터를 보낼 때 **별도의 연결 설정 없이 바로 전송**한다.

UDP의 특징은 다음과 같다:

- **Setup 과정 없음:** 3-way handshake 같은 연결 절차 없이 바로 데이터 전송
    
- **신뢰성 없음:** ACK, 재전송, 순서 보장 기능이 없다
    
- **흐름 제어 없음:** 송신 속도를 수신자 상태와 무관하게 결정
    
- **혼잡 제어 없음:** 네트워크 혼잡과 무관하게 계속 전송
    

즉, UDP는 단순히 **데이터를 “던지는(send and forget)” 방식**으로 동작한다.  
그 대신 헤더가 작고 처리 과정이 단순하기 때문에 **전송 지연이 적고 속도가 빠르다.**

