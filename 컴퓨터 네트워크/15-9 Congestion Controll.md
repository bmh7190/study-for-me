### 복습 Packet Switching vs Circuit Switching

우리가 통신을 하는 방식은 크게 **Packet Switching** 과 **Circuit Switching** 두 가지로 나눌 수 있다.  이 두 방식의 가장 큰 차이점은 **“경로를 어디서, 어떻게 설정하느냐”** 에 있다.

먼저 **패킷 교환 방식**은 중앙에서 전체 경로를 미리 정하지 않는다. 송신지와 수신지의 주소만 알면 되고, 중간 경로는 각 라우터가 그때그때 네트워크 상황에 따라 **동적으로 결정**한다.  
데이터는 일정 크기의 **패킷 단위**로 쪼개져 각각 독립적으로 전송되며, 서로 다른 경로를 통해 도착할 수도 있다.  이 때문에 모든 패킷이 반드시 같은 경로를 거치지는 않는다.  

중앙에서 경로를 통제하지 않기 때문에 **모니터링이나 제어가 어렵고**, 네트워크의 혼잡도에 따라 **전송 지연 시간이 일정하지 않다.**  하지만 여러 사용자가 네트워크 자원을 효율적으로 공유할 수 있고, 필요할 때만 전송하므로 전체적인 자원 활용률이 높다는 장점이 있다.  

우리가 사용하는 **인터넷이 바로 이 패킷 교환 방식**을 기반으로 동작한다.

반면 **회선 교환 방식**은 통신을 시작하기 전에 송신자와 수신자 사이의 **경로를 중앙에서 미리 설정**한다.  즉, 데이터를 주고받기 전에 하나의 **전용 회선(회로)** 을 확보하고, 통신이 끝날 때까지 그 경로가 **고정적으로 유지**된다.  

이 회선은 다른 트래픽의 영향을 받지 않기 때문에 **일관된 속도와 안정적인 품질**을 보장할 수 있다.  하지만 모든 사용자가 동시에 회선을 요청하면 사용할 수 있는 경로가 부족해 **연결 자체가 불가능한 상황**이 발생할 수도 있다. 또한 한 번 연결된 회선은 통신이 끝날 때까지 점유되므로, 자원 활용 효율이 낮다는 단점이 있다.  

전화 통신이 대표적인 회선 교환 방식의 예다.

---

우리가 지금 보려는 개념은 **네트워크의 혼잡(Congestion)** 이다.  

![](../images/Pasted%20image%2020251014004547.png)


만약 라우터와 라우터 사이의 **전송 용량이 100Mbps**라고 가정하자.  
이때 어떤 하나의 경로에서 데이터가 이 **100Mbps 전송 용량을 모두 사용하고 있다면**,  
그 구간은 **혼잡한(congested)** 상태라고 할 수 있다.

즉, 라우터가 처리할 수 있는 용량(대역폭, Bandwidth)을 이미 모두 사용하고 있기 때문에  
추가적인 데이터가 들어오면 **지연(latency)** 이 발생하거나 **패킷이 손실(loss)** 될 가능성이 커진다.  
이런 상태를 **네트워크 혼잡**이라고 부르며,  
혼잡이 심해질수록 전체 네트워크 성능이 급격히 저하될 수 있다.

![](../images/Pasted%20image%2020251014005528.png)


여기 그래프를 보면, **x축은 Load(부하)**, 즉 **데이터를 보내는 양**을 나타내고, 
**y축은 Delay(지연 시간)** 을 나타낸다.

처음에는 네트워크 부하가 적을 때, 데이터를 조금씩 더 보내더라도 지연 시간은 거의 증가하지 않는다.  하지만 부하가 점점 커져서 **라우터나 링크의 전송 용량(Capacity)** 에 가까워질수록, 즉 **최대 처리 속도(예: 100Mbps)** 에 도달할수록 **지연 시간(Delay)** 이 **급격하게 증가**하는 것을 볼 수 있다.


![](../images/Pasted%20image%2020251014005714.png)

이번 그래프에서 **x축은 데이터 전송량(Load)**, 즉 네트워크에 보내는 데이터의 양을 나타내고,  
**y축은 처리량(Throughput)**, 즉 단위 시간당 실제로 전송이 성공적으로 완료된 데이터의 양을 나타낸다.

처음에는 데이터 전송량이 증가함에 따라 처리량도 함께 증가한다. 그러나 일정 수준을 넘어가면서 **네트워크에 혼잡(Congestion)** 이 발생하면 상황이 달라진다.  

혼잡이 생기면 라우터의 **버퍼(Buffer)** 가 가득 차게 되고, 새로 들어오는 패킷은 **버퍼에 저장되지 못하고 즉시 버려지게 된다**. 이때 송신자는 패킷이 손실되었음을 직접 알 수 없기 때문에, **ACK(확인 응답)** 이 오지 않거나 **Timeout** 또는 **Fast Retransmission** 메커니즘을 통해 손실된 패킷을 **다시 재전송**하게 된다.

문제는 이러한 재전송이 **혼잡 상태에서는 계속 반복될 수 있다는 점**이다.  

즉, 네트워크가 과부하 상태일수록 손실과 재전송이 늘어나고, 그 결과 실제로 단위 시간당 성공적으로 전달되는 데이터의 양(Throughput)은 오히려 **감소**하게 된다.

결국 그래프를 보면, **처리량은 초기에는 부하 증가와 함께 상승하다가**, **최대 용량(Capacity, 예: 100Mbps)** 을 넘는 시점부터는 혼잡으로 인해 급격히 **하락**하는 모습을 보인다.  

이 구간이 바로 네트워크의 **혼잡 구간(Congestion Region)** 이며, TCP 혼잡 제어 알고리즘이 동작해야 하는 핵심 구간이다.

---
## Slow start, exponential increase

네트워크에서 혼잡이 발생하더라도, TCP는 이를 스스로 감지하고 조절할 수 있는 **혼잡 제어(Congestion Control)** 메커니즘을 가지고 있다.

우리가 앞서 배운 **흐름 제어(Flow Control)** 에서는 수신 측이 받을 수 있는 데이터의 양을 의미하는 **rwnd (Receiver Window)** 를 기준으로 윈도우 크기를 조절했다. 그러나 실제 전송 속도를 결정하는 데에는 수신 측의 상태뿐 아니라, **네트워크 전체의 혼잡도**도 고려되어야 한다. 이때 TCP는 **cwnd (Congestion Window)** 라는 개념을 추가로 사용한다.

즉, **rwnd**는 “수신자가 얼마나 받을 수 있는가”를 나타내는 값이라면, **cwnd**는 “현재 네트워크가 얼마나 감당할 수 있는가”를 나타내는 값이다.  TCP는 이 두 값 중 더 작은 값을 실제 윈도우 크기로 선택하여 전송량을 조절한다. 이때 cwnd는 중앙에서 알려주는 값이 아니라, 송신 측이 스스로 네트워크 상태를 관찰하며 동적으로 계산한다.

만약 cwnd가 존재하지 않는다면, 수신 측이 매우 큰 rwnd를 보내왔을 때 송신 측은 한 번에 엄청난 양의 데이터를 전송하게 된다. 그 결과 네트워크가 한순간에 과부하되어 **혼잡(Congestion)** 이 발생할 수 있다. 이를 방지하기 위해 TCP는 처음에는 **cwnd를 1 MSS (Maximum Segment Size)** 로 설정한 뒤, 네트워크의 상태를 살펴보며 점진적으로 전송 속도를 늘려 나간다.

![](../images/Pasted%20image%2020251014204555.png)

이 과정이 바로 **Slow Start Algorithm(느린 시작 알고리즘)** 이다.

이름은 ‘느린 시작’이지만, 실제로는 매우 빠르게 증가한다. 처음에는 cwnd가 1 MSS로 시작하고, 데이터를 전송한 뒤 **ACK을 받을 때마다 cwnd를 두 배씩 증가**시킨다. 즉, 첫 번째 라운드에서는 cwnd = 1, 두 번째에는 2, 세 번째에는 4, 그다음에는 8 MSS로 증가하는 식이다. 이처럼 지수적으로 성장하기 때문에 네트워크의 여유 용량을 빠르게 탐색할 수 있다.

다만 cwnd가 무한정 커지면 결국 다시 혼잡이 발생할 수 있으므로, TCP는 **threshold(임계값)** 를 정해두고, cwnd가 이 값에 도달하기 전까지는 두 배씩 증가시키지만, 이후부터는 증가 속도를 줄여 점진적으로 늘려 나간다. 이 임계값은 네트워크 상태를 고려하기보다는 시스템이 설정한 **기본값(default 값)** 에 의해 정해진다.

결국 **Slow Start Algorithm**은 이름처럼 처음에는 천천히 시작하는 것이 아니라, “Flow Control에 비해 상대적으로 느린 시작을 보인다”는 의미를 가진다.

---
## 혼잡 회피

TCP의 **혼잡 제어(Congestion Control)** 는 단순히 전송 속도를 늘리거나 줄이는 것이 아니라,  
네트워크의 상태를 관찰하면서 **점진적으로 안전한 수준의 전송량을 유지**하려는 과정이다.

앞서 설명한 **Slow Start 단계**에서는 cwnd(Congestion Window)가 **ACK을 받을 때마다 2배씩 증가**했다. 그러나 cwnd가 **임계값(Threshold, ssthresh)** 에 도달하면 TCP는 더 이상 지수적으로 증가시키지 않고, **혼잡 회피(Congestion Avoidance)** 단계로 진입한다.

![](../images/Pasted%20image%2020251014205230.png)

임계값을 넘어서면 cwnd는 갑자기 감소하거나 멈추는 것이 아니라, 이제부터는 **점진적으로 1씩 증가**한다. 즉, cwnd의 증가 속도가 **지수적(2배)** → **선형적(1씩)** 으로 바뀌는 것이다.

실제 네트워크 상황에서는 송신 측이 한 번에 여러 개의 세그먼트를 전송한다. 즉, cwnd 크기만큼의 세그먼트가 동시에 전송되고, 이 각각의 세그먼트에 대해 **ACK** 이 순차적으로 도착하게 된다.

송신 측은 **해당 RTT(Round Trip Time)** — 즉, 데이터를 보내고 ACK이 돌아오는 한 주기 —  
동안 모든 세그먼트의 ACK을 다 받았을 때를 기준으로 “지금은 혼잡하지 않다”고 판단한다.  
그때마다 cwnd를 **1 MSS씩 증가**시킨다.

이렇게 cwnd를 천천히 늘려가며 네트워크의 여유 용량을 점진적으로 탐색하는 것이 혼잡 회피의 핵심이다.

---
## TCP 혼잡 전체 보기

TCP는 네트워크 혼잡이 발생하면 스스로 전송 속도를 조절하여 안정적인 통신을 유지한다.  
이를 위해 사용하는 핵심 변수는 **cwnd**와 **ssthresh (Slow Start Threshold)** 이다.

처음 연결이 시작되면 **cwnd = 1 MSS** 로 설정되고, 데이터를 전송하며 ACK을 받을 때마다 cwnd가 점점 커진다. 이때 **ssthresh(임계값)** 에 도달하기 전까지는 cwnd가 **2배씩 증가(Slow Start)** 하고, 임계값을 넘어서면 **1씩 증가(Congestion Avoidance)** 하며 네트워크 상태를 조심스럽게 관찰한다.

![](../images/Pasted%20image%2020251014210022.png)

TCP는 네트워크에서 **패킷 손실(Packet Loss)** 이 발생했을 때 이를 **혼잡(Congestion)** 으로 간주한다. 실제로 전체 패킷 손실의 약 99%는 네트워크 혼잡으로 인해 발생하기 때문이다. 따라서 TCP는 패킷이 손실되었다고 판단하는 순간, **혼잡이 발생했다**고 인식하고 전송 속도를 줄인다.

### Congestion Avoidance
TCP는 **혼잡 회피(Congestion Avoidance)** 구간에서 네트워크의 여유를 관찰하며 천천히 cwnd를 1씩 증가시키며 전송량을 늘린다. 하지만 네트워크가 일정 수준 이상으로 바빠지면, 결국 **혼잡(Congestion)** 이 발생할 수 있다.

이때 TCP는 패킷 손실을 통해 혼잡을 감지하며, 혼잡이 발생했다고 판단하는 상황은 두 가지로 구분된다. 하나는 **3번의 중복 ACK이 도착한 경우**, 다른 하나는 **Timeout(재전송 타이머 초과)** 이 발생한 경우다.

같은 ACK 번호가 **3번 연속으로 도착**했다는 것은 중간에 특정 세그먼트가 손실되었음을 의미한다. 즉, 네트워크에 **부분적인 혼잡**이 생긴 상황이다.

이 경우 TCP는 다음과 같이 동작한다:

1. **혼잡 인식:** 3개의 중복 ACK 수신
    
2. **cwnd 조정:** 현재 cwnd의 절반으로 줄인다.
    
3. **전송 재개:** cwnd를 1씩 증가시키며 천천히 회복 (선형적 증가)


만약 송신 측이 전송한 데이터에 대한 ACK을 **일정 시간 동안 전혀 받지 못한다면**, 이는 네트워크가 매우 심각하게 혼잡하거나 중단된 상태로 판단한다.

이 경우 TCP는 보다 강력한 복구 절차를 수행한다:

1. **혼잡 인식:** Timeout 발생
    
2. **cwnd 초기화:** cwnd를 다시 **1 MSS** 로 리셋
    
3. **ssthresh 조정:** 새로운 threshold = (Timeout 시점의 cwnd의 절반)
    
4. **Slow Start 재진입:** cwnd = 1부터 다시 시작, 이후 2배씩 증가


즉, Timeout은 단순한 혼잡이 아니라 **네트워크 붕괴 수준의 혼잡**으로 간주되어  
TCP는 다시 처음부터 전송 속도를 탐색하는 **Slow Start 단계**로 돌아간다.

---
### Slow start
지금까지 살펴본 혼잡 제어는 **Threshold를 넘은 이후**, 즉 **Congestion Avoidance(혼잡 회피)** 구간에서 혼잡이 발생했을 때의 동작이었다. 하지만 혼잡은 Threshold에 도달하기 전, 즉 **Slow Start 단계**에서도 발생할 수 있다.

이 경우에도 TCP는 마찬가지로 혼잡을 감지하는 두 가지 신호 — **3중 중복 ACK** 과 **Timeout** — 을 통해 대응하지만, 그 반응 방식은 Congestion Avoidance 단계와 조금 다르다.

##### 3중 중복 ACK이 발생한 경우 

Slow Start 구간에서는 cwnd가 **지수적으로(2배씩)** 빠르게 증가한다. 이 시점에서 동일한 ACK이 **3번 연속으로 수신**되면, 네트워크에 혼잡이 생겨 일부 패킷이 손실된 것으로 판단한다.

이때 TCP는 다음과 같이 동작한다:

1. **혼잡 인식:** 3개의 중복 ACK 수신
    
2. **cwnd 조정:** 현재 cwnd의 절반으로 줄인다.
    
3. **상태 변경:** Slow Start 단계를 종료하고 **Congestion Avoidance 단계**로 전환
    
4. **전송 재개:** cwnd를 1씩 증가시키며 전송 (선형적 증가)

즉, 원래는 2배씩 증가하던 cwnd가 혼잡을 감지한 순간 **절반으로 줄고**, 이후부터는 **1씩 증가하는 완만한 모드**로 전환된다. 이것이 **Slow Start → Congestion Avoidance** 로의 전환 지점이다.

##### Timeout이 발생한 경우

반면, **Timeout**이 발생했다는 것은 단순한 혼잡이 아니라 네트워크가 **심각하게 정체된 상황**이라는 뜻이다. 이때는 Congestion Avoidance 상태로 가지 않고, TCP는 다시 **Slow Start 단계의 처음으로 되돌아간다.**

즉, 다음과 같은 동작이 이루어진다:

1. **혼잡 인식:** Timeout 발생
    
2. **cwnd 초기화:** cwnd를 다시 **1 MSS** 로 리셋
    
3. **ssthresh 재설정:** 새로운 ssthresh = (Timeout 발생 시 cwnd의 절반)
    
4. **Slow Start 재진입:** cwnd = 1부터 시작해 2배씩 증가
    

이렇게 함으로써 TCP는 완전히 혼잡한 네트워크를 피하기 위해 전송 속도를 다시 최소한의 수준으로 줄이고, 안전하게 네트워크 용량을 재탐색한다.

---
### Congestion Example

![](../images/Pasted%20image%2020251014212242.png)

그래프를 보면 알 수 있듯이, **TCP의 혼잡 윈도우(cwnd)** 값은 절대로 0이 되지 않는다.  
그 이유는 TCP의 전송 구조 자체가 **윈도우 크기(Window Size)** 에 의해 결정되기 때문이다.

TCP에서 한 번에 전송할 수 있는 데이터의 양, 즉 **윈도우 크기**는 다음과 같은 공식으로 결정된다:

> **Window Size = min(rwnd, cwnd)**

여기서 **rwnd (Receiver Window)** 는 수신 측의 버퍼 여유 공간, **cwnd (Congestion Window)** 는 네트워크 혼잡 상태를 반영한 송신 측의 제어 변수이다.

만약 cwnd가 0이 된다면, 결국 `Window Size = 0` 이 되어 송신 측은 **어떠한 데이터도 전송할 수 없게 된다.** 

문제는 여기서 끝이 아니다.

TCP는 cwnd를 조정하기 위해 **ACK(확인 응답)** 을 받아야 하는데, cwnd가 0이면 **데이터를 전송하지 못하므로 ACK을 받을 수도 없다.** 즉, cwnd를 갱신할 수단 자체가 사라지는 **교착 상태(deadlock)** 에 빠지게 된다.

따라서 TCP는 설계상 cwnd가 0이 되지 않도록 한다. 혼잡이 발생해 cwnd를 줄일 때에도 **최소 1 MSS**(Maximum Segment Size) 이하로는 내려가지 않으며, 이 최소 단위를 유지한 채 다시 네트워크 상태를 탐색할 수 있도록 한다.

---

## 왜 TCP는 공평하다고 할까?

두 개의 connection이 RTT 가 같을 때, RTT 마다 cwnd +=1 이 되고, 혼잡이 발생한 경우에 3duplicated ack이라고 가정하자.


지금 cwnd 가 똑같이 증가하고, rtt도 같으므로 x증가랑가 y증가량이 같아 y=x라는 식이 성립한다. 그런데 만약 R 영역을 넘고 혼잡이 발생한다면, 3 duplicated ack이기 때문에 현재 cwnd는 반이 될 것이다. 그런데 여전히 x증가량과 y증가량은 동일하므로 기울기는 1이다. 근데 혼잡이 여러번 발생해서 이 과정을 여러번 수행하다면 y=x 즉 x connection과 yconnection의 throughput이 동일하게 된다. 이런 방식으로 TCP 는 네트워크의 사용량을 연결된 커넥션에게 동일하게 점유시키는 것이다.


RTT가 같은 경우에 TCP 는 fair하다 즉 공평하게 네트워크를 점유한다. 


근데 만약 RTT가 두 개의 커넥셔닝 다른 경우에는 어떻게 될까?

윈도우 size는 RTT 마다 증가하기 때문에 RTT 가 다른 경우 증가 속도 또한 달라지게 된다. 결국 각 커넥션의 변화량이 달라지기 때문에 기울기가 달라져 y = x즉 x 의 throughput과 y의 thorughput이 같아지는게 아니라 x가 y보다 RTT가 2배 빠르다면 y = 1/2x에 근접하게 된다.

RTT가 다른 경우에 fair 하지 않고, RTT가 빠를 수록 네트워크를 더 점유한다.


여기 또 생각해볼 것은 
하나의 커넥션이 여러 개의 flow를 가지고 있다고 해보자 멀티프로세스를 통해서 여러 흐름을 만든 것이다. 이때 라우터는 누가 보냈는지 알지 못하고, 다음 경로 설정을 해주기 때문에 만약 connection 1에서 2개의 flow, connection 2에서 1개의 flow를 가진다고 치면, 총 3개의 flow에 동일하게 네트워크 사용량이 점유 되는 것이다. 결과적으로 connection 1이 더 점유하게 되는 상황이 발생한다.

flow가 여러 개면 fair 하지 못 하다.